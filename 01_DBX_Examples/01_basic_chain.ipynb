{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d353afa-013c-435c-82ef-c5aade9a0c58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade langchain-databricks langchain-community langchain databricks-sql-connector nltk rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30914844-caaa-41ac-9e0d-2e2fac9348be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python or dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe6ff43a-1ab1-47d6-98b3-a5bde13322fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Proof of concept (POC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4586de27-31af-4213-b099-f2297d71dc68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here we want to make a simple chain that takes a question and gives an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5566ff40-981d-4a5d-9a91-09860be77e9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain_databricks import ChatDatabricks\n",
    "\n",
    "chat_model = ChatDatabricks(\n",
    "                            endpoint=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "                            temperature=0.1,\n",
    "                            max_tokens=250,\n",
    "                        )\n",
    "\n",
    "prompt_template = \"\"\"Answer the following question {question}\"\"\"\n",
    "\n",
    "question = \"what is databricks?\"\n",
    "\n",
    "prompt_template = prompt_template.format(question=question)\n",
    "\n",
    "result = chat_model.invoke(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13250e7a-d78a-48ab-8dbc-52d98101ed54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Databricks is a cloud-based data engineering platform that enables data teams to collaborate on data integration, data engineering, data science, and data analytics workloads. It was founded by the original creators of Apache Spark, a popular open-source data processing engine.\\n\\nDatabricks provides a unified platform for data engineering, data science, and data analytics, allowing users to work with various data sources, including structured, semi-structured, and unstructured data. The platform offers a range of features, including:\\n\\n1. **Data Engineering**: Databricks provides a scalable and secure environment for data engineers to build, deploy, and manage data pipelines, using languages like Python, Scala, and R.\\n2. **Data Science**: The platform offers a collaborative environment for data scientists to explore, visualize, and model data using popular libraries like TensorFlow, PyTorch, and scikit-learn.\\n3. **Data Analytics**: Databricks provides a fast and scalable environment for data analysts to query, analyze, and visualize data using SQL, Python, and R.\\n4. **Data Lakehouse**: Databricks offers a data lakehouse architecture, which combines the benefits of data warehouses and data lakes, allowing users to store and analyze data in a single platform'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7287e4ad-e9c3-4e2b-8b44-bee11b411b8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ML Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b09119c4-a2d7-4e72-a9f9-35bbaa3ae376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b12fba2-f31c-4b44-b1cf-73c0bc967c1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_chain_to_mlflow(chain, wrapper, experiment_name: str = \"example-chain\"):\n",
    "    \"\"\"Helper function for logging a chain to MLflow\"\"\"\n",
    "    # Get Path for MLflow\n",
    "    if IS_DATABRICKS:\n",
    "        # Use workspace path for Databricks\n",
    "        experiment_path = f\"/Shared/{experiment_name}\"\n",
    "        try:\n",
    "            experiment = mlflow.get_experiment_by_name(experiment_path)\n",
    "            if experiment is None:\n",
    "                mlflow.create_experiment(experiment_path)\n",
    "            mlflow.set_experiment(experiment_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up Databricks experiment: {e}\")\n",
    "            raise\n",
    "    else:\n",
    "        # Local experiment setup\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            mlflow.create_experiment(experiment_name)\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    # Define model signature\n",
    "    from mlflow.models.signature import ModelSignature\n",
    "    from mlflow.types import Schema, ColSpec, DataType\n",
    "    \n",
    "    # Define input schema (question column)\n",
    "    input_schema = Schema([\n",
    "        ColSpec(DataType.string, \"question\")\n",
    "    ])\n",
    "    \n",
    "    # Define output schema (model returns string)\n",
    "    output_schema = Schema([\n",
    "        ColSpec(DataType.string)\n",
    "    ])\n",
    "    \n",
    "    # Create signature\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "    # Start logging of model\n",
    "    with mlflow.start_run() as run:\n",
    "        config = chain.get_config()\n",
    "        mlflow.log_params({\n",
    "            \"model_name\": config[\"model_name\"],\n",
    "            \"temperature\": config[\"temperature\"],\n",
    "            \"environment\": \"databricks\" if IS_DATABRICKS else \"local\"\n",
    "        })\n",
    "\n",
    "        # Create temporary file for prompt template\n",
    "        prompt_path = None\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\n",
    "            f.write(config[\"prompt_template\"])\n",
    "            prompt_path = f.name\n",
    "\n",
    "        try:\n",
    "            # Create wrapper\n",
    "            wrapper = wrapper(chain)\n",
    "            # Log the model with requirements and signature\n",
    "            requirements = [\n",
    "                \"youtube-transcript-api\",\n",
    "                \"groq\",\n",
    "                \"python-dotenv\",\n",
    "                \"pandas\"\n",
    "            ]\n",
    "            if IS_DATABRICKS:\n",
    "                requirements.append(\"databricks-mlflow\")\n",
    "            \n",
    "            logged_model = mlflow.pyfunc.log_model(\n",
    "                artifact_path=\"artifacts\",\n",
    "                python_model=wrapper,\n",
    "                artifacts={\"prompt_template\": prompt_path},\n",
    "                pip_requirements=requirements,\n",
    "                signature=signature  # Add the signature here\n",
    "            )\n",
    "        finally:\n",
    "            if prompt_path and os.path.exists(prompt_path):\n",
    "                os.unlink(prompt_path)\n",
    "\n",
    "    return run.info.run_id, logged_model.model_uri\n",
    "\n",
    "def load_chain_from_mlflow(run_id: str, experiment_name = \"example_chain\", ):\n",
    "    \"\"\"\n",
    "    Helper function to load a chain from MLFlow\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if IS_DATABRICKS:\n",
    "            model_uri = f\"runs:/{run_id}/artifacts\"\n",
    "            chain = mlflow.pyfunc.load_model(model_uri)\n",
    "            return chain\n",
    "        else:\n",
    "            model_uri = f\"runs:/{run_id}/{experiment_name}\"\n",
    "            chain = mlflow.pyfunc.load_model(model_uri)\n",
    "            return chain\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading chain from MLflow: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67007d81-fc5c-4b02-ba5c-76bb316791c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Defining chain as a Model with a wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d675c218-eee6-425f-a916-71a65166004b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Class for the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "966249a5-e6e0-42a5-8681-71a832bd9892",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain_databricks import ChatDatabricks\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "try:\n",
    "    import databricks.mlflow\n",
    "    IS_DATABRICKS = True\n",
    "    import dbutils\n",
    "except ImportError:\n",
    "    IS_DATABRICKS = False\n",
    "\n",
    "class myChain:\n",
    "    def __init__(self, model_name, prompt_template, temperature=0):\n",
    "        self.model_name = model_name\n",
    "        self.prompt_template = prompt_template\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, query):\n",
    "        chat_model = ChatDatabricks(\n",
    "                                        endpoint=self.model_name,\n",
    "                                        temperature=self.temperature,\n",
    "                                        max_tokens=250,\n",
    "                                    )\n",
    "        \n",
    "        prompt = self.prompt_template.format(question=query)\n",
    "        result = chat_model.invoke(prompt).content\n",
    "        return result\n",
    "    \n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get chain configuration for MLflow tracking\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"prompt_template\": self.prompt_template\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42494b4a-9642-4138-8f99-0d6847653528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Wrapper for MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dda70f8b-64f0-44d5-8eff-8444fe0edad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class myChainWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, chain=None):\n",
    "        self.chain = chain\n",
    "        \n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        :param context: MLflow model context\n",
    "        :param model_input: DataFrame or Series containing YouTube URLs\n",
    "        :return: List of summaries\n",
    "        \"\"\"\n",
    "        questions = model_input['question'].to_list()\n",
    "            \n",
    "        return [self.chain(question) for question in questions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f131673-b25c-4f49-a139-3eb596b8b047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# create an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58bdf61d-3e7b-4746-bbb6-dc9bb7d6bf4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:05:48 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n2024/11/21 10:05:48 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dce099c3c64517b3597d1ae470e8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:05:48 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n - youtube-transcript-api (current: uninstalled, required: youtube-transcript-api)\n - groq (current: uninstalled, required: groq)\nTo fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fe274113ed42dcb38a52121a612bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:05:49 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n2024/11/21 10:05:49 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run polite-rook-425 at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680/runs/cdb51904cd854e33bb4f3b8f7c3682e3\n🧪 View experiment at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "Answer the following question: {question}\n",
    "\"\"\"\n",
    "model_name = \"databricks-meta-llama-3-1-70b-instruct\"\n",
    "\n",
    "chain = myChain(prompt_template=prompt_template, model_name=model_name)\n",
    "\n",
    "run_id, model_uri = log_chain_to_mlflow(chain=chain, \n",
    "                             wrapper=myChainWrapper, experiment_name=\"/Users/guillermo.angarita.gutierrez@gmail.com/example-chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f71a43b1-ef3b-4cae-8dea-95ce4ee2e3a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cdb51904cd854e33bb4f3b8f7c3682e3'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "485909ff-8e7c-4467-8791-9b1053eb109d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'runs:/cdb51904cd854e33bb4f3b8f7c3682e3/artifacts'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "171320b8-fe15-49c8-8446-f1ac7e8799f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Monitoring model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3dcc76a-7612-476b-b00b-c9517dcef781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f512e761-8858-405c-be08-a1bea1d3d869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "mlflow.enable_system_metrics_logging()\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.metrics_history = []\n",
    "    \n",
    "    def measure_latency(self, func, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Measure execution time of a function\n",
    "        \n",
    "        :param func: Function to measure\n",
    "        :param args: Positional arguments for the function\n",
    "        :param kwargs: Keyword arguments for the function\n",
    "        :return: tuple of (results, execution_time)\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        results = func(*args, **kwargs)  # Just store the results directly\n",
    "        end_time = time.time()\n",
    "        return results, end_time - start_time\n",
    "    \n",
    "    def measure_resource_usage(self):\n",
    "        \"\"\"Measure CPU and memory usage\"\"\"\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_info = psutil.Process().memory_info()\n",
    "        return {\n",
    "            'cpu_percent': cpu_percent,\n",
    "            'memory_mb': memory_info.rss / 1024 / 1024\n",
    "        }\n",
    "    \n",
    "    def calculate_text_metrics(self, question: str, response: str) -> dict:\n",
    "        \"\"\"\n",
    "        Calculate text-based metrics like reduction percentage and lengths\n",
    "        \"\"\"\n",
    "        question_length = len(question.split())\n",
    "        response_length = len(response.split())\n",
    "        \n",
    "        return {\n",
    "            'question_length': question_length,\n",
    "            'response_length': response_length,\n",
    "        }\n",
    "    \n",
    "    def log_performance(self, latency, question: str, response:str, resource_usage: dict):\n",
    "        \"\"\"\n",
    "        Log all performance metrics including text metrics\n",
    "        \"\"\"\n",
    "        text_metrics = self.calculate_text_metrics(question, response)\n",
    "        metrics = {\n",
    "            'latency': latency,\n",
    "            **resource_usage,\n",
    "            **text_metrics\n",
    "        }\n",
    "        self.metrics_history.append(metrics)\n",
    "        self.log_metrics(metrics)\n",
    "        return metrics\n",
    "    \n",
    "    def log_metrics(self, metrics_dict):\n",
    "        \"\"\"Log metrics to MLflow\"\"\"\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_metrics(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f948328-ec90-44f6-b9af-ddd66f36f82c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_metrics_over_time(metrics_history):\n",
    "    \"\"\"\n",
    "    Create interactive plots for metrics over time including text metrics\n",
    "    \n",
    "    :param metrics_history: List of dictionaries containing metrics data\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(metrics_history)\n",
    "    \n",
    "    # Latency plot\n",
    "    fig_latency = px.line(df, y='latency', title='Inference Latency Over Time')\n",
    "    fig_latency.show()\n",
    "    \n",
    "    # Resource usage plot\n",
    "    fig_resources = go.Figure()\n",
    "    fig_resources.add_trace(go.Scatter(y=df['cpu_percent'], name='CPU %'))\n",
    "    fig_resources.add_trace(go.Scatter(y=df['memory_mb'], name='Memory (MB)'))\n",
    "    fig_resources.update_layout(title='Resource Usage Over Time')\n",
    "    fig_resources.show()\n",
    "    \n",
    "    # Text metrics plot\n",
    "    fig_text = go.Figure()\n",
    "    text_metrics = ['question_length', 'response_length']\n",
    "    for metric in text_metrics:\n",
    "        if metric in df.columns:\n",
    "            fig_text.add_trace(go.Scatter(y=df[metric], name=metric))\n",
    "    fig_text.update_layout(title='Text Metrics Over Time')\n",
    "    fig_text.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6e50072-40cf-454b-b93e-fd8e29afa5ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c24a6ccc-6667-4dce-8844-bce3e66828e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_queries(input_df, ml_flow_chain, monitor):\n",
    "    \"\"\"\n",
    "    Process multiple videos with monitoring\n",
    "    \n",
    "    :param video_ids: List of YouTube video IDs or URLs\n",
    "    :return: tuple of (list of summaries, list of metrics)\n",
    "    \"\"\"\n",
    "    # Process all videos\n",
    "    responses = []\n",
    "    metrics_list = []\n",
    "    \n",
    "    # Generate summaries with latency measurement\n",
    "    results, total_latency = monitor.measure_latency(\n",
    "        lambda: ml_flow_chain.predict(input_df)\n",
    "    )\n",
    "    \n",
    "    # Calculate average latency per video\n",
    "    avg_latency = total_latency / len(input_df)\n",
    "    \n",
    "    # Process each result\n",
    "    for idx, result in enumerate(results):\n",
    "        # Measure resource usage\n",
    "        resource_usage = monitor.measure_resource_usage()\n",
    "\n",
    "        # Log metrics for each video\n",
    "        metrics = monitor.log_performance(avg_latency, input_df['question'].iloc[idx], result, resource_usage)\n",
    "        \n",
    "        responses.append(result)\n",
    "        metrics_list.append(metrics)\n",
    "    \n",
    "    return responses, metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1a30189-5ef5-4870-9ac3-68fce986c6d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fd271193444ff1b236c00598d2d530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:05:54 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n - youtube-transcript-api (current: uninstalled, required: youtube-transcript-api)\n - groq (current: uninstalled, required: groq)\nTo fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n2024/11/21 10:06:17 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n2024/11/21 10:06:17 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n2024/11/21 10:06:17 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n2024/11/21 10:06:17 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run classy-deer-261 at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680/runs/efdb1e9b189e4cc7889c676cb41fb0c0\n🧪 View experiment at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:06:17 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n2024/11/21 10:06:17 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n2024/11/21 10:06:17 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n2024/11/21 10:06:18 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run agreeable-horse-124 at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680/runs/b51832bd6ba94b888db0ad5c1def959c\n🧪 View experiment at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:06:18 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n2024/11/21 10:06:18 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n2024/11/21 10:06:18 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n2024/11/21 10:06:18 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run dashing-shrimp-832 at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680/runs/985e5ea3f3924a509181da1146ef19c2\n🧪 View experiment at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.32.0.min.js\"></script>                <div id=\"ee3dc613-74b1-4f89-9f46-5a2bf16661cc\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ee3dc613-74b1-4f89-9f46-5a2bf16661cc\")) {                    Plotly.newPlot(                        \"ee3dc613-74b1-4f89-9f46-5a2bf16661cc\",                        [{\"hovertemplate\":\"index=%{x}\\u003cbr\\u003elatency=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0,1,2],\"xaxis\":\"x\",\"y\":[7.565717140833537,7.565717140833537,7.565717140833537],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"latency\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Inference Latency Over Time\"}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.32.0.min.js\"></script>                <div id=\"918f02ef-e0c9-464c-b633-bf45748c9181\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"918f02ef-e0c9-464c-b633-bf45748c9181\")) {                    Plotly.newPlot(                        \"918f02ef-e0c9-464c-b633-bf45748c9181\",                        [{\"name\":\"CPU %\",\"y\":[5.2,6.3,5.1],\"type\":\"scatter\"},{\"name\":\"Memory (MB)\",\"y\":[768.6953125,768.70703125,768.71875],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Resource Usage Over Time\"}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.32.0.min.js\"></script>                <div id=\"e555db2a-1f40-47a8-bea9-8d26ac4f7e3b\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e555db2a-1f40-47a8-bea9-8d26ac4f7e3b\")) {                    Plotly.newPlot(                        \"e555db2a-1f40-47a8-bea9-8d26ac4f7e3b\",                        [{\"name\":\"question_length\",\"y\":[5,3,3],\"type\":\"scatter\"},{\"name\":\"response_length\",\"y\":[34,182,162],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Text Metrics Over Time\"}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-155699e004a447618b6421f062c039c7\", \"tr-d5d8683e570a4bbda6a90aa47caaf3f8\", \"tr-cfb6161176b14ead846559b215b4a66c\"]",
      "text/plain": [
       "[Trace(request_id=tr-155699e004a447618b6421f062c039c7), Trace(request_id=tr-d5d8683e570a4bbda6a90aa47caaf3f8), Trace(request_id=tr-cfb6161176b14ead846559b215b4a66c)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the performance monitor\n",
    "monitor = PerformanceMonitor()\n",
    "\n",
    "ml_flow_chain = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "questions = [\"Qué es EPM en Colombia?\",\n",
    "              \"What is Databricks?\",\n",
    "              \"Que es langchain?\"]\n",
    "\n",
    "import pandas as pd\n",
    "input_df = pd.DataFrame({'question': questions})\n",
    "\n",
    "answers, metrics = process_queries(input_df, ml_flow_chain, monitor)\n",
    "plot_metrics_over_time(monitor.metrics_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "441673d9-6c33-4160-a4c6-13d93a3ccbfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ac5b4ee-83ef-4c06-8ac0-dc0a1476fda8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12657de5-e284-4f04-8888-5c1b4afab901",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import nltk\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4128d2-91dc-4c04-92df-3b6278ad8e38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_mlflow(model, test_data: List[Dict[str, str]], experiment_name: str):\n",
    "    \"\"\"Evaluate model and log results to MLflow\"\"\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"model_evaluation\") as run:\n",
    "        all_metrics = []\n",
    "        \n",
    "        # Evaluate each test example\n",
    "        for i, example in enumerate(test_data):\n",
    "            try:\n",
    "                # Create DataFrame input\n",
    "                input_df = pd.DataFrame({'question': [example['question']]})\n",
    "                \n",
    "                # Generate prediction\n",
    "                result = model.predict(input_df)[0]  # Get first result\n",
    "                \n",
    "                # Calculate metrics\n",
    "                metrics = calculate_metrics(example['question'], result, example['answer'])\n",
    "                all_metrics.append(metrics)\n",
    "                \n",
    "                # Log metrics for each example\n",
    "                for metric_name, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"example_{i}_{metric_name}\", value)\n",
    "                \n",
    "                # Log summaries as artifacts\n",
    "                example_dir = f\"example_{i}\"\n",
    "                os.makedirs(example_dir, exist_ok=True)\n",
    "                \n",
    "                with open(f\"{example_dir}/predicted_answer.txt\", \"w\") as f:\n",
    "                    f.write(result)\n",
    "                with open(f\"{example_dir}/reference_answer.txt\", \"w\") as f:\n",
    "                    f.write(example['answer'])\n",
    "                \n",
    "                mlflow.log_artifacts(example_dir)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing example {i}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not all_metrics:\n",
    "            print(\"No successful evaluations completed\")\n",
    "            return None, None\n",
    "            \n",
    "        # Calculate and log average metrics\n",
    "        avg_metrics = {}\n",
    "        for metric in all_metrics[0].keys():\n",
    "            avg_value = np.mean([m[metric] for m in all_metrics])\n",
    "            avg_metrics[f\"avg_{metric}\"] = avg_value\n",
    "            mlflow.log_metric(f\"avg_{metric}\", avg_value)\n",
    "        \n",
    "        # Create and log visualizations\n",
    "        create_and_log_visualizations(all_metrics)\n",
    "        \n",
    "        return run.info.run_id, avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3553bb6a-f85f-4150-8d0e-20df008065eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Defining metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1f14ebf-6c40-4f1c-90a8-cac8d4001947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "@mlflow.trace(name=\"calculating metrics\")\n",
    "def calculate_metrics(question: str, answer: str, reference_answer: str) -> Dict[str, float]:\n",
    "    \"\"\"Calculate various evaluation metrics\"\"\"\n",
    "    # ROUGE scores\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = scorer.score(reference_answer, answer)\n",
    "    \n",
    "    # BLEU score\n",
    "    reference = [reference_answer.split()]\n",
    "    candidate = answer.split()\n",
    "    bleu = sentence_bleu(reference, candidate)\n",
    "    \n",
    "    # Summary length metrics\n",
    "    pred_length = len(answer.split())\n",
    "    ref_length = len(reference_answer.split())\n",
    "    length_ratio = pred_length / ref_length if ref_length > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'rouge1_precision': rouge_scores['rouge1'].precision,\n",
    "        'rouge1_recall': rouge_scores['rouge1'].recall,\n",
    "        'rouge1_f1': rouge_scores['rouge1'].fmeasure,\n",
    "        'rouge2_f1': rouge_scores['rouge2'].fmeasure,\n",
    "        'rougeL_f1': rouge_scores['rougeL'].fmeasure,\n",
    "        'bleu_score': bleu,\n",
    "        'predicted/reference_length_ratio': length_ratio,\n",
    "        'predicted_length': pred_length,\n",
    "        'reference_length': ref_length,\n",
    "    }\n",
    "\n",
    "def create_and_log_visualizations(metrics_list: List[Dict[str, float]]):\n",
    "    \"\"\"Create and log visualizations to MLflow\"\"\"\n",
    "    # Convert metrics to DataFrame\n",
    "    df = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    # ROUGE scores comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    rouge_metrics = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']\n",
    "    df[rouge_metrics].mean().plot(kind='bar')\n",
    "    plt.title('Average ROUGE Scores')\n",
    "    plt.ylabel('Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('rouge_scores.png')\n",
    "    mlflow.log_artifact('rouge_scores.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Summary length analysis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['reference_length'], df['predicted_length'])\n",
    "    plt.plot([0, max(df['reference_length'])], [0, max(df['reference_length'])], '--', color='red')\n",
    "    plt.xlabel('Reference response Length')\n",
    "    plt.ylabel('Predicted response Length')\n",
    "    plt.title('Response Length Comparison')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('length_comparison.png')\n",
    "    mlflow.log_artifact('length_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Metrics distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics_to_plot = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1', 'bleu_score']\n",
    "    df[metrics_to_plot].boxplot()\n",
    "    plt.title('Distribution of Evaluation Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_distribution.png')\n",
    "    mlflow.log_artifact('metrics_distribution.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b93c19b-f1bc-4421-9c90-8f267c68b737",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prepare dataset for evalaution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f3e3bf2-f15f-4a53-bfac-ddfff36d282b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prepare_test_data() -> List[Dict[str, str]]:\n",
    "    \"\"\"Prepare test data with YouTube videos and reference summaries\"\"\"\n",
    "    # Replace with your actual test data\n",
    "    return [\n",
    "        {\n",
    "            \"question\": \"que es epm en colombia\",\n",
    "            \"answer\": \"Es una empresa colombiana de servicios públicos domiciliarios fundada el 6 de agosto de 1955 en Medellín. EPM ofrece servicios de energía eléctrica, gas natural, agua potable, saneamiento básico y telecomunicaciones. Es propiedad del municipio de Medellín y tiene presencia en varias regiones de Colombia y otros países de América Latina.\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"why databricks can be written as dbx\",\n",
    "            \"answer\": \"\"\"Databricks can be abbreviated as DBX because it is a shorthand or mnemonic derived from the company’s name, following a common convention in technology and branding:\n",
    "\t1.\t“DB” for Databricks: The “DB” part directly represents “Data” and “Bricks,” reflecting the name of the platform.\n",
    "\t2.\t“X” for Flexibility or Multiplicity:\n",
    "\t•\tThe “X” is often used in technology branding to imply scalability, versatility, or cutting-edge innovation.\n",
    "\t•\tIn some cases, “X” also represents a short, dynamic character to make abbreviations look modern and tech-savvy.\n",
    "\t3.\tCompact Branding:\n",
    "\t•\tUsing DBX is easier to write, remember, and type than the full name “Databricks.”\n",
    "\t•\tMany organizations and products adopt similar shortened names (e.g., GCP for Google Cloud Platform or AWS for Amazon Web Services).\n",
    "\n",
    "Thus, DBX is a convenient, modern shorthand for Databricks, widely used in casual and technical communication.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"what is an LLM Agent\",\n",
    "            \"answer\": \"An LLM Agent is a software or application framework that uses a Large Language Model (LLM) as a core component to perform complex tasks by reasoning, generating content, or interacting with users or systems. LLM Agents typically extend the capabilities of an LLM to incorporate structured decision-making, external tool usage, and contextual adaptability.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "test_data = prepare_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1cb5fea-7310-43c6-9269-485a9db81163",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56cff8e8-963c-454e-8880-de2389957091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Experiment 1: Basic prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e672076b-5aee-4ab8-881e-77e86f69df11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:06:20 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n2024/11/21 10:06:20 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04636cb5bbc84256a792d7a0afa36f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:06:20 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n - youtube-transcript-api (current: uninstalled, required: youtube-transcript-api)\n - groq (current: uninstalled, required: groq)\nTo fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75b93858aca4977bb5d3caaf7c845d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:06:21 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n2024/11/21 10:06:21 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run salty-hound-845 at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680/runs/cbfb59c4f2c741ea8446233b7169baba\n🧪 View experiment at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680\nChain logged with run_id: cbfb59c4f2c741ea8446233b7169baba\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b32bb7096143aa8769c1c8d39815d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:06:22 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n - youtube-transcript-api (current: uninstalled, required: youtube-transcript-api)\n - groq (current: uninstalled, required: groq)\nTo fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "Answer the following question: {question}\n",
    "\"\"\"\n",
    "model_name = \"databricks-meta-llama-3-1-70b-instruct\"\n",
    "\n",
    "chain = myChain(prompt_template=prompt_template, model_name=model_name)\n",
    "\n",
    "run_id, model_uri = log_chain_to_mlflow(chain=chain, \n",
    "                             wrapper=myChainWrapper, experiment_name=\"/Users/guillermo.angarita.gutierrez@gmail.com/example-chain\")\n",
    "\n",
    "print(f\"Chain logged with run_id: {run_id}\")\n",
    "\n",
    "# Load the chain\n",
    "ml_flow_chain = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35ac8ce0-ba10-4115-bf3c-358a884fb8a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:06:23 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n2024/11/21 10:06:23 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded072753c9c4b78a50b63cb043d46e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-94bafbe5-1a67-4858-bca6-62c5343be06b/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning:\n\n\nThe hypothesis contains 0 counts of 4-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3365765176534e43af76b332c13eefcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-94bafbe5-1a67-4858-bca6-62c5343be06b/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning:\n\n\nThe hypothesis contains 0 counts of 4-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4b97f8b15642ab80d94c7e91c63ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 10:06:56 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n2024/11/21 10:06:56 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run model_evaluation at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680/runs/2992c448038d41d8b498614d8fa33e8f\n🧪 View experiment at: https://dbc-44a2cc4b-08f0.cloud.databricks.com/ml/experiments/2444381359140680\n\nEvaluation Results:\n==================\navg_rouge1_precision: 0.3941\navg_rouge1_recall: 0.4926\navg_rouge1_f1: 0.4031\navg_rouge2_f1: 0.1717\navg_rougeL_f1: 0.2577\navg_bleu_score: 0.0291\navg_predicted/reference_length_ratio: 1.8230\navg_predicted_length: 131.0000\navg_reference_length: 81.0000\n\nMLflow run ID: 2992c448038d41d8b498614d8fa33e8f\nView detailed results in the MLflow UI\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-f20ef3a55e8c4dddac91b13ecffddc89\", \"tr-465353f9d6754285adf36a12986c329c\", \"tr-7c6a8b7472ca4f1ba8e124ffe1d0f99f\", \"tr-0b160e81821d4731aa57ca7643df2173\", \"tr-59bb065169ce4c558bfe74674b5df00c\", \"tr-cebd13d0dbc3446c898f92b2b4bb00bf\"]",
      "text/plain": [
       "[Trace(request_id=tr-f20ef3a55e8c4dddac91b13ecffddc89), Trace(request_id=tr-465353f9d6754285adf36a12986c329c), Trace(request_id=tr-7c6a8b7472ca4f1ba8e124ffe1d0f99f), Trace(request_id=tr-0b160e81821d4731aa57ca7643df2173), Trace(request_id=tr-59bb065169ce4c558bfe74674b5df00c), Trace(request_id=tr-cebd13d0dbc3446c898f92b2b4bb00bf)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare test data\n",
    "test_data = prepare_test_data()\n",
    "experiment_name = \"/Users/guillermo.angarita.gutierrez@gmail.com/example-chain\"\n",
    "# Run evaluation\n",
    "run_id, avg_metrics = evaluate_model_with_mlflow(ml_flow_chain, test_data, experiment_name)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(\"==================\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nMLflow run ID: {run_id}\")\n",
    "print(\"View detailed results in the MLflow UI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9821a086-3886-40dd-ac06-28fba50c9d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'avg_rouge1_precision': 0.39406062449871393,\n",
       " 'avg_rouge1_recall': 0.4925566138426358,\n",
       " 'avg_rouge1_f1': 0.40309388650149436,\n",
       " 'avg_rouge2_f1': 0.1717194006790708,\n",
       " 'avg_rougeL_f1': 0.2577484896838709,\n",
       " 'avg_bleu_score': 0.02905379028174043,\n",
       " 'avg_predicted/reference_length_ratio': 1.8229598341304758,\n",
       " 'avg_predicted_length': 131.0,\n",
       " 'avg_reference_length': 81.0}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77263cf3-8311-4c44-8282-e39f51816f7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e0cfa0b-aba0-433d-ad8c-a383af261e71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'llm_qa_chain' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8193881a0cfd47af90158afbaee9d139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242ea3a447144559aeae75d1db0fe4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'llmops_class.default.llm_qa_chain'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered as: llm_qa_chain\nModel version: 1\n"
     ]
    }
   ],
   "source": [
    "# Log the final model to Databricks Model Registry\n",
    "model_name = \"llm_qa_chain\"\n",
    "model_version = mlflow.register_model(\n",
    "    model_uri=model_uri,\n",
    "    name=model_name  # Remove the \"models:/\" prefix\n",
    ")\n",
    "\n",
    "# Add description and tags\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.update_registered_model(\n",
    "    name=model_name,  # Use simple model name\n",
    "    description=\"Question-Answering Chain using Llama 3 70B\"\n",
    ")\n",
    "\n",
    "# Add version-specific tags\n",
    "client.update_model_version(\n",
    "    name=model_name,  # Use simple model name\n",
    "    version=model_version.version,\n",
    "    description=\"Basic QA chain with simple prompt template\"\n",
    ")\n",
    "\n",
    "print(f\"Model registered as: {model_name}\")\n",
    "print(f\"Model version: {model_version.version}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "basic_chain",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}