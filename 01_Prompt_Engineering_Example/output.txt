
================================================================================
# agents.yaml
================================================================================

# src/latest_ai_development/config/agents.yaml
researcher:
  role: >
    {topic} Senior Data Researcher
  goal: >
    Uncover cutting-edge developments in {topic}
  backstory: >
    You're a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.
      
reporting_analyst:
  role: >
    {topic} Reporting Analyst
  goal: >
    Create detailed reports based on {topic} data analysis and research findings
  backstory: >
    You're a meticulous analyst with a keen eye for detail. You're known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.



================================================================================
# README.md
================================================================================

# YouTube Video Summarizer with MLOps

An advanced YouTube video summarization tool that leverages Groq's LLM capabilities and MLOps practices to generate high-quality summaries of YouTube videos from their transcripts.

## 🌟 Features

- Extract transcripts from YouTube videos automatically
- Generate concise, accurate summaries using Groq's LLM
- Track and version experiments using MLflow
- Evaluate summary quality using ROUGE scores
- Visualize performance metrics and length comparisons
- Reproducible MLOps pipeline

## 📋 Prerequisites

- Python 3.8+
- Groq API key
- YouTube Data API access (optional)

## 🛠️ Installation

1. Clone the repository:
```bash
git clone [your-repo-url]
cd llmops-youtube-summarizer
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Set up environment variables:
```bash
cp .env.example .env
```
Edit `.env` and add your Groq API key:
```
GROQ_API_KEY=your_api_key_here
```

## 🚀 Usage

### Quick Start
1. Open and run the `01_PoC.ipynb` notebook for a simple proof-of-concept implementation
2. For the full MLOps pipeline, use `02_MLFlow_implementation.ipynb`

### MLflow Tracking
The project uses MLflow to track:
- Model parameters
- ROUGE scores
- Summary lengths
- Performance metrics

Access the MLflow UI:
```bash
mlflow ui
```

## 📊 Performance Metrics

The project includes several visualization tools:
- `length_comparison.png`: Compare original vs summarized text lengths
- `metrics_distribution.png`: Distribution of various performance metrics
- `rouge_scores.png`: ROUGE score analysis

## 🔧 Dependencies

Key dependencies include:
- youtube-transcript-api >= 0.6.1
- groq >= 0.4.2
- mlflow >= 2.10.0
- pandas >= 2.0.0
- rouge-score >= 0.1.2
- transformers >= 4.30.0

For a complete list, see `requirements.txt`

## 📁 Project Structure

```
.
├── 01_PoC.ipynb                  # Proof of concept implementation
├── 02_MLFlow_implementation.ipynb # MLOps pipeline implementation
├── prompt_template.txt           # LLM prompt engineering template
├── requirements.txt              # Project dependencies
├── mlruns/                      # MLflow experiment tracking
└── example_*/                   # Example outputs and results
```

## 🤝 Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## 📝 License

[Your chosen license]

## 🙏 Acknowledgments

- Groq for providing the LLM API
- YouTube for transcript access
- MLflow for experiment tracking


================================================================================
# 04_Chat_with_docs.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "generate a txt file for a local repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iterate through repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "# agents.yaml\n",
      "================================================================================\n",
      "\n",
      "# src/latest_ai_development/config/agents.yaml\n",
      "researcher:\n",
      "  role: >\n",
      "    {topic} Senior Data Researcher\n",
      "  goal: >\n",
      "    Uncover cutting-edge developments in {topic}\n",
      "  backstory: >\n",
      "    You're a seasoned researcher with a knack for uncovering the latest\n",
      "    developments in {topic}. Known for your ability to find the most relevant\n",
      "    information and present it in a clear and concise manner.\n",
      "      \n",
      "reporting_analyst:\n",
      "  role: >\n",
      "    {topic} Reporting Analyst\n",
      "  goal: >\n",
      "    Create detailed reports based on {topic} data analysis and research findings\n",
      "  backstory: >\n",
      "    You're a meticulous analyst with a keen eye for detail. You're known for\n",
      "    your ability to turn complex data into clear and concise reports, making\n",
      "    it easy for others to understand and act on the information you provide.\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# README.md\n",
      "================================================================================\n",
      "\n",
      "# YouTube Video Summarizer with MLOps\n",
      "\n",
      "An advanced YouTube video summarization tool that leverages Groq's LLM capabilities and MLOps practices to generate high-quality summaries of YouTube videos from their transcripts.\n",
      "\n",
      "## 🌟 Features\n",
      "\n",
      "- Extract transcripts from YouTube videos automatically\n",
      "- Generate concise, accurate summaries using Groq's LLM\n",
      "- Track and version experiments using MLflow\n",
      "- Evaluate summary quality using ROUGE scores\n",
      "- Visualize performance metrics and length comparisons\n",
      "- Reproducible MLOps pipeline\n",
      "\n",
      "## 📋 Prerequisites\n",
      "\n",
      "- Python 3.8+\n",
      "- Groq API key\n",
      "- YouTube Data API access (optional)\n",
      "\n",
      "## 🛠️ Installation\n",
      "\n",
      "1. Clone the repository:\n",
      "```bash\n",
      "git clone [your-repo-url]\n",
      "cd llmops-youtube-summarizer\n",
      "```\n",
      "\n",
      "2. Install dependencies:\n",
      "```bash\n",
      "pip install -r requirements.txt\n",
      "```\n",
      "\n",
      "3. Set up environment variables:\n",
      "```bash\n",
      "cp .env.example .env\n",
      "```\n",
      "Edit `.env` and add your Groq API key:\n",
      "```\n",
      "GROQ_API_KEY=your_api_key_here\n",
      "```\n",
      "\n",
      "## 🚀 Usage\n",
      "\n",
      "### Quick Start\n",
      "1. Open and run the `01_PoC.ipynb` notebook for a simple proof-of-concept implementation\n",
      "2. For the full MLOps pipeline, use `02_MLFlow_implementation.ipynb`\n",
      "\n",
      "### MLflow Tracking\n",
      "The project uses MLflow to track:\n",
      "- Model parameters\n",
      "- ROUGE scores\n",
      "- Summary lengths\n",
      "- Performance metrics\n",
      "\n",
      "Access the MLflow UI:\n",
      "```bash\n",
      "mlflow ui\n",
      "```\n",
      "\n",
      "## 📊 Performance Metrics\n",
      "\n",
      "The project includes several visualization tools:\n",
      "- `length_comparison.png`: Compare original vs summarized text lengths\n",
      "- `metrics_distribution.png`: Distribution of various performance metrics\n",
      "- `rouge_scores.png`: ROUGE score analysis\n",
      "\n",
      "## 🔧 Dependencies\n",
      "\n",
      "Key dependencies include:\n",
      "- youtube-transcript-api >= 0.6.1\n",
      "- groq >= 0.4.2\n",
      "- mlflow >= 2.10.0\n",
      "- pandas >= 2.0.0\n",
      "- rouge-score >= 0.1.2\n",
      "- transformers >= 4.30.0\n",
      "\n",
      "For a complete list, see `requirements.txt`\n",
      "\n",
      "## 📁 Project Structure\n",
      "\n",
      "```\n",
      ".\n",
      "├── 01_PoC.ipynb                  # Proof of concept implementation\n",
      "├── 02_MLFlow_implementation.ipynb # MLOps pipeline implementation\n",
      "├── prompt_template.txt           # LLM prompt engineering template\n",
      "├── requirements.txt              # Project dependencies\n",
      "├── mlruns/                      # MLflow experiment tracking\n",
      "└── example_*/                   # Example outputs and results\n",
      "```\n",
      "\n",
      "## 🤝 Contributing\n",
      "\n",
      "1. Fork the repository\n",
      "2. Create your feature branch\n",
      "3. Commit your changes\n",
      "4. Push to the branch\n",
      "5. Open a Pull Request\n",
      "\n",
      "## 📝 License\n",
      "\n",
      "[Your chosen license]\n",
      "\n",
      "## 🙏 Acknowledgments\n",
      "\n",
      "- Groq for providing the LLM API\n",
      "- YouTube for transcript access\n",
      "- MLflow for experiment tracking\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# 04_Chat_with_docs.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Goal\\n\",\n",
      "    \"\\n\",\n",
      "    \"generate a txt file for a local repository\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# iterate through repo\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": []\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 3,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"import os\\n\",\n",
      "    \"\\n\",\n",
      "    \"def read_files(folder_path):\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Read files from the specified folder path with specific extensions.\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param folder_path: Path to the folder containing the files to read\\n\",\n",
      "    \"    :return: List of tuples containing file paths and their contents\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    files_and_code = []\\n\",\n",
      "    \"    file_extensions = ['.py', 'Dockerfile', '.yaml', '.env-example', '.md', \\\"ipynb\\\"]\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    for root, dirs, files in os.walk(folder_path):\\n\",\n",
      "    \"        for file_name in files:\\n\",\n",
      "    \"            if any(file_name.endswith(ext) for ext in file_extensions):\\n\",\n",
      "    \"                file_path = os.path.join(root, file_name)\\n\",\n",
      "    \"                with open(file_path, 'r', encoding='utf-8') as file:\\n\",\n",
      "    \"                    code = file.read()\\n\",\n",
      "    \"                    files_and_code.append((file_path, code))\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return files_and_code\\n\",\n",
      "    \"\\n\",\n",
      "    \"def create_txt_from_files(folder_path, output_txt_path):\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Create a text file containing the contents of all files in the specified folder.\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param folder_path: Path to the folder containing the files to process\\n\",\n",
      "    \"    :param output_txt_path: Path where the output text file will be saved\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    files_and_code = read_files(folder_path)\\n\",\n",
      "    \"    text = \\\"\\\"\\n\",\n",
      "    \"    with open(output_txt_path, 'w', encoding='utf-8') as output_file:\\n\",\n",
      "    \"        for file_path, code in files_and_code:\\n\",\n",
      "    \"            # Get relative path from the root folder\\n\",\n",
      "    \"            relative_path = os.path.relpath(file_path, folder_path)\\n\",\n",
      "    \"            text += f\\\"\\\\n{'='*80}\\\\n\\\"\\n\",\n",
      "    \"            output_file.write(f\\\"\\\\n{'='*80}\\\\n\\\")\\n\",\n",
      "    \"            text += f\\\"# {relative_path}\\\\n\\\"\\n\",\n",
      "    \"            output_file.write(f\\\"# {relative_path}\\\\n\\\")\\n\",\n",
      "    \"            text += f\\\"{'='*80}\\\\n\\\\n\\\"\\n\",\n",
      "    \"            output_file.write(f\\\"{'='*80}\\\\n\\\\n\\\")\\n\",\n",
      "    \"            text += f\\\"{code}\\\\n\\\\n\\\"\\n\",\n",
      "    \"            output_file.write(code)\\n\",\n",
      "    \"            output_file.write('\\\\n\\\\n')\\n\",\n",
      "    \"    return text\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Example usage:\\n\",\n",
      "    \"folder_path = '/Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille@gmail.com/My Drive/REPO/llmops-youtube-summarizer'  # replace with your folder path\\n\",\n",
      "    \"output_txt_path = 'output.txt'  # replace with your output text file path\\n\",\n",
      "    \"text = create_txt_from_files(folder_path, output_txt_path)\\n\",\n",
      "    \"print(text)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": []\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"llmops\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 2\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# 01_PoC.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Video Summarizer using Groq\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to create a YouTube video summarizer that:\\n\",\n",
      "    \"1. Takes a YouTube URL as input\\n\",\n",
      "    \"2. Extracts the video's transcription\\n\",\n",
      "    \"3. Uses Groq to generate a concise summary\\n\",\n",
      "    \"\\n\",\n",
      "    \"## Setup and Requirements\\n\",\n",
      "    \"First, we'll install the required packages:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 10,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"!pip install youtube-transcript-api groq python-dotenv -q\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Import Required Libraries\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 11,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"import groq\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from urllib.parse import urlparse, parse_qs\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load environment variables\\n\",\n",
      "    \"load_dotenv()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize Groq client\\n\",\n",
      "    \"client = groq.Groq(\\n\",\n",
      "    \"    api_key=os.getenv('GROQ_API_KEY')  # Put your API key here\\n\",\n",
      "    \")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Helper Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 12,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def extract_video_id(url):\\n\",\n",
      "    \"    \\\"\\\"\\\"Helper function to extract YouTube video ID from URL\\\"\\\"\\\"\\n\",\n",
      "    \"    parsed_url = urlparse(url)\\n\",\n",
      "    \"    if parsed_url.hostname == 'youtu.be':\\n\",\n",
      "    \"        return parsed_url.path[1:]\\n\",\n",
      "    \"    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\\n\",\n",
      "    \"        if parsed_url.path == '/watch':\\n\",\n",
      "    \"            return parse_qs(parsed_url.query)['v'][0]\\n\",\n",
      "    \"    return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"def get_transcript(video_id):\\n\",\n",
      "    \"    \\\"\\\"\\\"Helper function to get transcript for a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\\n\",\n",
      "    \"        return ' '.join([t['text'] for t in transcript_list])\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error getting transcript: {e}\\\")\\n\",\n",
      "    \"        return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"def summarize_text(text, language=\\\"spanish\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"Summarize text using Groq\\\"\\\"\\\"\\n\",\n",
      "    \"    prompt = f\\\"\\\"\\\"Please provide a comprehensive summary of the following video transcript in {language}. \\n\",\n",
      "    \"    Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"    {text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"    Please structure the summary with:\\n\",\n",
      "    \"    1. Main Topic/Theme\\n\",\n",
      "    \"    2. Key Points\\n\",\n",
      "    \"    3. Important Details\\n\",\n",
      "    \"    4. Conclusions\\\"\\\"\\\"\\n\",\n",
      "    \"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        completion = client.chat.completions.create(\\n\",\n",
      "    \"            model=\\\"llama-3.2-11b-vision-preview\\\",\\n\",\n",
      "    \"            messages=[\\n\",\n",
      "    \"                {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
      "    \"            ],\\n\",\n",
      "    \"            temperature=0.3,\\n\",\n",
      "    \"            max_tokens=2048\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"        return completion.choices[0].message.content\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error in summarization: {e}\\\")\\n\",\n",
      "    \"        return None\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Main Function to Summarize YouTube Video\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 23,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def summarize_youtube_video(url, language=\\\"spanish\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"Main function to summarize a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"    # Extract video ID\\n\",\n",
      "    \"    video_id = extract_video_id(url)\\n\",\n",
      "    \"    if not video_id:\\n\",\n",
      "    \"        return \\\"Invalid YouTube URL\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Get transcript\\n\",\n",
      "    \"    transcript = get_transcript(video_id)\\n\",\n",
      "    \"    transcript = transcript[:6000*4]\\n\",\n",
      "    \"    if not transcript:\\n\",\n",
      "    \"        return \\\"Could not retrieve transcript\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Generate summary\\n\",\n",
      "    \"    summary = summarize_text(transcript, language)\\n\",\n",
      "    \"    if not summary:\\n\",\n",
      "    \"        return \\\"Could not generate summary\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return summary\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Example Usage\\n\",\n",
      "    \"\\n\",\n",
      "    \"To use this summarizer, you'll need to:\\n\",\n",
      "    \"1. Create a `.env` file in the same directory as this notebook\\n\",\n",
      "    \"2. Add your Groq API key to the `.env` file: `GROQ_API_KEY=your_api_key_here`\\n\",\n",
      "    \"\\n\",\n",
      "    \"Then you can use the summarizer as shown below:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 24,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"**1. Main Topic/Theme**\\n\",\n",
      "      \"\\n\",\n",
      "      \"La emergencia invernal en Colombia, específicamente en los departamentos de Chocó, Guajira, Santander y Bogotá, ha causado daños significativos y afectado a miles de personas.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**2. Key Points**\\n\",\n",
      "      \"\\n\",\n",
      "      \"* La emergencia invernal ha causado daños en varios departamentos de Colombia, incluyendo Chocó, Guajira, Santander y Bogotá.\\n\",\n",
      "      \"* Miles de personas han sido afectadas, con algunas familias sin acceso a alimentos, agua potable y atención médica.\\n\",\n",
      "      \"* La falta de infraestructura y servicios básicos en algunas regiones ha agravado la situación.\\n\",\n",
      "      \"* La ayuda humanitaria ha sido lenta en llegar a algunas áreas, lo que ha generado preocupación y angustia entre los afectados.\\n\",\n",
      "      \"* La solidaridad de la comunidad colombiana ha sido notable, con donaciones y ayudas llegando a los afectados.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**3. Important Details**\\n\",\n",
      "      \"\\n\",\n",
      "      \"* En el departamento de Chocó, 188.000 personas han sido afectadas, con 40.000 familias damnificadas.\\n\",\n",
      "      \"* En la alta Guajira, 192.000 personas han sido afectadas, con una sola aeronave llegando con ayudas humanitarias.\\n\",\n",
      "      \"* En Santander, más de 350 familias han resultado damnificadas por el desbordamiento de la quebrada Las Cruces.\\n\",\n",
      "      \"* En Bogotá, una avalancha en el barrio Las Delicias del Carmen ha afectado a varias viviendas y vehículos.\\n\",\n",
      "      \"* La alcaldía de San Vicente de Chucurí había solicitado ayuda para prevenir la avalancha que se registró en diciembre de 2023.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**4. Conclusions**\\n\",\n",
      "      \"\\n\",\n",
      "      \"La emergencia invernal en Colombia ha causado daños significativos y afectado a miles de personas. La falta de infraestructura y servicios básicos en algunas regiones ha agravado la situación. Sin embargo, la solidaridad de la comunidad colombiana ha sido notable, con donaciones y ayudas llegando a los afectados. Es importante que se continúe trabajando para brindar ayuda y apoyo a las personas afectadas y que se tomen medidas para prevenir y mitigar futuras emergencias.\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Example usage\\n\",\n",
      "    \"youtube_url = \\\"https://www.youtube.com/watch?v=r5mEZCiXYN4&pp=ygUMZXBtIGNvbG9tYmlh\\\"\\n\",\n",
      "    \"language = \\\"spanish\\\"\\n\",\n",
      "    \"summary = summarize_youtube_video(youtube_url, language)\\n\",\n",
      "    \"print(summary)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": []\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# 02_MLFlow_implementation.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Video Summarizer with MLflow Integration\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to:\\n\",\n",
      "    \"1. Create a YouTube video summarization chain\\n\",\n",
      "    \"2. Track the chain and prompts using MLflow\\n\",\n",
      "    \"3. Load and use the tracked model\\n\",\n",
      "    \"\\n\",\n",
      "    \"## Setup and Requirements\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"in databricks:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 12,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\\n\",\n",
      "      \"Requirement already satisfied: youtube-transcript-api in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.6.3)\\n\",\n",
      "      \"Requirement already satisfied: groq in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.12.0)\\n\",\n",
      "      \"Requirement already satisfied: python-dotenv in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (1.0.1)\\n\",\n",
      "      \"Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\\n\",\n",
      "      \"Requirement already satisfied: requests in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\\n\",\n",
      "      \"Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.6.2.post1)\\n\",\n",
      "      \"Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.9.0)\\n\",\n",
      "      \"Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (0.27.2)\\n\",\n",
      "      \"Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (2.9.2)\\n\",\n",
      "      \"Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.3.1)\\n\",\n",
      "      \"Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.12.2)\\n\",\n",
      "      \"Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\\n\",\n",
      "      \"Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\\n\",\n",
      "      \"Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\\n\",\n",
      "      \"Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\\n\",\n",
      "      \"Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\\n\",\n",
      "      \"Requirement already satisfied: pydantic-core==2.23.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\\n\",\n",
      "      \"Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.0)\\n\",\n",
      "      \"Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2.2.3)\\n\",\n",
      "      \"Note: you may need to restart the kernel to use updated packages.\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"%pip install youtube-transcript-api groq python-dotenv\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"in local:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 13,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"!pip install youtube-transcript-api groq python-dotenv mlflow -q\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 14,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"True\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 14,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"import mlflow\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"import groq\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from urllib.parse import urlparse, parse_qs\\n\",\n",
      "    \"import json\\n\",\n",
      "    \"from typing import Dict, Any, List\\n\",\n",
      "    \"import pandas as pd\\n\",\n",
      "    \"import matplotlib.pyplot as plt\\n\",\n",
      "    \"import numpy as np\\n\",\n",
      "    \"\\n\",\n",
      "    \"try:\\n\",\n",
      "    \"    import databricks.mlflow\\n\",\n",
      "    \"    IS_DATABRICKS = True\\n\",\n",
      "    \"    import dbutils\\n\",\n",
      "    \"except ImportError:\\n\",\n",
      "    \"    IS_DATABRICKS = False\\n\",\n",
      "    \"\\n\",\n",
      "    \"from pathlib import Path\\n\",\n",
      "    \"import tempfile\\n\",\n",
      "    \"\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load environment variables\\n\",\n",
      "    \"load_dotenv()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Define Chain Components\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 15,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"class YouTubeSummaryChain:\\n\",\n",
      "    \"    def __init__(self, model_name: str = \\\"mixtral-8x7b-32768\\\", temperature: float = 0.3, prompt_template: str = \\\"\\\", language: str = \\\"spanish\\\"):\\n\",\n",
      "    \"        self.model_name = model_name\\n\",\n",
      "    \"        self.temperature = temperature\\n\",\n",
      "    \"        self.language = language\\n\",\n",
      "    \"        if prompt_template == \\\"\\\":\\n\",\n",
      "    \"            self.prompt_template = \\\"\\\"\\\"\\n\",\n",
      "    \"            Please provide a comprehensive summary of the following video transcript in {language}. \\n\",\n",
      "    \"            Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"            {text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"            Please structure the summary with:\\n\",\n",
      "    \"            1. Main Topic/Theme\\n\",\n",
      "    \"            2. Key Points\\n\",\n",
      "    \"            3. Important Details\\n\",\n",
      "    \"            4. Conclusions\\n\",\n",
      "    \"            \\\"\\\"\\\"\\n\",\n",
      "    \"        else:\\n\",\n",
      "    \"            self.prompt_template = prompt_template\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def summarize_text(self, text):\\n\",\n",
      "    \"        \\\"\\\"\\\"Summarize text using Groq\\\"\\\"\\\"\\n\",\n",
      "    \"        # Initialize client only when needed\\n\",\n",
      "    \"        if IS_DATABRICKS:\\n\",\n",
      "    \"            groq_api_key = dbutils.secrets.get(scope=\\\"your-scope\\\", key=\\\"groq-api-key\\\")\\n\",\n",
      "    \"        else:\\n\",\n",
      "    \"            groq_api_key = os.getenv('GROQ_API_KEY')\\n\",\n",
      "    \"            \\n\",\n",
      "    \"        client = groq.Groq(api_key=groq_api_key)\\n\",\n",
      "    \"        prompt = self.prompt_template.format(text=text, language=self.language)\\n\",\n",
      "    \"\\n\",\n",
      "    \"        try:\\n\",\n",
      "    \"            completion = client.chat.completions.create(\\n\",\n",
      "    \"                model=self.model_name,\\n\",\n",
      "    \"                messages=[\\n\",\n",
      "    \"                    {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
      "    \"                ],\\n\",\n",
      "    \"                temperature=self.temperature,\\n\",\n",
      "    \"                max_tokens=2048\\n\",\n",
      "    \"            )\\n\",\n",
      "    \"            return completion.choices[0].message.content\\n\",\n",
      "    \"        except Exception as e:\\n\",\n",
      "    \"            print(f\\\"Error in summarization: {e}\\\")\\n\",\n",
      "    \"            return None\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def extract_video_id(self, url: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Extract YouTube video ID from URL\\\"\\\"\\\"\\n\",\n",
      "    \"        parsed_url = urlparse(url)\\n\",\n",
      "    \"        if parsed_url.hostname == 'youtu.be':\\n\",\n",
      "    \"            return parsed_url.path[1:]\\n\",\n",
      "    \"        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\\n\",\n",
      "    \"            if parsed_url.path == '/watch':\\n\",\n",
      "    \"                return parse_qs(parsed_url.query)['v'][0]\\n\",\n",
      "    \"        return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def get_transcript(self, video_id: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Get transcript for a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"        try:\\n\",\n",
      "    \"            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\\n\",\n",
      "    \"            return ' '.join([t['text'] for t in transcript_list])\\n\",\n",
      "    \"        except Exception as e:\\n\",\n",
      "    \"            print(f\\\"Error getting transcript: {e}\\\")\\n\",\n",
      "    \"            return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def __call__(self, url: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Process a YouTube URL and return summary\\\"\\\"\\\"\\n\",\n",
      "    \"        video_id = self.extract_video_id(url)\\n\",\n",
      "    \"        if not video_id:\\n\",\n",
      "    \"            return \\\"Invalid YouTube URL\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        transcript = self.get_transcript(video_id)\\n\",\n",
      "    \"        if not transcript:\\n\",\n",
      "    \"            return \\\"Could not retrieve transcript\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        summary = self.summarize_text(transcript)\\n\",\n",
      "    \"        if not summary:\\n\",\n",
      "    \"            return \\\"Could not generate summary\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return summary, transcript\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def get_config(self) -> Dict[str, Any]:\\n\",\n",
      "    \"        \\\"\\\"\\\"Get chain configuration for MLflow tracking\\\"\\\"\\\"\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            \\\"model_name\\\": self.model_name,\\n\",\n",
      "    \"            \\\"temperature\\\": self.temperature,\\n\",\n",
      "    \"            \\\"prompt_template\\\": self.prompt_template\\n\",\n",
      "    \"        }\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## MLflow Integration\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 16,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def setup_mlflow():\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Set up MLflow tracking with support for both Databricks and local environments\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :return: None\\n\",\n",
      "    \"    :raises: MLflowException if tracking setup fails\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        if IS_DATABRICKS:\\n\",\n",
      "    \"            # Databricks automatically configures tracking URI\\n\",\n",
      "    \"            print(\\\"Running in Databricks environment\\\")\\n\",\n",
      "    \"        else:\\n\",\n",
      "    \"            mlflow_dir = Path(\\\"mlruns\\\")\\n\",\n",
      "    \"            mlflow_dir.mkdir(exist_ok=True)\\n\",\n",
      "    \"            mlflow.set_tracking_uri(\\\"sqlite:///mlflow.db\\\")\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error setting up MLflow tracking: {e}\\\")\\n\",\n",
      "    \"        raise\\n\",\n",
      "    \"\\n\",\n",
      "    \"def log_chain_to_mlflow(chain: YouTubeSummaryChain, experiment_name: str = \\\"youtube-summarizer\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Log the chain configuration and prompt to MLflow with Databricks support\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param chain: YouTubeSummaryChain instance to log\\n\",\n",
      "    \"    :param experiment_name: Name of the MLflow experiment\\n\",\n",
      "    \"    :return: MLflow run ID\\n\",\n",
      "    \"    :raises: MLflowException if logging fails\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        if IS_DATABRICKS:\\n\",\n",
      "    \"            # Use workspace path for Databricks\\n\",\n",
      "    \"            experiment_path = f\\\"/Shared/{experiment_name}\\\"\\n\",\n",
      "    \"            try:\\n\",\n",
      "    \"                experiment = mlflow.get_experiment_by_name(experiment_path)\\n\",\n",
      "    \"                if experiment is None:\\n\",\n",
      "    \"                    mlflow.create_experiment(experiment_path)\\n\",\n",
      "    \"                mlflow.set_experiment(experiment_path)\\n\",\n",
      "    \"            except Exception as e:\\n\",\n",
      "    \"                print(f\\\"Error setting up Databricks experiment: {e}\\\")\\n\",\n",
      "    \"                raise\\n\",\n",
      "    \"        else:\\n\",\n",
      "    \"            # Local experiment setup\\n\",\n",
      "    \"            experiment = mlflow.get_experiment_by_name(experiment_name)\\n\",\n",
      "    \"            if experiment is None:\\n\",\n",
      "    \"                mlflow.create_experiment(experiment_name)\\n\",\n",
      "    \"            mlflow.set_experiment(experiment_name)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        with mlflow.start_run() as run:\\n\",\n",
      "    \"            # Log parameters\\n\",\n",
      "    \"            config = chain.get_config()\\n\",\n",
      "    \"            mlflow.log_params({\\n\",\n",
      "    \"                \\\"model_name\\\": config[\\\"model_name\\\"],\\n\",\n",
      "    \"                \\\"temperature\\\": config[\\\"temperature\\\"],\\n\",\n",
      "    \"                \\\"environment\\\": \\\"databricks\\\" if IS_DATABRICKS else \\\"local\\\"\\n\",\n",
      "    \"            })\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Create temporary file for prompt template\\n\",\n",
      "    \"            prompt_path = None\\n\",\n",
      "    \"            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\\n\",\n",
      "    \"                f.write(config[\\\"prompt_template\\\"])\\n\",\n",
      "    \"                prompt_path = f.name\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            try:\\n\",\n",
      "    \"                # Create wrapper\\n\",\n",
      "    \"                wrapper = YouTubeSummarizerWrapper(chain)\\n\",\n",
      "    \"                \\n\",\n",
      "    \"                # Log the model with requirements\\n\",\n",
      "    \"                requirements = [\\n\",\n",
      "    \"                    \\\"youtube-transcript-api\\\",\\n\",\n",
      "    \"                    \\\"groq\\\",\\n\",\n",
      "    \"                    \\\"python-dotenv\\\",\\n\",\n",
      "    \"                    \\\"pandas\\\"\\n\",\n",
      "    \"                ]\\n\",\n",
      "    \"                if IS_DATABRICKS:\\n\",\n",
      "    \"                    requirements.append(\\\"databricks-mlflow\\\")\\n\",\n",
      "    \"                \\n\",\n",
      "    \"                mlflow.pyfunc.log_model(\\n\",\n",
      "    \"                    artifact_path=\\\"youtube_summarizer\\\",\\n\",\n",
      "    \"                    python_model=wrapper,\\n\",\n",
      "    \"                    artifacts={\\\"prompt_template\\\": prompt_path},\\n\",\n",
      "    \"                    pip_requirements=requirements\\n\",\n",
      "    \"                )\\n\",\n",
      "    \"            finally:\\n\",\n",
      "    \"                # Clean up temp file after logging\\n\",\n",
      "    \"                if prompt_path and os.path.exists(prompt_path):\\n\",\n",
      "    \"                    os.unlink(prompt_path)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            return run.info.run_id\\n\",\n",
      "    \"            \\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error logging chain to MLflow: {e}\\\")\\n\",\n",
      "    \"        raise\\n\",\n",
      "    \"\\n\",\n",
      "    \"def load_chain_from_mlflow(run_id: str) -> YouTubeSummaryChain:\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Load a chain from MLflow with Databricks support\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param run_id: MLflow run ID to load\\n\",\n",
      "    \"    :return: Loaded chain\\n\",\n",
      "    \"    :raises: MLflowException if loading fails\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        if IS_DATABRICKS:\\n\",\n",
      "    \"            model_uri = f\\\"runs:/{run_id}/youtube_summarizer\\\"\\n\",\n",
      "    \"            chain = mlflow.pyfunc.load_model(model_uri)\\n\",\n",
      "    \"            return chain\\n\",\n",
      "    \"        else:\\n\",\n",
      "    \"            model_uri = f\\\"runs:/{run_id}/youtube_summarizer\\\"\\n\",\n",
      "    \"            chain = mlflow.pyfunc.load_model(model_uri)\\n\",\n",
      "    \"            return chain\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error loading chain from MLflow: {e}\\\")\\n\",\n",
      "    \"        raise\\n\",\n",
      "    \"\\n\",\n",
      "    \"\\n\",\n",
      "    \"class YouTubeSummarizerWrapper(mlflow.pyfunc.PythonModel):\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    MLflow wrapper for YouTube summarizer\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param chain: Instance of YouTubeSummaryChain\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    def __init__(self, chain=None):\\n\",\n",
      "    \"        self.chain = chain or YouTubeSummaryChain()\\n\",\n",
      "    \"        \\n\",\n",
      "    \"    def predict(self, context, model_input):\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        :param context: MLflow model context\\n\",\n",
      "    \"        :param model_input: DataFrame or Series containing YouTube URLs\\n\",\n",
      "    \"        :return: List of summaries\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        if isinstance(model_input, pd.Series):\\n\",\n",
      "    \"            urls = model_input.tolist()\\n\",\n",
      "    \"        else:\\n\",\n",
      "    \"            urls = model_input['url'].tolist()\\n\",\n",
      "    \"            \\n\",\n",
      "    \"        return [self.chain(url) for url in urls]\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Example Usage\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 17,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"application/vnd.jupyter.widget-view+json\": {\n",
      "       \"model_id\": \"a105ce5f5a3d4b7ca154e6cb0309f56d\",\n",
      "       \"version_major\": 2,\n",
      "       \"version_minor\": 0\n",
      "      },\n",
      "      \"text/plain\": [\n",
      "       \"Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\"\n",
      "      ]\n",
      "     },\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"display_data\"\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"2024/11/19 09:50:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Chain logged with run_id: 327f957a0ae94cf58849f91eb5362af9\\n\",\n",
      "      \"1. Main Topic/Theme:\\n\",\n",
      "      \"The main topic of this transcript is the announcement of the beginning of the process of selling the telecommunications branch of Empresas Públicas de Medellín (EPM) by its manager, John Maya.\\n\",\n",
      "      \"\\n\",\n",
      "      \"2. Key Points:\\n\",\n",
      "      \"   - The telecommunications industry requires high capital investments due to its rapid technological changes every 5 years.\\n\",\n",
      "      \"   - EPM, as a public service provider, needs to invest in strategic areas such as energy generation, distribution, water supply, and gas, instead of telecommunications.\\n\",\n",
      "      \"   - The sale of the telecommunications branch depends on the approval of the Medellín Council, and the funds will be specifically allocated to EPM, not the mayoralty.\\n\",\n",
      "      \"   - EPM's current financial situation is good, with positive results in the first semester of the year, but there is a budget deficit of around 500,000 million pesos for planned projects.\\n\",\n",
      "      \"   - The sale process will follow a specific route, starting with offering the shares to the solidarity sector, then to special sectors, and finally to the general market.\\n\",\n",
      "      \"   - If the sale is not successful in any of these phases, EPM will continue as a partner in the telecommunications company.\\n\",\n",
      "      \"\\n\",\n",
      "      \"3. Important Details:\\n\",\n",
      "      \"   - The value of the telecommunications branch in EPM's books is 1.6 billion pesos, considering the 2022 deterioration of 1.04 billion pesos and the 2023 capitalization of 600,000 million pesos, of which 300,000 million corresponded to EPM.\\n\",\n",
      "      \"   - The government is also considering selling its shares in the telecommunications market, which could lead to a stronger competitor against the current market leader, Claro.\\n\",\n",
      "      \"   - If the sale is approved, the resources will be allocated to education and scholarships, innovation and technology for public services, waste valorization, and improving connectivity in communities.\\n\",\n",
      "      \"\\n\",\n",
      "      \"4. Conclusions:\\n\",\n",
      "      \"   - The decision to sell the telecommunications branch of EPM aims to optimize the use of resources and focus on strategic areas for the company.\\n\",\n",
      "      \"   - The sale process will follow a specific order, and EPM will continue as a partner if the sale is not successful.\\n\",\n",
      "      \"   - The funds from the sale will be invested in various projects that benefit the public services sector, education, innovation, waste management, and connectivity.\\n\",\n",
      "      \"   - The government is also considering selling its shares in the telecommunications market, which could lead to a more competitive market.\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Example usage\\n\",\n",
      "    \"setup_mlflow()\\n\",\n",
      "    \"\\n\",\n",
      "    \"chain = YouTubeSummaryChain(language=\\\"spanish\\\")\\n\",\n",
      "    \"run_id = log_chain_to_mlflow(chain)\\n\",\n",
      "    \"print(f\\\"Chain logged with run_id: {run_id}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load the chain\\n\",\n",
      "    \"loaded_chain = load_chain_from_mlflow(run_id)\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Use the loaded chain - Fix the prediction call\\n\",\n",
      "    \"youtube_url = \\\"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\\\"\\n\",\n",
      "    \"# Convert single URL to pandas Series\\n\",\n",
      "    \"input_data = pd.Series([youtube_url])\\n\",\n",
      "    \"summary, transcript = loaded_chain.predict(input_data)[0]  # Get first result from the list\\n\",\n",
      "    \"print(summary)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Model monitoring\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 18,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def log_metrics(metrics_dict):\\n\",\n",
      "    \"    \\\"\\\"\\\"Log metrics to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    with mlflow.start_run():\\n\",\n",
      "    \"        mlflow.log_metrics(metrics_dict)\\n\",\n",
      "    \"        mlflow.log_param(\\\"model_name\\\", \\\"facebook/bart-large-cnn\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 19,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"from rouge_score import rouge_scorer\\n\",\n",
      "    \"import psutil\\n\",\n",
      "    \"import plotly.express as px\\n\",\n",
      "    \"import plotly.graph_objects as go\\n\",\n",
      "    \"import time\\n\",\n",
      "    \"\\n\",\n",
      "    \"class PerformanceMonitor:\\n\",\n",
      "    \"    def __init__(self):\\n\",\n",
      "    \"        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\\n\",\n",
      "    \"        self.metrics_history = []\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def measure_latency(self, func, *args, **kwargs):\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        Measure execution time of a function\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        :param func: Function to measure\\n\",\n",
      "    \"        :param args: Positional arguments for the function\\n\",\n",
      "    \"        :param kwargs: Keyword arguments for the function\\n\",\n",
      "    \"        :return: tuple of (results, execution_time)\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        start_time = time.time()\\n\",\n",
      "    \"        results = func(*args, **kwargs)  # Just store the results directly\\n\",\n",
      "    \"        end_time = time.time()\\n\",\n",
      "    \"        return results, end_time - start_time\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def measure_resource_usage(self):\\n\",\n",
      "    \"        \\\"\\\"\\\"Measure CPU and memory usage\\\"\\\"\\\"\\n\",\n",
      "    \"        cpu_percent = psutil.cpu_percent()\\n\",\n",
      "    \"        memory_info = psutil.Process().memory_info()\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            'cpu_percent': cpu_percent,\\n\",\n",
      "    \"            'memory_mb': memory_info.rss / 1024 / 1024\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def calculate_text_metrics(self, summary: str, transcript: str) -> dict:\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        Calculate text-based metrics like reduction percentage and lengths\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        :param summary: Generated summary text\\n\",\n",
      "    \"        :param transcript: Original transcript text\\n\",\n",
      "    \"        :return: Dictionary containing text metrics\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        summary_length = len(summary.split())\\n\",\n",
      "    \"        transcript_length = len(transcript.split())\\n\",\n",
      "    \"        reduction_percentage = ((transcript_length - summary_length) / transcript_length) * 100\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            'summary_length': summary_length,\\n\",\n",
      "    \"            'transcript_length': transcript_length,\\n\",\n",
      "    \"            'reduction_percentage': reduction_percentage\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def log_performance(self, latency, summary: str, transcript: str, resource_usage: dict):\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        Log all performance metrics including text metrics\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        :param latency: Processing time\\n\",\n",
      "    \"        :param summary: Generated summary text\\n\",\n",
      "    \"        :param transcript: Original transcript text\\n\",\n",
      "    \"        :param resource_usage: Dictionary containing resource usage metrics\\n\",\n",
      "    \"        :return: Combined metrics dictionary\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        text_metrics = self.calculate_text_metrics(summary, transcript)\\n\",\n",
      "    \"        metrics = {\\n\",\n",
      "    \"            'latency': latency,\\n\",\n",
      "    \"            **resource_usage,\\n\",\n",
      "    \"            **text_metrics\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"        self.metrics_history.append(metrics)\\n\",\n",
      "    \"        log_metrics(metrics)\\n\",\n",
      "    \"        return metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 20,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def plot_metrics_over_time(metrics_history):\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Create interactive plots for metrics over time including text metrics\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param metrics_history: List of dictionaries containing metrics data\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    df = pd.DataFrame(metrics_history)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Latency plot\\n\",\n",
      "    \"    fig_latency = px.line(df, y='latency', title='Inference Latency Over Time')\\n\",\n",
      "    \"    fig_latency.show()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Resource usage plot\\n\",\n",
      "    \"    fig_resources = go.Figure()\\n\",\n",
      "    \"    fig_resources.add_trace(go.Scatter(y=df['cpu_percent'], name='CPU %'))\\n\",\n",
      "    \"    fig_resources.add_trace(go.Scatter(y=df['memory_mb'], name='Memory (MB)'))\\n\",\n",
      "    \"    fig_resources.update_layout(title='Resource Usage Over Time')\\n\",\n",
      "    \"    fig_resources.show()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Text metrics plot\\n\",\n",
      "    \"    fig_text = go.Figure()\\n\",\n",
      "    \"    text_metrics = ['summary_length', 'transcript_length', 'reduction_percentage']\\n\",\n",
      "    \"    for metric in text_metrics:\\n\",\n",
      "    \"        if metric in df.columns:\\n\",\n",
      "    \"            fig_text.add_trace(go.Scatter(y=df[metric], name=metric))\\n\",\n",
      "    \"    fig_text.update_layout(title='Text Metrics Over Time')\\n\",\n",
      "    \"    fig_text.show()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 21,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# Initialize the performance monitor\\n\",\n",
      "    \"monitor = PerformanceMonitor()\\n\",\n",
      "    \"\\n\",\n",
      "    \"summarizer = load_chain_from_mlflow(run_id)\\n\",\n",
      "    \"\\n\",\n",
      "    \"def process_videos(video_ids):\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Process multiple videos with monitoring\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param video_ids: List of YouTube video IDs or URLs\\n\",\n",
      "    \"    :return: tuple of (list of summaries, list of metrics)\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    # if videos_ids is a string, convert it to a list\\n\",\n",
      "    \"    if isinstance(video_ids, str):\\n\",\n",
      "    \"        video_ids = [video_ids]\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Prepare input data\\n\",\n",
      "    \"    input_data = []\\n\",\n",
      "    \"    for vid in video_ids:\\n\",\n",
      "    \"        if \\\"youtube.com\\\" in vid or \\\"youtu.be\\\" in vid:\\n\",\n",
      "    \"            input_data.append(vid)\\n\",\n",
      "    \"        else:\\n\",\n",
      "    \"            input_data.append(f\\\"https://youtube.com/watch?v={vid}\\\")\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    input_series = pd.Series(input_data)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Process all videos\\n\",\n",
      "    \"    summaries = []\\n\",\n",
      "    \"    metrics_list = []\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Generate summaries with latency measurement\\n\",\n",
      "    \"    results, total_latency = monitor.measure_latency(\\n\",\n",
      "    \"        lambda: summarizer.predict(input_series)\\n\",\n",
      "    \"    )\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Calculate average latency per video\\n\",\n",
      "    \"    avg_latency = total_latency / len(video_ids)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Process each result\\n\",\n",
      "    \"    for result in results:\\n\",\n",
      "    \"        summary, transcript = result  # Unpack each result\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Measure resource usage\\n\",\n",
      "    \"        resource_usage = monitor.measure_resource_usage()\\n\",\n",
      "    \"\\n\",\n",
      "    \"        # Log metrics for each video\\n\",\n",
      "    \"        metrics = monitor.log_performance(avg_latency, summary, transcript, resource_usage)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        summaries.append(summary)\\n\",\n",
      "    \"        metrics_list.append(metrics)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return summaries, metrics_list\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 22,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"application/vnd.plotly.v1+json\": {\n",
      "       \"config\": {\n",
      "        \"plotlyServerURL\": \"https://plot.ly\"\n",
      "       },\n",
      "       \"data\": [\n",
      "        {\n",
      "         \"hovertemplate\": \"index=%{x}<br>latency=%{y}<extra></extra>\",\n",
      "         \"legendgroup\": \"\",\n",
      "         \"line\": {\n",
      "          \"color\": \"#636efa\",\n",
      "          \"dash\": \"solid\"\n",
      "         },\n",
      "         \"marker\": {\n",
      "          \"symbol\": \"circle\"\n",
      "         },\n",
      "         \"mode\": \"lines\",\n",
      "         \"name\": \"\",\n",
      "         \"orientation\": \"v\",\n",
      "         \"showlegend\": false,\n",
      "         \"type\": \"scatter\",\n",
      "         \"x\": [\n",
      "          0,\n",
      "          1,\n",
      "          2\n",
      "         ],\n",
      "         \"xaxis\": \"x\",\n",
      "         \"y\": [\n",
      "          45.083091020584106,\n",
      "          45.083091020584106,\n",
      "          45.083091020584106\n",
      "         ],\n",
      "         \"yaxis\": \"y\"\n",
      "        }\n",
      "       ],\n",
      "       \"layout\": {\n",
      "        \"legend\": {\n",
      "         \"tracegroupgap\": 0\n",
      "        },\n",
      "        \"template\": {\n",
      "         \"data\": {\n",
      "          \"bar\": [\n",
      "           {\n",
      "            \"error_x\": {\n",
      "             \"color\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"error_y\": {\n",
      "             \"color\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"marker\": {\n",
      "             \"line\": {\n",
      "              \"color\": \"#E5ECF6\",\n",
      "              \"width\": 0.5\n",
      "             },\n",
      "             \"pattern\": {\n",
      "              \"fillmode\": \"overlay\",\n",
      "              \"size\": 10,\n",
      "              \"solidity\": 0.2\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"bar\"\n",
      "           }\n",
      "          ],\n",
      "          \"barpolar\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"line\": {\n",
      "              \"color\": \"#E5ECF6\",\n",
      "              \"width\": 0.5\n",
      "             },\n",
      "             \"pattern\": {\n",
      "              \"fillmode\": \"overlay\",\n",
      "              \"size\": 10,\n",
      "              \"solidity\": 0.2\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"barpolar\"\n",
      "           }\n",
      "          ],\n",
      "          \"carpet\": [\n",
      "           {\n",
      "            \"aaxis\": {\n",
      "             \"endlinecolor\": \"#2a3f5f\",\n",
      "             \"gridcolor\": \"white\",\n",
      "             \"linecolor\": \"white\",\n",
      "             \"minorgridcolor\": \"white\",\n",
      "             \"startlinecolor\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"baxis\": {\n",
      "             \"endlinecolor\": \"#2a3f5f\",\n",
      "             \"gridcolor\": \"white\",\n",
      "             \"linecolor\": \"white\",\n",
      "             \"minorgridcolor\": \"white\",\n",
      "             \"startlinecolor\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"type\": \"carpet\"\n",
      "           }\n",
      "          ],\n",
      "          \"choropleth\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"type\": \"choropleth\"\n",
      "           }\n",
      "          ],\n",
      "          \"contour\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"contour\"\n",
      "           }\n",
      "          ],\n",
      "          \"contourcarpet\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"type\": \"contourcarpet\"\n",
      "           }\n",
      "          ],\n",
      "          \"heatmap\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"heatmap\"\n",
      "           }\n",
      "          ],\n",
      "          \"heatmapgl\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"heatmapgl\"\n",
      "           }\n",
      "          ],\n",
      "          \"histogram\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"pattern\": {\n",
      "              \"fillmode\": \"overlay\",\n",
      "              \"size\": 10,\n",
      "              \"solidity\": 0.2\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"histogram\"\n",
      "           }\n",
      "          ],\n",
      "          \"histogram2d\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"histogram2d\"\n",
      "           }\n",
      "          ],\n",
      "          \"histogram2dcontour\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"histogram2dcontour\"\n",
      "           }\n",
      "          ],\n",
      "          \"mesh3d\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"type\": \"mesh3d\"\n",
      "           }\n",
      "          ],\n",
      "          \"parcoords\": [\n",
      "           {\n",
      "            \"line\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"parcoords\"\n",
      "           }\n",
      "          ],\n",
      "          \"pie\": [\n",
      "           {\n",
      "            \"automargin\": true,\n",
      "            \"type\": \"pie\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatter\": [\n",
      "           {\n",
      "            \"fillpattern\": {\n",
      "             \"fillmode\": \"overlay\",\n",
      "             \"size\": 10,\n",
      "             \"solidity\": 0.2\n",
      "            },\n",
      "            \"type\": \"scatter\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatter3d\": [\n",
      "           {\n",
      "            \"line\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatter3d\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattercarpet\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattercarpet\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattergeo\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattergeo\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattergl\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattergl\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattermapbox\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattermapbox\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatterpolar\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatterpolar\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatterpolargl\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatterpolargl\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatterternary\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatterternary\"\n",
      "           }\n",
      "          ],\n",
      "          \"surface\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"surface\"\n",
      "           }\n",
      "          ],\n",
      "          \"table\": [\n",
      "           {\n",
      "            \"cells\": {\n",
      "             \"fill\": {\n",
      "              \"color\": \"#EBF0F8\"\n",
      "             },\n",
      "             \"line\": {\n",
      "              \"color\": \"white\"\n",
      "             }\n",
      "            },\n",
      "            \"header\": {\n",
      "             \"fill\": {\n",
      "              \"color\": \"#C8D4E3\"\n",
      "             },\n",
      "             \"line\": {\n",
      "              \"color\": \"white\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"table\"\n",
      "           }\n",
      "          ]\n",
      "         },\n",
      "         \"layout\": {\n",
      "          \"annotationdefaults\": {\n",
      "           \"arrowcolor\": \"#2a3f5f\",\n",
      "           \"arrowhead\": 0,\n",
      "           \"arrowwidth\": 1\n",
      "          },\n",
      "          \"autotypenumbers\": \"strict\",\n",
      "          \"coloraxis\": {\n",
      "           \"colorbar\": {\n",
      "            \"outlinewidth\": 0,\n",
      "            \"ticks\": \"\"\n",
      "           }\n",
      "          },\n",
      "          \"colorscale\": {\n",
      "           \"diverging\": [\n",
      "            [\n",
      "             0,\n",
      "             \"#8e0152\"\n",
      "            ],\n",
      "            [\n",
      "             0.1,\n",
      "             \"#c51b7d\"\n",
      "            ],\n",
      "            [\n",
      "             0.2,\n",
      "             \"#de77ae\"\n",
      "            ],\n",
      "            [\n",
      "             0.3,\n",
      "             \"#f1b6da\"\n",
      "            ],\n",
      "            [\n",
      "             0.4,\n",
      "             \"#fde0ef\"\n",
      "            ],\n",
      "            [\n",
      "             0.5,\n",
      "             \"#f7f7f7\"\n",
      "            ],\n",
      "            [\n",
      "             0.6,\n",
      "             \"#e6f5d0\"\n",
      "            ],\n",
      "            [\n",
      "             0.7,\n",
      "             \"#b8e186\"\n",
      "            ],\n",
      "            [\n",
      "             0.8,\n",
      "             \"#7fbc41\"\n",
      "            ],\n",
      "            [\n",
      "             0.9,\n",
      "             \"#4d9221\"\n",
      "            ],\n",
      "            [\n",
      "             1,\n",
      "             \"#276419\"\n",
      "            ]\n",
      "           ],\n",
      "           \"sequential\": [\n",
      "            [\n",
      "             0,\n",
      "             \"#0d0887\"\n",
      "            ],\n",
      "            [\n",
      "             0.1111111111111111,\n",
      "             \"#46039f\"\n",
      "            ],\n",
      "            [\n",
      "             0.2222222222222222,\n",
      "             \"#7201a8\"\n",
      "            ],\n",
      "            [\n",
      "             0.3333333333333333,\n",
      "             \"#9c179e\"\n",
      "            ],\n",
      "            [\n",
      "             0.4444444444444444,\n",
      "             \"#bd3786\"\n",
      "            ],\n",
      "            [\n",
      "             0.5555555555555556,\n",
      "             \"#d8576b\"\n",
      "            ],\n",
      "            [\n",
      "             0.6666666666666666,\n",
      "             \"#ed7953\"\n",
      "            ],\n",
      "            [\n",
      "             0.7777777777777778,\n",
      "             \"#fb9f3a\"\n",
      "            ],\n",
      "            [\n",
      "             0.8888888888888888,\n",
      "             \"#fdca26\"\n",
      "            ],\n",
      "            [\n",
      "             1,\n",
      "             \"#f0f921\"\n",
      "            ]\n",
      "           ],\n",
      "           \"sequentialminus\": [\n",
      "            [\n",
      "             0,\n",
      "             \"#0d0887\"\n",
      "            ],\n",
      "            [\n",
      "             0.1111111111111111,\n",
      "             \"#46039f\"\n",
      "            ],\n",
      "            [\n",
      "             0.2222222222222222,\n",
      "             \"#7201a8\"\n",
      "            ],\n",
      "            [\n",
      "             0.3333333333333333,\n",
      "             \"#9c179e\"\n",
      "            ],\n",
      "            [\n",
      "             0.4444444444444444,\n",
      "             \"#bd3786\"\n",
      "            ],\n",
      "            [\n",
      "             0.5555555555555556,\n",
      "             \"#d8576b\"\n",
      "            ],\n",
      "            [\n",
      "             0.6666666666666666,\n",
      "             \"#ed7953\"\n",
      "            ],\n",
      "            [\n",
      "             0.7777777777777778,\n",
      "             \"#fb9f3a\"\n",
      "            ],\n",
      "            [\n",
      "             0.8888888888888888,\n",
      "             \"#fdca26\"\n",
      "            ],\n",
      "            [\n",
      "             1,\n",
      "             \"#f0f921\"\n",
      "            ]\n",
      "           ]\n",
      "          },\n",
      "          \"colorway\": [\n",
      "           \"#636efa\",\n",
      "           \"#EF553B\",\n",
      "           \"#00cc96\",\n",
      "           \"#ab63fa\",\n",
      "           \"#FFA15A\",\n",
      "           \"#19d3f3\",\n",
      "           \"#FF6692\",\n",
      "           \"#B6E880\",\n",
      "           \"#FF97FF\",\n",
      "           \"#FECB52\"\n",
      "          ],\n",
      "          \"font\": {\n",
      "           \"color\": \"#2a3f5f\"\n",
      "          },\n",
      "          \"geo\": {\n",
      "           \"bgcolor\": \"white\",\n",
      "           \"lakecolor\": \"white\",\n",
      "           \"landcolor\": \"#E5ECF6\",\n",
      "           \"showlakes\": true,\n",
      "           \"showland\": true,\n",
      "           \"subunitcolor\": \"white\"\n",
      "          },\n",
      "          \"hoverlabel\": {\n",
      "           \"align\": \"left\"\n",
      "          },\n",
      "          \"hovermode\": \"closest\",\n",
      "          \"mapbox\": {\n",
      "           \"style\": \"light\"\n",
      "          },\n",
      "          \"paper_bgcolor\": \"white\",\n",
      "          \"plot_bgcolor\": \"#E5ECF6\",\n",
      "          \"polar\": {\n",
      "           \"angularaxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           },\n",
      "           \"bgcolor\": \"#E5ECF6\",\n",
      "           \"radialaxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           }\n",
      "          },\n",
      "          \"scene\": {\n",
      "           \"xaxis\": {\n",
      "            \"backgroundcolor\": \"#E5ECF6\",\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"gridwidth\": 2,\n",
      "            \"linecolor\": \"white\",\n",
      "            \"showbackground\": true,\n",
      "            \"ticks\": \"\",\n",
      "            \"zerolinecolor\": \"white\"\n",
      "           },\n",
      "           \"yaxis\": {\n",
      "            \"backgroundcolor\": \"#E5ECF6\",\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"gridwidth\": 2,\n",
      "            \"linecolor\": \"white\",\n",
      "            \"showbackground\": true,\n",
      "            \"ticks\": \"\",\n",
      "            \"zerolinecolor\": \"white\"\n",
      "           },\n",
      "           \"zaxis\": {\n",
      "            \"backgroundcolor\": \"#E5ECF6\",\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"gridwidth\": 2,\n",
      "            \"linecolor\": \"white\",\n",
      "            \"showbackground\": true,\n",
      "            \"ticks\": \"\",\n",
      "            \"zerolinecolor\": \"white\"\n",
      "           }\n",
      "          },\n",
      "          \"shapedefaults\": {\n",
      "           \"line\": {\n",
      "            \"color\": \"#2a3f5f\"\n",
      "           }\n",
      "          },\n",
      "          \"ternary\": {\n",
      "           \"aaxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           },\n",
      "           \"baxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           },\n",
      "           \"bgcolor\": \"#E5ECF6\",\n",
      "           \"caxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           }\n",
      "          },\n",
      "          \"title\": {\n",
      "           \"x\": 0.05\n",
      "          },\n",
      "          \"xaxis\": {\n",
      "           \"automargin\": true,\n",
      "           \"gridcolor\": \"white\",\n",
      "           \"linecolor\": \"white\",\n",
      "           \"ticks\": \"\",\n",
      "           \"title\": {\n",
      "            \"standoff\": 15\n",
      "           },\n",
      "           \"zerolinecolor\": \"white\",\n",
      "           \"zerolinewidth\": 2\n",
      "          },\n",
      "          \"yaxis\": {\n",
      "           \"automargin\": true,\n",
      "           \"gridcolor\": \"white\",\n",
      "           \"linecolor\": \"white\",\n",
      "           \"ticks\": \"\",\n",
      "           \"title\": {\n",
      "            \"standoff\": 15\n",
      "           },\n",
      "           \"zerolinecolor\": \"white\",\n",
      "           \"zerolinewidth\": 2\n",
      "          }\n",
      "         }\n",
      "        },\n",
      "        \"title\": {\n",
      "         \"text\": \"Inference Latency Over Time\"\n",
      "        },\n",
      "        \"xaxis\": {\n",
      "         \"anchor\": \"y\",\n",
      "         \"domain\": [\n",
      "          0,\n",
      "          1\n",
      "         ],\n",
      "         \"title\": {\n",
      "          \"text\": \"index\"\n",
      "         }\n",
      "        },\n",
      "        \"yaxis\": {\n",
      "         \"anchor\": \"x\",\n",
      "         \"domain\": [\n",
      "          0,\n",
      "          1\n",
      "         ],\n",
      "         \"title\": {\n",
      "          \"text\": \"latency\"\n",
      "         }\n",
      "        }\n",
      "       }\n",
      "      }\n",
      "     },\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"display_data\"\n",
      "    },\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"application/vnd.plotly.v1+json\": {\n",
      "       \"config\": {\n",
      "        \"plotlyServerURL\": \"https://plot.ly\"\n",
      "       },\n",
      "       \"data\": [\n",
      "        {\n",
      "         \"name\": \"CPU %\",\n",
      "         \"type\": \"scatter\",\n",
      "         \"y\": [\n",
      "          19.9,\n",
      "          28.8,\n",
      "          31.6\n",
      "         ]\n",
      "        },\n",
      "        {\n",
      "         \"name\": \"Memory (MB)\",\n",
      "         \"type\": \"scatter\",\n",
      "         \"y\": [\n",
      "          103.125,\n",
      "          139.75,\n",
      "          144.109375\n",
      "         ]\n",
      "        }\n",
      "       ],\n",
      "       \"layout\": {\n",
      "        \"template\": {\n",
      "         \"data\": {\n",
      "          \"bar\": [\n",
      "           {\n",
      "            \"error_x\": {\n",
      "             \"color\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"error_y\": {\n",
      "             \"color\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"marker\": {\n",
      "             \"line\": {\n",
      "              \"color\": \"#E5ECF6\",\n",
      "              \"width\": 0.5\n",
      "             },\n",
      "             \"pattern\": {\n",
      "              \"fillmode\": \"overlay\",\n",
      "              \"size\": 10,\n",
      "              \"solidity\": 0.2\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"bar\"\n",
      "           }\n",
      "          ],\n",
      "          \"barpolar\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"line\": {\n",
      "              \"color\": \"#E5ECF6\",\n",
      "              \"width\": 0.5\n",
      "             },\n",
      "             \"pattern\": {\n",
      "              \"fillmode\": \"overlay\",\n",
      "              \"size\": 10,\n",
      "              \"solidity\": 0.2\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"barpolar\"\n",
      "           }\n",
      "          ],\n",
      "          \"carpet\": [\n",
      "           {\n",
      "            \"aaxis\": {\n",
      "             \"endlinecolor\": \"#2a3f5f\",\n",
      "             \"gridcolor\": \"white\",\n",
      "             \"linecolor\": \"white\",\n",
      "             \"minorgridcolor\": \"white\",\n",
      "             \"startlinecolor\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"baxis\": {\n",
      "             \"endlinecolor\": \"#2a3f5f\",\n",
      "             \"gridcolor\": \"white\",\n",
      "             \"linecolor\": \"white\",\n",
      "             \"minorgridcolor\": \"white\",\n",
      "             \"startlinecolor\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"type\": \"carpet\"\n",
      "           }\n",
      "          ],\n",
      "          \"choropleth\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"type\": \"choropleth\"\n",
      "           }\n",
      "          ],\n",
      "          \"contour\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"contour\"\n",
      "           }\n",
      "          ],\n",
      "          \"contourcarpet\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"type\": \"contourcarpet\"\n",
      "           }\n",
      "          ],\n",
      "          \"heatmap\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"heatmap\"\n",
      "           }\n",
      "          ],\n",
      "          \"heatmapgl\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"heatmapgl\"\n",
      "           }\n",
      "          ],\n",
      "          \"histogram\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"pattern\": {\n",
      "              \"fillmode\": \"overlay\",\n",
      "              \"size\": 10,\n",
      "              \"solidity\": 0.2\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"histogram\"\n",
      "           }\n",
      "          ],\n",
      "          \"histogram2d\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"histogram2d\"\n",
      "           }\n",
      "          ],\n",
      "          \"histogram2dcontour\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"histogram2dcontour\"\n",
      "           }\n",
      "          ],\n",
      "          \"mesh3d\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"type\": \"mesh3d\"\n",
      "           }\n",
      "          ],\n",
      "          \"parcoords\": [\n",
      "           {\n",
      "            \"line\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"parcoords\"\n",
      "           }\n",
      "          ],\n",
      "          \"pie\": [\n",
      "           {\n",
      "            \"automargin\": true,\n",
      "            \"type\": \"pie\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatter\": [\n",
      "           {\n",
      "            \"fillpattern\": {\n",
      "             \"fillmode\": \"overlay\",\n",
      "             \"size\": 10,\n",
      "             \"solidity\": 0.2\n",
      "            },\n",
      "            \"type\": \"scatter\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatter3d\": [\n",
      "           {\n",
      "            \"line\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatter3d\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattercarpet\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattercarpet\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattergeo\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattergeo\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattergl\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattergl\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattermapbox\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattermapbox\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatterpolar\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatterpolar\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatterpolargl\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatterpolargl\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatterternary\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatterternary\"\n",
      "           }\n",
      "          ],\n",
      "          \"surface\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"surface\"\n",
      "           }\n",
      "          ],\n",
      "          \"table\": [\n",
      "           {\n",
      "            \"cells\": {\n",
      "             \"fill\": {\n",
      "              \"color\": \"#EBF0F8\"\n",
      "             },\n",
      "             \"line\": {\n",
      "              \"color\": \"white\"\n",
      "             }\n",
      "            },\n",
      "            \"header\": {\n",
      "             \"fill\": {\n",
      "              \"color\": \"#C8D4E3\"\n",
      "             },\n",
      "             \"line\": {\n",
      "              \"color\": \"white\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"table\"\n",
      "           }\n",
      "          ]\n",
      "         },\n",
      "         \"layout\": {\n",
      "          \"annotationdefaults\": {\n",
      "           \"arrowcolor\": \"#2a3f5f\",\n",
      "           \"arrowhead\": 0,\n",
      "           \"arrowwidth\": 1\n",
      "          },\n",
      "          \"autotypenumbers\": \"strict\",\n",
      "          \"coloraxis\": {\n",
      "           \"colorbar\": {\n",
      "            \"outlinewidth\": 0,\n",
      "            \"ticks\": \"\"\n",
      "           }\n",
      "          },\n",
      "          \"colorscale\": {\n",
      "           \"diverging\": [\n",
      "            [\n",
      "             0,\n",
      "             \"#8e0152\"\n",
      "            ],\n",
      "            [\n",
      "             0.1,\n",
      "             \"#c51b7d\"\n",
      "            ],\n",
      "            [\n",
      "             0.2,\n",
      "             \"#de77ae\"\n",
      "            ],\n",
      "            [\n",
      "             0.3,\n",
      "             \"#f1b6da\"\n",
      "            ],\n",
      "            [\n",
      "             0.4,\n",
      "             \"#fde0ef\"\n",
      "            ],\n",
      "            [\n",
      "             0.5,\n",
      "             \"#f7f7f7\"\n",
      "            ],\n",
      "            [\n",
      "             0.6,\n",
      "             \"#e6f5d0\"\n",
      "            ],\n",
      "            [\n",
      "             0.7,\n",
      "             \"#b8e186\"\n",
      "            ],\n",
      "            [\n",
      "             0.8,\n",
      "             \"#7fbc41\"\n",
      "            ],\n",
      "            [\n",
      "             0.9,\n",
      "             \"#4d9221\"\n",
      "            ],\n",
      "            [\n",
      "             1,\n",
      "             \"#276419\"\n",
      "            ]\n",
      "           ],\n",
      "           \"sequential\": [\n",
      "            [\n",
      "             0,\n",
      "             \"#0d0887\"\n",
      "            ],\n",
      "            [\n",
      "             0.1111111111111111,\n",
      "             \"#46039f\"\n",
      "            ],\n",
      "            [\n",
      "             0.2222222222222222,\n",
      "             \"#7201a8\"\n",
      "            ],\n",
      "            [\n",
      "             0.3333333333333333,\n",
      "             \"#9c179e\"\n",
      "            ],\n",
      "            [\n",
      "             0.4444444444444444,\n",
      "             \"#bd3786\"\n",
      "            ],\n",
      "            [\n",
      "             0.5555555555555556,\n",
      "             \"#d8576b\"\n",
      "            ],\n",
      "            [\n",
      "             0.6666666666666666,\n",
      "             \"#ed7953\"\n",
      "            ],\n",
      "            [\n",
      "             0.7777777777777778,\n",
      "             \"#fb9f3a\"\n",
      "            ],\n",
      "            [\n",
      "             0.8888888888888888,\n",
      "             \"#fdca26\"\n",
      "            ],\n",
      "            [\n",
      "             1,\n",
      "             \"#f0f921\"\n",
      "            ]\n",
      "           ],\n",
      "           \"sequentialminus\": [\n",
      "            [\n",
      "             0,\n",
      "             \"#0d0887\"\n",
      "            ],\n",
      "            [\n",
      "             0.1111111111111111,\n",
      "             \"#46039f\"\n",
      "            ],\n",
      "            [\n",
      "             0.2222222222222222,\n",
      "             \"#7201a8\"\n",
      "            ],\n",
      "            [\n",
      "             0.3333333333333333,\n",
      "             \"#9c179e\"\n",
      "            ],\n",
      "            [\n",
      "             0.4444444444444444,\n",
      "             \"#bd3786\"\n",
      "            ],\n",
      "            [\n",
      "             0.5555555555555556,\n",
      "             \"#d8576b\"\n",
      "            ],\n",
      "            [\n",
      "             0.6666666666666666,\n",
      "             \"#ed7953\"\n",
      "            ],\n",
      "            [\n",
      "             0.7777777777777778,\n",
      "             \"#fb9f3a\"\n",
      "            ],\n",
      "            [\n",
      "             0.8888888888888888,\n",
      "             \"#fdca26\"\n",
      "            ],\n",
      "            [\n",
      "             1,\n",
      "             \"#f0f921\"\n",
      "            ]\n",
      "           ]\n",
      "          },\n",
      "          \"colorway\": [\n",
      "           \"#636efa\",\n",
      "           \"#EF553B\",\n",
      "           \"#00cc96\",\n",
      "           \"#ab63fa\",\n",
      "           \"#FFA15A\",\n",
      "           \"#19d3f3\",\n",
      "           \"#FF6692\",\n",
      "           \"#B6E880\",\n",
      "           \"#FF97FF\",\n",
      "           \"#FECB52\"\n",
      "          ],\n",
      "          \"font\": {\n",
      "           \"color\": \"#2a3f5f\"\n",
      "          },\n",
      "          \"geo\": {\n",
      "           \"bgcolor\": \"white\",\n",
      "           \"lakecolor\": \"white\",\n",
      "           \"landcolor\": \"#E5ECF6\",\n",
      "           \"showlakes\": true,\n",
      "           \"showland\": true,\n",
      "           \"subunitcolor\": \"white\"\n",
      "          },\n",
      "          \"hoverlabel\": {\n",
      "           \"align\": \"left\"\n",
      "          },\n",
      "          \"hovermode\": \"closest\",\n",
      "          \"mapbox\": {\n",
      "           \"style\": \"light\"\n",
      "          },\n",
      "          \"paper_bgcolor\": \"white\",\n",
      "          \"plot_bgcolor\": \"#E5ECF6\",\n",
      "          \"polar\": {\n",
      "           \"angularaxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           },\n",
      "           \"bgcolor\": \"#E5ECF6\",\n",
      "           \"radialaxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           }\n",
      "          },\n",
      "          \"scene\": {\n",
      "           \"xaxis\": {\n",
      "            \"backgroundcolor\": \"#E5ECF6\",\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"gridwidth\": 2,\n",
      "            \"linecolor\": \"white\",\n",
      "            \"showbackground\": true,\n",
      "            \"ticks\": \"\",\n",
      "            \"zerolinecolor\": \"white\"\n",
      "           },\n",
      "           \"yaxis\": {\n",
      "            \"backgroundcolor\": \"#E5ECF6\",\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"gridwidth\": 2,\n",
      "            \"linecolor\": \"white\",\n",
      "            \"showbackground\": true,\n",
      "            \"ticks\": \"\",\n",
      "            \"zerolinecolor\": \"white\"\n",
      "           },\n",
      "           \"zaxis\": {\n",
      "            \"backgroundcolor\": \"#E5ECF6\",\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"gridwidth\": 2,\n",
      "            \"linecolor\": \"white\",\n",
      "            \"showbackground\": true,\n",
      "            \"ticks\": \"\",\n",
      "            \"zerolinecolor\": \"white\"\n",
      "           }\n",
      "          },\n",
      "          \"shapedefaults\": {\n",
      "           \"line\": {\n",
      "            \"color\": \"#2a3f5f\"\n",
      "           }\n",
      "          },\n",
      "          \"ternary\": {\n",
      "           \"aaxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           },\n",
      "           \"baxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           },\n",
      "           \"bgcolor\": \"#E5ECF6\",\n",
      "           \"caxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           }\n",
      "          },\n",
      "          \"title\": {\n",
      "           \"x\": 0.05\n",
      "          },\n",
      "          \"xaxis\": {\n",
      "           \"automargin\": true,\n",
      "           \"gridcolor\": \"white\",\n",
      "           \"linecolor\": \"white\",\n",
      "           \"ticks\": \"\",\n",
      "           \"title\": {\n",
      "            \"standoff\": 15\n",
      "           },\n",
      "           \"zerolinecolor\": \"white\",\n",
      "           \"zerolinewidth\": 2\n",
      "          },\n",
      "          \"yaxis\": {\n",
      "           \"automargin\": true,\n",
      "           \"gridcolor\": \"white\",\n",
      "           \"linecolor\": \"white\",\n",
      "           \"ticks\": \"\",\n",
      "           \"title\": {\n",
      "            \"standoff\": 15\n",
      "           },\n",
      "           \"zerolinecolor\": \"white\",\n",
      "           \"zerolinewidth\": 2\n",
      "          }\n",
      "         }\n",
      "        },\n",
      "        \"title\": {\n",
      "         \"text\": \"Resource Usage Over Time\"\n",
      "        }\n",
      "       }\n",
      "      }\n",
      "     },\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"display_data\"\n",
      "    },\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"application/vnd.plotly.v1+json\": {\n",
      "       \"config\": {\n",
      "        \"plotlyServerURL\": \"https://plot.ly\"\n",
      "       },\n",
      "       \"data\": [\n",
      "        {\n",
      "         \"name\": \"summary_length\",\n",
      "         \"type\": \"scatter\",\n",
      "         \"y\": [\n",
      "          28,\n",
      "          40,\n",
      "          305\n",
      "         ]\n",
      "        },\n",
      "        {\n",
      "         \"name\": \"transcript_length\",\n",
      "         \"type\": \"scatter\",\n",
      "         \"y\": [\n",
      "          1819,\n",
      "          2576,\n",
      "          1936\n",
      "         ]\n",
      "        },\n",
      "        {\n",
      "         \"name\": \"reduction_percentage\",\n",
      "         \"type\": \"scatter\",\n",
      "         \"y\": [\n",
      "          98.46069268829028,\n",
      "          98.4472049689441,\n",
      "          84.24586776859503\n",
      "         ]\n",
      "        }\n",
      "       ],\n",
      "       \"layout\": {\n",
      "        \"template\": {\n",
      "         \"data\": {\n",
      "          \"bar\": [\n",
      "           {\n",
      "            \"error_x\": {\n",
      "             \"color\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"error_y\": {\n",
      "             \"color\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"marker\": {\n",
      "             \"line\": {\n",
      "              \"color\": \"#E5ECF6\",\n",
      "              \"width\": 0.5\n",
      "             },\n",
      "             \"pattern\": {\n",
      "              \"fillmode\": \"overlay\",\n",
      "              \"size\": 10,\n",
      "              \"solidity\": 0.2\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"bar\"\n",
      "           }\n",
      "          ],\n",
      "          \"barpolar\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"line\": {\n",
      "              \"color\": \"#E5ECF6\",\n",
      "              \"width\": 0.5\n",
      "             },\n",
      "             \"pattern\": {\n",
      "              \"fillmode\": \"overlay\",\n",
      "              \"size\": 10,\n",
      "              \"solidity\": 0.2\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"barpolar\"\n",
      "           }\n",
      "          ],\n",
      "          \"carpet\": [\n",
      "           {\n",
      "            \"aaxis\": {\n",
      "             \"endlinecolor\": \"#2a3f5f\",\n",
      "             \"gridcolor\": \"white\",\n",
      "             \"linecolor\": \"white\",\n",
      "             \"minorgridcolor\": \"white\",\n",
      "             \"startlinecolor\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"baxis\": {\n",
      "             \"endlinecolor\": \"#2a3f5f\",\n",
      "             \"gridcolor\": \"white\",\n",
      "             \"linecolor\": \"white\",\n",
      "             \"minorgridcolor\": \"white\",\n",
      "             \"startlinecolor\": \"#2a3f5f\"\n",
      "            },\n",
      "            \"type\": \"carpet\"\n",
      "           }\n",
      "          ],\n",
      "          \"choropleth\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"type\": \"choropleth\"\n",
      "           }\n",
      "          ],\n",
      "          \"contour\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"contour\"\n",
      "           }\n",
      "          ],\n",
      "          \"contourcarpet\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"type\": \"contourcarpet\"\n",
      "           }\n",
      "          ],\n",
      "          \"heatmap\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"heatmap\"\n",
      "           }\n",
      "          ],\n",
      "          \"heatmapgl\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"heatmapgl\"\n",
      "           }\n",
      "          ],\n",
      "          \"histogram\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"pattern\": {\n",
      "              \"fillmode\": \"overlay\",\n",
      "              \"size\": 10,\n",
      "              \"solidity\": 0.2\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"histogram\"\n",
      "           }\n",
      "          ],\n",
      "          \"histogram2d\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"histogram2d\"\n",
      "           }\n",
      "          ],\n",
      "          \"histogram2dcontour\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"histogram2dcontour\"\n",
      "           }\n",
      "          ],\n",
      "          \"mesh3d\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"type\": \"mesh3d\"\n",
      "           }\n",
      "          ],\n",
      "          \"parcoords\": [\n",
      "           {\n",
      "            \"line\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"parcoords\"\n",
      "           }\n",
      "          ],\n",
      "          \"pie\": [\n",
      "           {\n",
      "            \"automargin\": true,\n",
      "            \"type\": \"pie\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatter\": [\n",
      "           {\n",
      "            \"fillpattern\": {\n",
      "             \"fillmode\": \"overlay\",\n",
      "             \"size\": 10,\n",
      "             \"solidity\": 0.2\n",
      "            },\n",
      "            \"type\": \"scatter\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatter3d\": [\n",
      "           {\n",
      "            \"line\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatter3d\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattercarpet\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattercarpet\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattergeo\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattergeo\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattergl\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattergl\"\n",
      "           }\n",
      "          ],\n",
      "          \"scattermapbox\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scattermapbox\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatterpolar\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatterpolar\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatterpolargl\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatterpolargl\"\n",
      "           }\n",
      "          ],\n",
      "          \"scatterternary\": [\n",
      "           {\n",
      "            \"marker\": {\n",
      "             \"colorbar\": {\n",
      "              \"outlinewidth\": 0,\n",
      "              \"ticks\": \"\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"scatterternary\"\n",
      "           }\n",
      "          ],\n",
      "          \"surface\": [\n",
      "           {\n",
      "            \"colorbar\": {\n",
      "             \"outlinewidth\": 0,\n",
      "             \"ticks\": \"\"\n",
      "            },\n",
      "            \"colorscale\": [\n",
      "             [\n",
      "              0,\n",
      "              \"#0d0887\"\n",
      "             ],\n",
      "             [\n",
      "              0.1111111111111111,\n",
      "              \"#46039f\"\n",
      "             ],\n",
      "             [\n",
      "              0.2222222222222222,\n",
      "              \"#7201a8\"\n",
      "             ],\n",
      "             [\n",
      "              0.3333333333333333,\n",
      "              \"#9c179e\"\n",
      "             ],\n",
      "             [\n",
      "              0.4444444444444444,\n",
      "              \"#bd3786\"\n",
      "             ],\n",
      "             [\n",
      "              0.5555555555555556,\n",
      "              \"#d8576b\"\n",
      "             ],\n",
      "             [\n",
      "              0.6666666666666666,\n",
      "              \"#ed7953\"\n",
      "             ],\n",
      "             [\n",
      "              0.7777777777777778,\n",
      "              \"#fb9f3a\"\n",
      "             ],\n",
      "             [\n",
      "              0.8888888888888888,\n",
      "              \"#fdca26\"\n",
      "             ],\n",
      "             [\n",
      "              1,\n",
      "              \"#f0f921\"\n",
      "             ]\n",
      "            ],\n",
      "            \"type\": \"surface\"\n",
      "           }\n",
      "          ],\n",
      "          \"table\": [\n",
      "           {\n",
      "            \"cells\": {\n",
      "             \"fill\": {\n",
      "              \"color\": \"#EBF0F8\"\n",
      "             },\n",
      "             \"line\": {\n",
      "              \"color\": \"white\"\n",
      "             }\n",
      "            },\n",
      "            \"header\": {\n",
      "             \"fill\": {\n",
      "              \"color\": \"#C8D4E3\"\n",
      "             },\n",
      "             \"line\": {\n",
      "              \"color\": \"white\"\n",
      "             }\n",
      "            },\n",
      "            \"type\": \"table\"\n",
      "           }\n",
      "          ]\n",
      "         },\n",
      "         \"layout\": {\n",
      "          \"annotationdefaults\": {\n",
      "           \"arrowcolor\": \"#2a3f5f\",\n",
      "           \"arrowhead\": 0,\n",
      "           \"arrowwidth\": 1\n",
      "          },\n",
      "          \"autotypenumbers\": \"strict\",\n",
      "          \"coloraxis\": {\n",
      "           \"colorbar\": {\n",
      "            \"outlinewidth\": 0,\n",
      "            \"ticks\": \"\"\n",
      "           }\n",
      "          },\n",
      "          \"colorscale\": {\n",
      "           \"diverging\": [\n",
      "            [\n",
      "             0,\n",
      "             \"#8e0152\"\n",
      "            ],\n",
      "            [\n",
      "             0.1,\n",
      "             \"#c51b7d\"\n",
      "            ],\n",
      "            [\n",
      "             0.2,\n",
      "             \"#de77ae\"\n",
      "            ],\n",
      "            [\n",
      "             0.3,\n",
      "             \"#f1b6da\"\n",
      "            ],\n",
      "            [\n",
      "             0.4,\n",
      "             \"#fde0ef\"\n",
      "            ],\n",
      "            [\n",
      "             0.5,\n",
      "             \"#f7f7f7\"\n",
      "            ],\n",
      "            [\n",
      "             0.6,\n",
      "             \"#e6f5d0\"\n",
      "            ],\n",
      "            [\n",
      "             0.7,\n",
      "             \"#b8e186\"\n",
      "            ],\n",
      "            [\n",
      "             0.8,\n",
      "             \"#7fbc41\"\n",
      "            ],\n",
      "            [\n",
      "             0.9,\n",
      "             \"#4d9221\"\n",
      "            ],\n",
      "            [\n",
      "             1,\n",
      "             \"#276419\"\n",
      "            ]\n",
      "           ],\n",
      "           \"sequential\": [\n",
      "            [\n",
      "             0,\n",
      "             \"#0d0887\"\n",
      "            ],\n",
      "            [\n",
      "             0.1111111111111111,\n",
      "             \"#46039f\"\n",
      "            ],\n",
      "            [\n",
      "             0.2222222222222222,\n",
      "             \"#7201a8\"\n",
      "            ],\n",
      "            [\n",
      "             0.3333333333333333,\n",
      "             \"#9c179e\"\n",
      "            ],\n",
      "            [\n",
      "             0.4444444444444444,\n",
      "             \"#bd3786\"\n",
      "            ],\n",
      "            [\n",
      "             0.5555555555555556,\n",
      "             \"#d8576b\"\n",
      "            ],\n",
      "            [\n",
      "             0.6666666666666666,\n",
      "             \"#ed7953\"\n",
      "            ],\n",
      "            [\n",
      "             0.7777777777777778,\n",
      "             \"#fb9f3a\"\n",
      "            ],\n",
      "            [\n",
      "             0.8888888888888888,\n",
      "             \"#fdca26\"\n",
      "            ],\n",
      "            [\n",
      "             1,\n",
      "             \"#f0f921\"\n",
      "            ]\n",
      "           ],\n",
      "           \"sequentialminus\": [\n",
      "            [\n",
      "             0,\n",
      "             \"#0d0887\"\n",
      "            ],\n",
      "            [\n",
      "             0.1111111111111111,\n",
      "             \"#46039f\"\n",
      "            ],\n",
      "            [\n",
      "             0.2222222222222222,\n",
      "             \"#7201a8\"\n",
      "            ],\n",
      "            [\n",
      "             0.3333333333333333,\n",
      "             \"#9c179e\"\n",
      "            ],\n",
      "            [\n",
      "             0.4444444444444444,\n",
      "             \"#bd3786\"\n",
      "            ],\n",
      "            [\n",
      "             0.5555555555555556,\n",
      "             \"#d8576b\"\n",
      "            ],\n",
      "            [\n",
      "             0.6666666666666666,\n",
      "             \"#ed7953\"\n",
      "            ],\n",
      "            [\n",
      "             0.7777777777777778,\n",
      "             \"#fb9f3a\"\n",
      "            ],\n",
      "            [\n",
      "             0.8888888888888888,\n",
      "             \"#fdca26\"\n",
      "            ],\n",
      "            [\n",
      "             1,\n",
      "             \"#f0f921\"\n",
      "            ]\n",
      "           ]\n",
      "          },\n",
      "          \"colorway\": [\n",
      "           \"#636efa\",\n",
      "           \"#EF553B\",\n",
      "           \"#00cc96\",\n",
      "           \"#ab63fa\",\n",
      "           \"#FFA15A\",\n",
      "           \"#19d3f3\",\n",
      "           \"#FF6692\",\n",
      "           \"#B6E880\",\n",
      "           \"#FF97FF\",\n",
      "           \"#FECB52\"\n",
      "          ],\n",
      "          \"font\": {\n",
      "           \"color\": \"#2a3f5f\"\n",
      "          },\n",
      "          \"geo\": {\n",
      "           \"bgcolor\": \"white\",\n",
      "           \"lakecolor\": \"white\",\n",
      "           \"landcolor\": \"#E5ECF6\",\n",
      "           \"showlakes\": true,\n",
      "           \"showland\": true,\n",
      "           \"subunitcolor\": \"white\"\n",
      "          },\n",
      "          \"hoverlabel\": {\n",
      "           \"align\": \"left\"\n",
      "          },\n",
      "          \"hovermode\": \"closest\",\n",
      "          \"mapbox\": {\n",
      "           \"style\": \"light\"\n",
      "          },\n",
      "          \"paper_bgcolor\": \"white\",\n",
      "          \"plot_bgcolor\": \"#E5ECF6\",\n",
      "          \"polar\": {\n",
      "           \"angularaxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           },\n",
      "           \"bgcolor\": \"#E5ECF6\",\n",
      "           \"radialaxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           }\n",
      "          },\n",
      "          \"scene\": {\n",
      "           \"xaxis\": {\n",
      "            \"backgroundcolor\": \"#E5ECF6\",\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"gridwidth\": 2,\n",
      "            \"linecolor\": \"white\",\n",
      "            \"showbackground\": true,\n",
      "            \"ticks\": \"\",\n",
      "            \"zerolinecolor\": \"white\"\n",
      "           },\n",
      "           \"yaxis\": {\n",
      "            \"backgroundcolor\": \"#E5ECF6\",\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"gridwidth\": 2,\n",
      "            \"linecolor\": \"white\",\n",
      "            \"showbackground\": true,\n",
      "            \"ticks\": \"\",\n",
      "            \"zerolinecolor\": \"white\"\n",
      "           },\n",
      "           \"zaxis\": {\n",
      "            \"backgroundcolor\": \"#E5ECF6\",\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"gridwidth\": 2,\n",
      "            \"linecolor\": \"white\",\n",
      "            \"showbackground\": true,\n",
      "            \"ticks\": \"\",\n",
      "            \"zerolinecolor\": \"white\"\n",
      "           }\n",
      "          },\n",
      "          \"shapedefaults\": {\n",
      "           \"line\": {\n",
      "            \"color\": \"#2a3f5f\"\n",
      "           }\n",
      "          },\n",
      "          \"ternary\": {\n",
      "           \"aaxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           },\n",
      "           \"baxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           },\n",
      "           \"bgcolor\": \"#E5ECF6\",\n",
      "           \"caxis\": {\n",
      "            \"gridcolor\": \"white\",\n",
      "            \"linecolor\": \"white\",\n",
      "            \"ticks\": \"\"\n",
      "           }\n",
      "          },\n",
      "          \"title\": {\n",
      "           \"x\": 0.05\n",
      "          },\n",
      "          \"xaxis\": {\n",
      "           \"automargin\": true,\n",
      "           \"gridcolor\": \"white\",\n",
      "           \"linecolor\": \"white\",\n",
      "           \"ticks\": \"\",\n",
      "           \"title\": {\n",
      "            \"standoff\": 15\n",
      "           },\n",
      "           \"zerolinecolor\": \"white\",\n",
      "           \"zerolinewidth\": 2\n",
      "          },\n",
      "          \"yaxis\": {\n",
      "           \"automargin\": true,\n",
      "           \"gridcolor\": \"white\",\n",
      "           \"linecolor\": \"white\",\n",
      "           \"ticks\": \"\",\n",
      "           \"title\": {\n",
      "            \"standoff\": 15\n",
      "           },\n",
      "           \"zerolinecolor\": \"white\",\n",
      "           \"zerolinewidth\": 2\n",
      "          }\n",
      "         }\n",
      "        },\n",
      "        \"title\": {\n",
      "         \"text\": \"Text Metrics Over Time\"\n",
      "        }\n",
      "       }\n",
      "      }\n",
      "     },\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"display_data\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"videos_ids = [\\\"https://www.youtube.com/watch?v=v2DGDwOjdIk&pp=ygUMZXBtIGNvbG9tYmlh\\\",\\n\",\n",
      "    \"              \\\"https://www.youtube.com/watch?v=mACcTs5YsMM&pp=ygUMZXBtIGNvbG9tYmlh\\\",\\n\",\n",
      "    \"              \\\"https://www.youtube.com/watch?v=2LU9KKnI4Do&pp=ygUMZXBtIGNvbG9tYmlh\\\"]\\n\",\n",
      "    \"\\n\",\n",
      "    \"summary, metrics = process_videos(videos_ids)\\n\",\n",
      "    \"plot_metrics_over_time(monitor.metrics_history)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Evaluate the model\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Evaluation Pipeline\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 23,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"[nltk_data] Downloading package punkt to /Users/ganga/nltk_data...\\n\",\n",
      "      \"[nltk_data]   Package punkt is already up-to-date!\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"True\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 23,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"from nltk.translate.bleu_score import sentence_bleu\\n\",\n",
      "    \"import nltk\\n\",\n",
      "    \"# Download required NLTK data\\n\",\n",
      "    \"nltk.download('punkt')\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 24,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def prepare_test_data() -> List[Dict[str, str]]:\\n\",\n",
      "    \"    \\\"\\\"\\\"Prepare test data with YouTube videos and reference summaries\\\"\\\"\\\"\\n\",\n",
      "    \"    # Replace with your actual test data\\n\",\n",
      "    \"    return [\\n\",\n",
      "    \"        {\\n\",\n",
      "    \"            \\\"video_url\\\": \\\"https://www.youtube.com/watch?v=v2DGDwOjdIk&pp=ygUMZXBtIGNvbG9tYmlh\\\",\\n\",\n",
      "    \"            \\\"reference_summary\\\": \\\"This source is a transcript of a video detailing the history of Empresas Públicas de Medellín (EPM), a public service company in Medellín, Colombia. It highlights the pivotal moment when Medellín was first illuminated by electric light in 1898, a time when gas lamps were the norm, and emphasizes the impact of this innovation on the city and its residents. The text also emphasizes the importance of EPM’s continued service in bringing electricity to remote areas in Colombia even in the 21st century, demonstrating the company's commitment to providing essential services to all. The transcript showcases the evolution of EPM from its origins in private companies to its current status as a public utility, highlighting its historical significance and its ongoing role in improving the lives of people in Medellín and beyond.\\\"\\n\",\n",
      "    \"        },\\n\",\n",
      "    \"        {\\n\",\n",
      "    \"            \\\"video_url\\\": \\\"https://www.youtube.com/watch?v=mACcTs5YsMM&pp=ygUMZXBtIGNvbG9tYmlh\\\",\\n\",\n",
      "    \"            \\\"reference_summary\\\": \\\"This source is a transcript of a radio interview with John Maya, the manager of Empresas Públicas de Medellín (EPM), a public utility company in Colombia. The interview focuses on the financial difficulties faced by Afinia, a subsidiary of EPM that provides electricity to the Colombian Caribbean coast. Maya explains that Afinia's problems stem from a combination of factors, including a lack of government subsidies, delayed payments for a tariff option, and a rise in energy losses due to increased consumption and unpaid bills. He asserts that the root of the problem lies not with Afinia's management, but with the high cost of electricity in the region, which is driven by a combination of factors including high electricity generation costs and energy losses. Maya proposes a solution involving the government taking over a portion of the costs, but expresses concern about the slow pace of progress and the potential for the government to intervene and permanently take control of Afinia, a scenario he considers problematic. He also criticizes the previous administration's decision to replace Afinia's experienced manager with someone less qualified, a move that negatively impacted the company's performance. Overall, the interview provides insight into the complex financial and operational challenges faced by Afinia and the broader electricity sector in the Colombian Caribbean coast, highlighting the role of government policy, energy market dynamics, and internal management in shaping the current situation.\\\"\\n\",\n",
      "    \"        },\\n\",\n",
      "    \"        {\\n\",\n",
      "    \"            \\\"video_url\\\": \\\"https://www.youtube.com/watch?v=2LU9KKnI4Do&pp=ygUMZXBtIGNvbG9tYmlh\\\",\\n\",\n",
      "    \"            \\\"reference_summary\\\": \\\"This excerpt is a transcript of a radio interview with Federico Gutiérrez, the mayor of Medellín, Colombia. The interview focuses on a looming crisis in Colombia’s natural gas supply, with Gutiérrez warning of potential rationing and price increases due to a nationwide shortage. He emphasizes the urgency of the situation, noting that existing supply contracts are expiring soon and that there are insufficient offers to meet projected demand. Gutiérrez argues that the government's energy policies have contributed to this crisis by neglecting exploration and exploitation. He also criticizes President Petro for using inflammatory language to describe a police intervention that involved removing an individual who was allegedly exposing himself to children, characterizing it as an instance of fascism. Gutiérrez contrasts this with his own focus on governance and addressing the city's pressing needs.\\\"\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    ]\\n\",\n",
      "    \"\\n\",\n",
      "    \"test_data = prepare_test_data()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 25,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"import re\\n\",\n",
      "    \"\\n\",\n",
      "    \"def evaluate_transcript_with_llm(transcript: str, predicted_summary: str, reference_summary: str) -> str:\\n\",\n",
      "    \"    \\\"\\\"\\\"Evaluate a transcript with a LLM\\\"\\\"\\\"\\n\",\n",
      "    \"    if IS_DATABRICKS:\\n\",\n",
      "    \"            groq_api_key = dbutils.secrets.get(scope=\\\"your-scope\\\", key=\\\"groq-api-key\\\")\\n\",\n",
      "    \"    else:\\n\",\n",
      "    \"        groq_api_key = os.getenv('GROQ_API_KEY')\\n\",\n",
      "    \"    client = groq.Groq(api_key=groq_api_key)\\n\",\n",
      "    \"    prompt_template = \\\"\\\"\\\"\\n\",\n",
      "    \"    You are a professional editor, give me a score for the following summary based on the reference summary:\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    transcript: {transcript}\\n\",\n",
      "    \"    reference summary: {reference_summary}\\n\",\n",
      "    \"    predicted summary: {predicted_summary}\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    give me a score between 0 and 100 for the predicted summary\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    prompt = prompt_template.format(transcript=transcript, predicted_summary=predicted_summary, reference_summary=reference_summary)\\n\",\n",
      "    \"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        completion = client.chat.completions.create(\\n\",\n",
      "    \"            model=\\\"llama-3.2-90b-vision-preview\\\",\\n\",\n",
      "    \"            messages=[\\n\",\n",
      "    \"                {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
      "    \"            ],\\n\",\n",
      "    \"            temperature=0.3,\\n\",\n",
      "    \"            max_tokens=2048\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"        result = completion.choices[0].message.content\\n\",\n",
      "    \"        # extract number from the result using regex\\n\",\n",
      "    \"        return int(re.search(r'\\\\d+', result).group())\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error in summarization: {e}\\\")\\n\",\n",
      "    \"        return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"def calculate_metrics(transcript: str, predicted_summary: str, reference_summary: str) -> Dict[str, float]:\\n\",\n",
      "    \"    \\\"\\\"\\\"Calculate various evaluation metrics\\\"\\\"\\\"\\n\",\n",
      "    \"    # ROUGE scores\\n\",\n",
      "    \"    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\\n\",\n",
      "    \"    rouge_scores = scorer.score(reference_summary, predicted_summary)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # BLEU score\\n\",\n",
      "    \"    reference = [reference_summary.split()]\\n\",\n",
      "    \"    candidate = predicted_summary.split()\\n\",\n",
      "    \"    bleu = sentence_bleu(reference, candidate)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Summary length metrics\\n\",\n",
      "    \"    pred_length = len(predicted_summary.split())\\n\",\n",
      "    \"    ref_length = len(reference_summary.split())\\n\",\n",
      "    \"    length_ratio = pred_length / ref_length if ref_length > 0 else 0\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Evaluation with LLM\\n\",\n",
      "    \"    score_llm = evaluate_transcript_with_llm(transcript, predicted_summary, reference_summary)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return {\\n\",\n",
      "    \"        'rouge1_precision': rouge_scores['rouge1'].precision,\\n\",\n",
      "    \"        'rouge1_recall': rouge_scores['rouge1'].recall,\\n\",\n",
      "    \"        'rouge1_f1': rouge_scores['rouge1'].fmeasure,\\n\",\n",
      "    \"        'rouge2_f1': rouge_scores['rouge2'].fmeasure,\\n\",\n",
      "    \"        'rougeL_f1': rouge_scores['rougeL'].fmeasure,\\n\",\n",
      "    \"        'bleu_score': bleu,\\n\",\n",
      "    \"        'summary_length_ratio': length_ratio,\\n\",\n",
      "    \"        'predicted_length': pred_length,\\n\",\n",
      "    \"        'reference_length': ref_length,\\n\",\n",
      "    \"        'llm_score': score_llm\\n\",\n",
      "    \"    }\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 26,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def create_and_log_visualizations(metrics_list: List[Dict[str, float]]):\\n\",\n",
      "    \"    \\\"\\\"\\\"Create and log visualizations to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    # Convert metrics to DataFrame\\n\",\n",
      "    \"    df = pd.DataFrame(metrics_list)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # ROUGE scores comparison\\n\",\n",
      "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
      "    \"    rouge_metrics = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']\\n\",\n",
      "    \"    df[rouge_metrics].mean().plot(kind='bar')\\n\",\n",
      "    \"    plt.title('Average ROUGE Scores')\\n\",\n",
      "    \"    plt.ylabel('Score')\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('rouge_scores.png')\\n\",\n",
      "    \"    mlflow.log_artifact('rouge_scores.png')\\n\",\n",
      "    \"    plt.close()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Summary length analysis\\n\",\n",
      "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
      "    \"    plt.scatter(df['reference_length'], df['predicted_length'])\\n\",\n",
      "    \"    plt.plot([0, max(df['reference_length'])], [0, max(df['reference_length'])], '--', color='red')\\n\",\n",
      "    \"    plt.xlabel('Reference Summary Length')\\n\",\n",
      "    \"    plt.ylabel('Predicted Summary Length')\\n\",\n",
      "    \"    plt.title('Summary Length Comparison')\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('length_comparison.png')\\n\",\n",
      "    \"    mlflow.log_artifact('length_comparison.png')\\n\",\n",
      "    \"    plt.close()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Metrics distribution\\n\",\n",
      "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
      "    \"    metrics_to_plot = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1', 'bleu_score']\\n\",\n",
      "    \"    df[metrics_to_plot].boxplot()\\n\",\n",
      "    \"    plt.title('Distribution of Evaluation Metrics')\\n\",\n",
      "    \"    plt.ylabel('Score')\\n\",\n",
      "    \"    plt.xticks(rotation=45)\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('metrics_distribution.png')\\n\",\n",
      "    \"    mlflow.log_artifact('metrics_distribution.png')\\n\",\n",
      "    \"    plt.close()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 27,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def evaluate_model_with_mlflow(model, test_data: List[Dict[str, str]]):\\n\",\n",
      "    \"    \\\"\\\"\\\"Evaluate model and log results to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    mlflow.set_experiment(\\\"youtube-summarizer-evaluation\\\")\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    with mlflow.start_run(run_name=\\\"model_evaluation\\\") as run:\\n\",\n",
      "    \"        all_metrics = []\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log model parameters if available\\n\",\n",
      "    \"        model_params = model.get_config() if hasattr(model, 'get_config') else {}\\n\",\n",
      "    \"        mlflow.log_params(model_params)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Evaluate each test example\\n\",\n",
      "    \"        for i, example in enumerate(test_data):\\n\",\n",
      "    \"            try:\\n\",\n",
      "    \"                # Generate summary using predict method\\n\",\n",
      "    \"                input_data = pd.Series([example['video_url']])\\n\",\n",
      "    \"                result = model.predict(input_data)[0]  # Get first result\\n\",\n",
      "    \"                \\n\",\n",
      "    \"                # Check the type of result and handle accordingly\\n\",\n",
      "    \"                if isinstance(result, tuple):\\n\",\n",
      "    \"                    summary, transcript = result\\n\",\n",
      "    \"                elif isinstance(result, str):\\n\",\n",
      "    \"                    summary = result\\n\",\n",
      "    \"                    transcript = \\\"Transcript not available\\\"  # fallback\\n\",\n",
      "    \"                else:\\n\",\n",
      "    \"                    print(f\\\"Unexpected result type: {type(result)}\\\")\\n\",\n",
      "    \"                    continue\\n\",\n",
      "    \"                \\n\",\n",
      "    \"                # Calculate metrics\\n\",\n",
      "    \"                metrics = calculate_metrics(transcript, summary, example['reference_summary'])\\n\",\n",
      "    \"                all_metrics.append(metrics)\\n\",\n",
      "    \"                \\n\",\n",
      "    \"                # Log metrics for each example\\n\",\n",
      "    \"                for metric_name, value in metrics.items():\\n\",\n",
      "    \"                    mlflow.log_metric(f\\\"example_{i}_{metric_name}\\\", value)\\n\",\n",
      "    \"                \\n\",\n",
      "    \"                # Log summaries as artifacts\\n\",\n",
      "    \"                example_dir = f\\\"example_{i}\\\"\\n\",\n",
      "    \"                os.makedirs(example_dir, exist_ok=True)\\n\",\n",
      "    \"                \\n\",\n",
      "    \"                with open(f\\\"{example_dir}/predicted_summary.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"                    f.write(summary)\\n\",\n",
      "    \"                with open(f\\\"{example_dir}/reference_summary.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"                    f.write(example['reference_summary'])\\n\",\n",
      "    \"                \\n\",\n",
      "    \"                mlflow.log_artifacts(example_dir)\\n\",\n",
      "    \"                \\n\",\n",
      "    \"            except Exception as e:\\n\",\n",
      "    \"                print(f\\\"Error processing example {i}: {str(e)}\\\")\\n\",\n",
      "    \"                continue\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        if not all_metrics:\\n\",\n",
      "    \"            print(\\\"No successful evaluations completed\\\")\\n\",\n",
      "    \"            return None, None\\n\",\n",
      "    \"            \\n\",\n",
      "    \"        # Calculate and log average metrics\\n\",\n",
      "    \"        avg_metrics = {}\\n\",\n",
      "    \"        for metric in all_metrics[0].keys():\\n\",\n",
      "    \"            avg_value = np.mean([m[metric] for m in all_metrics])\\n\",\n",
      "    \"            avg_metrics[f\\\"avg_{metric}\\\"] = avg_value\\n\",\n",
      "    \"            mlflow.log_metric(f\\\"avg_{metric}\\\", avg_value)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Create and log visualizations\\n\",\n",
      "    \"        create_and_log_visualizations(all_metrics)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return run.info.run_id, avg_metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Base line Evaluation\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"log experiment to MLFlow\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 28,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"application/vnd.jupyter.widget-view+json\": {\n",
      "       \"model_id\": \"21525b2c624b4237a82f3311b2c6305e\",\n",
      "       \"version_major\": 2,\n",
      "       \"version_minor\": 0\n",
      "      },\n",
      "      \"text/plain\": [\n",
      "       \"Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\"\n",
      "      ]\n",
      "     },\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"display_data\"\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"2024/11/19 09:57:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Chain logged with run_id: 7af45a39ac3049e7bada8bc93b771e0b\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Example usage\\n\",\n",
      "    \"setup_mlflow()\\n\",\n",
      "    \"\\n\",\n",
      "    \"prompt_template = \\\"\\\"\\\"\\n\",\n",
      "    \"Please provide a comprehensive summary of the following video transcript in {language}. \\n\",\n",
      "    \"Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"{text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"Please structure the summary with:\\n\",\n",
      "    \"1. Main Topic/Theme\\n\",\n",
      "    \"2. Key Points\\n\",\n",
      "    \"3. Important Details\\n\",\n",
      "    \"4. Conclusions\\n\",\n",
      "    \"\\\"\\\"\\\"\\n\",\n",
      "    \"model_name = \\\"llama-3.2-90b-vision-preview\\\"\\n\",\n",
      "    \"\\n\",\n",
      "    \"chain = YouTubeSummaryChain(prompt_template=prompt_template, language=\\\"english\\\")\\n\",\n",
      "    \"run_id = log_chain_to_mlflow(chain)\\n\",\n",
      "    \"print(f\\\"Chain logged with run_id: {run_id}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load the chain\\n\",\n",
      "    \"loaded_chain = load_chain_from_mlflow(run_id)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 29,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"1. Main Topic/Theme:\\n\",\n",
      "      \"The main topic of the transcript is the proposed sale of EPM's stake in Tigo-Une by the manager of DPM (Dirección de Proyectos Estratégicos - Strategic Projects Directorate), John Maya. He discusses the reasons for selling, the financial situation of EPM, and the potential use of the sale's proceeds.\\n\",\n",
      "      \"\\n\",\n",
      "      \"2. Key Points:\\n\",\n",
      "      \"\\n\",\n",
      "      \"- The telecommunications industry requires significant capital investments due to rapid technological changes every 5 years.\\n\",\n",
      "      \"- EPM, as a public services provider, needs to invest in strategic areas like energy generation, distribution, water, gas, and telecommunications through partners.\\n\",\n",
      "      \"- EPM has identified a budget deficit of around $150 million for financing planned projects.\\n\",\n",
      "      \"- The value of Tigo-Une's shares in EPM's books is around 1.6 trillion pesos ($400 million) after accounting for a 1.04 trillion pesos ($250 million) deterioration in 2022.\\n\",\n",
      "      \"- The sale of Tigo-Une's shares requires the approval of the EPM board and a subsequent valuation by a financial institution.\\n\",\n",
      "      \"- The government is also considering selling its stake in Telecom, which may result in a stronger competitor for Claro in the Colombian telecommunications market.\\n\",\n",
      "      \"- If the sale is not approved by the sector, special groups, or the market, EPM has a clause to sell the shares with a partner, such as Millicom (Tigo's parent company).\\n\",\n",
      "      \"- The potential use of the sale's proceeds includes education, innovation, residue valorization, and improving connectivity in underserved areas.\\n\",\n",
      "      \"\\n\",\n",
      "      \"3. Important Details:\\n\",\n",
      "      \"\\n\",\n",
      "      \"- EPM's financial situation is good, with positive results in the first semester of the year.\\n\",\n",
      "      \"- EPM's budget deficit is not a loss or a sign of financial difficulties but a result of insufficient financing for planned projects.\\n\",\n",
      "      \"- The deterioration of Tigo-Une's shares in 2022 occurred during the administration of former Medellín mayor Daniel Quintero.\\n\",\n",
      "      \"- The sale of Tigo-Une's shares would not directly benefit the city of Medellín, as the funds would be reinvested in EPM for specific purposes.\\n\",\n",
      "      \"- EPM's extensive fiber-optic network can be used to improve connectivity in schools, hospitals, and communities, but EPM does not intend to enter the telecommunications commercialization business.\\n\",\n",
      "      \"\\n\",\n",
      "      \"4. Conclusions:\\n\",\n",
      "      \"\\n\",\n",
      "      \"- The sale of EPM's stake in Tigo-Une is driven by the need to invest in strategic areas and the rapid technological changes in the telecommunications industry.\\n\",\n",
      "      \"- EPM's financial situation is stable, but there is a budget deficit for planned projects.\\n\",\n",
      "      \"- The potential sale of Tigo-Une's shares would require several approvals and valuations, and the proceeds would be reinvested in EPM for various purposes.\\n\",\n",
      "      \"- The government is also considering selling its stake in Telecom, which could impact the Colombian telecommunications market.\\n\",\n",
      "      \"- EPM aims to improve education, innovation, residue valorization, and connectivity in underserved areas with the potential sale's proceeds.\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Use the loaded chain - Fix the prediction call\\n\",\n",
      "    \"youtube_url = \\\"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\\\"\\n\",\n",
      "    \"# Convert single URL to pandas Series\\n\",\n",
      "    \"input_data = pd.Series([youtube_url])\\n\",\n",
      "    \"summary, transcript = loaded_chain.predict(input_data)[0]  # Get first result from the list\\n\",\n",
      "    \"print(summary)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 30,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"/Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning:\\n\",\n",
      "      \"\\n\",\n",
      "      \"\\n\",\n",
      "      \"The hypothesis contains 0 counts of 4-gram overlaps.\\n\",\n",
      "      \"Therefore the BLEU score evaluates to 0, independently of\\n\",\n",
      "      \"how many N-gram overlaps of lower order it contains.\\n\",\n",
      "      \"Consider using lower n-gram order or use SmoothingFunction()\\n\",\n",
      "      \"\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"\\n\",\n",
      "      \"Evaluation Results:\\n\",\n",
      "      \"==================\\n\",\n",
      "      \"avg_rouge1_precision: 0.2747\\n\",\n",
      "      \"avg_rouge1_recall: 0.5431\\n\",\n",
      "      \"avg_rouge1_f1: 0.3603\\n\",\n",
      "      \"avg_rouge2_f1: 0.1044\\n\",\n",
      "      \"avg_rougeL_f1: 0.1901\\n\",\n",
      "      \"avg_bleu_score: 0.0325\\n\",\n",
      "      \"avg_summary_length_ratio: 2.1463\\n\",\n",
      "      \"avg_predicted_length: 334.3333\\n\",\n",
      "      \"avg_reference_length: 165.3333\\n\",\n",
      "      \"avg_llm_score: 87.3333\\n\",\n",
      "      \"\\n\",\n",
      "      \"MLflow run ID: 467d9e0959a444a181fcd6c889663c1e\\n\",\n",
      "      \"View detailed results in the MLflow UI\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Prepare test data\\n\",\n",
      "    \"test_data = prepare_test_data()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Run evaluation\\n\",\n",
      "    \"run_id, avg_metrics = evaluate_model_with_mlflow(loaded_chain, test_data)\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(\\\"\\\\nEvaluation Results:\\\")\\n\",\n",
      "    \"print(\\\"==================\\\")\\n\",\n",
      "    \"for metric, value in avg_metrics.items():\\n\",\n",
      "    \"    print(f\\\"{metric}: {value:.4f}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(f\\\"\\\\nMLflow run ID: {run_id}\\\")\\n\",\n",
      "    \"print(\\\"View detailed results in the MLflow UI\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 32,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"application/vnd.jupyter.widget-view+json\": {\n",
      "       \"model_id\": \"bff8cc9a6f8d4f19b7f417abb75dd969\",\n",
      "       \"version_major\": 2,\n",
      "       \"version_minor\": 0\n",
      "      },\n",
      "      \"text/plain\": [\n",
      "       \"Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\"\n",
      "      ]\n",
      "     },\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"display_data\"\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"2024/11/19 10:01:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Chain logged with run_id: 4a78dfca7de94b32882502181643e67c\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"/Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning:\\n\",\n",
      "      \"\\n\",\n",
      "      \"\\n\",\n",
      "      \"The hypothesis contains 0 counts of 4-gram overlaps.\\n\",\n",
      "      \"Therefore the BLEU score evaluates to 0, independently of\\n\",\n",
      "      \"how many N-gram overlaps of lower order it contains.\\n\",\n",
      "      \"Consider using lower n-gram order or use SmoothingFunction()\\n\",\n",
      "      \"\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"\\n\",\n",
      "      \"Evaluation Results:\\n\",\n",
      "      \"==================\\n\",\n",
      "      \"avg_rouge1_precision: 0.2477\\n\",\n",
      "      \"avg_rouge1_recall: 0.5797\\n\",\n",
      "      \"avg_rouge1_f1: 0.3453\\n\",\n",
      "      \"avg_rouge2_f1: 0.1109\\n\",\n",
      "      \"avg_rougeL_f1: 0.1838\\n\",\n",
      "      \"avg_bleu_score: 0.0393\\n\",\n",
      "      \"avg_summary_length_ratio: 2.4600\\n\",\n",
      "      \"avg_predicted_length: 394.3333\\n\",\n",
      "      \"avg_reference_length: 165.3333\\n\",\n",
      "      \"avg_llm_score: 87.3333\\n\",\n",
      "      \"\\n\",\n",
      "      \"MLflow run ID: 35ebfbc3649d4024a1691655a74dbae1\\n\",\n",
      "      \"View detailed results in the MLflow UI\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Example usage\\n\",\n",
      "    \"setup_mlflow()\\n\",\n",
      "    \"\\n\",\n",
      "    \"prompt_template = \\\"\\\"\\\"\\n\",\n",
      "    \"Please provide a comprehensive summary of the following video transcript in {language}. \\n\",\n",
      "    \"Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"{text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"Please structure the summary with:\\n\",\n",
      "    \"1. Main Topic/Theme\\n\",\n",
      "    \"2. Key Points\\n\",\n",
      "    \"3. Important Details\\n\",\n",
      "    \"4. Conclusions\\n\",\n",
      "    \"\\\"\\\"\\\"\\n\",\n",
      "    \"model_name = \\\"llama-3.2-11b-text-preview\\\"\\n\",\n",
      "    \"\\n\",\n",
      "    \"chain = YouTubeSummaryChain(prompt_template=prompt_template, language=\\\"english\\\")\\n\",\n",
      "    \"run_id = log_chain_to_mlflow(chain)\\n\",\n",
      "    \"print(f\\\"Chain logged with run_id: {run_id}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load the chain\\n\",\n",
      "    \"loaded_chain = load_chain_from_mlflow(run_id)\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Prepare test data\\n\",\n",
      "    \"test_data = prepare_test_data()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Run evaluation\\n\",\n",
      "    \"run_id, avg_metrics = evaluate_model_with_mlflow(loaded_chain, test_data)\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(\\\"\\\\nEvaluation Results:\\\")\\n\",\n",
      "    \"print(\\\"==================\\\")\\n\",\n",
      "    \"for metric, value in avg_metrics.items():\\n\",\n",
      "    \"    print(f\\\"{metric}: {value:.4f}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(f\\\"\\\\nMLflow run ID: {run_id}\\\")\\n\",\n",
      "    \"print(\\\"View detailed results in the MLflow UI\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## View MLflow Experiment Results\\n\",\n",
      "    \"\\n\",\n",
      "    \"You can view the tracked experiments by running:\\n\",\n",
      "    \"```bash\\n\",\n",
      "    \"mlflow ui\\n\",\n",
      "    \"```\\n\",\n",
      "    \"\\n\",\n",
      "    \"This will start the MLflow UI server where you can see:\\n\",\n",
      "    \"1. All experiment runs\\n\",\n",
      "    \"2. Chain configurations\\n\",\n",
      "    \"3. Prompt templates\\n\",\n",
      "    \"4. Performance metrics (if added)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# 03_CrewAi_example.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Summary\\n\",\n",
      "    \"\\n\",\n",
      "    \"In this use case we are going to use crewai to generate code\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# CrewAi Architecture\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 1,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\\n\",\n",
      "      \"Collecting crewai\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/13/55/8caa2264c59be4c11266be1aae2b57610dcd30cd1c6f0752416589126f3b/crewai-0.80.0-py3-none-any.whl (197 kB)\\n\",\n",
      "      \"Collecting appdirs>=1.4.4 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\\n\",\n",
      "      \"Collecting auth0-python>=4.7.1 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/e4/0e/38cb7b781371e79e9c697fb78f3ccd18fda8bd547d0a2e76e616561a3792/auth0_python-4.7.2-py3-none-any.whl (131 kB)\\n\",\n",
      "      \"Collecting chromadb>=0.4.24 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/5f/7a/10bf5dc92d13cc03230190fcc5016a0b138d99e5b36b8b89ee0fe1680e10/chromadb-0.5.20-py3-none-any.whl (617 kB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m617.9/617.9 kB\\u001b[0m \\u001b[31m264.4 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hRequirement already satisfied: click>=8.1.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (8.1.7)\\n\",\n",
      "      \"Collecting crewai-tools>=0.14.0 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c8/ed/9f4e64e1507062957b0118085332d38b621c1000874baef2d1c4069bfd97/crewai_tools-0.14.0-py3-none-any.whl (462 kB)\\n\",\n",
      "      \"Collecting instructor>=1.3.3 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/9d/f1/e136ffee98aeadb6c6f3d36fe7ff6cdcc08d857827b9f234e67d1abe18e6/instructor-1.6.4-py3-none-any.whl (70 kB)\\n\",\n",
      "      \"Collecting json-repair>=0.25.2 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ed/e0/6eb79e8b0379df19d0567adbe4c4cde4a328423bf0452a4dcd77aa00f901/json_repair-0.30.2-py3-none-any.whl (18 kB)\\n\",\n",
      "      \"Collecting jsonref>=1.1.0 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/0c/ec/e1db9922bceb168197a558a2b8c03a7963f1afe93517ddd3cf99f202f996/jsonref-1.1.0-py3-none-any.whl (9.4 kB)\\n\",\n",
      "      \"Collecting langchain>=0.2.16 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/49/09/72630413a7ded27684e33392a0ff52ff1c8ea6749fee641319e75f82072b/langchain-0.3.7-py3-none-any.whl (1.0 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m1.0/1.0 MB\\u001b[0m \\u001b[31m329.6 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting litellm>=1.44.22 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/83/19/f0725dfecfc9f3ed7eb433b5f303b6af4fb5245ed5ed6735f32872df9c65/litellm-1.52.10-py3-none-any.whl (6.4 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m6.4/6.4 MB\\u001b[0m \\u001b[31m278.1 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m00:01\\u001b[0m00:02\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting openai>=1.13.3 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/30/90/7f6621a79de8b32f120e9790441c24dd9afafb2f1ca41fd3b9f4faaf8f9f/openai-1.54.5-py3-none-any.whl (389 kB)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-api>=1.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (1.28.2)\\n\",\n",
      "      \"Collecting opentelemetry-exporter-otlp-proto-http>=1.22.0 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/19/23/802b889cf8bf3e235f30fbcbaa2b3fd484fe8c76b5b4db00f00c0e9af20f/opentelemetry_exporter_otlp_proto_http-1.28.2-py3-none-any.whl (17 kB)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (1.28.2)\\n\",\n",
      "      \"Requirement already satisfied: pydantic>=2.4.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (2.9.2)\\n\",\n",
      "      \"Requirement already satisfied: python-dotenv>=1.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (1.0.1)\\n\",\n",
      "      \"Collecting pyvis>=0.3.2 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ab/4b/e37e4e5d5ee1179694917b445768bdbfb084f5a59ecd38089d3413d4c70f/pyvis-0.3.2-py3-none-any.whl (756 kB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m756.0/756.0 kB\\u001b[0m \\u001b[31m275.2 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hRequirement already satisfied: regex>=2024.9.11 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (2024.11.6)\\n\",\n",
      "      \"Collecting tomli-w>=1.1.0 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c4/ac/ce90573ba446a9bbe65838ded066a805234d159b4446ae9f8ec5bbd36cbd/tomli_w-1.1.0-py3-none-any.whl (6.4 kB)\\n\",\n",
      "      \"Collecting tomli>=2.0.2 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/de/f7/4da0ffe1892122c9ea096c57f64c2753ae5dd3ce85488802d11b0992cc6d/tomli-2.1.0-py3-none-any.whl (13 kB)\\n\",\n",
      "      \"Collecting uv>=0.4.25 (from crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/24/e0/f468ea89d85fb4c7a442b999d6fc1a5ef32e6fa3c872e471f0a1ba856069/uv-0.5.2-py3-none-macosx_11_0_arm64.whl (12.7 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m12.7/12.7 MB\\u001b[0m \\u001b[31m320.1 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m00:01\\u001b[0m00:02\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.5 (from auth0-python>=4.7.1->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/b7/d7/56f11579e6521f058b011ad22d8a8818eb68c22e7e6237de0277f0963973/aiohttp-3.11.4-cp311-cp311-macosx_11_0_arm64.whl (454 kB)\\n\",\n",
      "      \"Collecting cryptography<44.0.0,>=43.0.1 (from auth0-python>=4.7.1->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/30/d5/c8b32c047e2e81dd172138f772e81d852c51f0f2ad2ae8a24f1122e9e9a7/cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl (6.2 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m6.2/6.2 MB\\u001b[0m \\u001b[31m238.1 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting pyjwt<3.0.0,>=2.8.0 (from auth0-python>=4.7.1->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/6f/1d/ef9b066e7ef60494c94173dc9f0b9adf5d9ec5f888109f5c669f53d4144b/PyJWT-2.10.0-py3-none-any.whl (23 kB)\\n\",\n",
      "      \"Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from auth0-python>=4.7.1->crewai) (2.32.3)\\n\",\n",
      "      \"Requirement already satisfied: urllib3<3.0.0,>=2.0.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from auth0-python>=4.7.1->crewai) (2.2.3)\\n\",\n",
      "      \"Collecting build>=1.0.3 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/84/c2/80633736cd183ee4a62107413def345f7e6e3c01563dbca1417363cf957e/build-1.2.2.post1-py3-none-any.whl (22 kB)\\n\",\n",
      "      \"Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/0d/19/aa6f2139f1ff7ad23a690ebf2a511b2594ab359915d7979f76f3213e46c4/chroma_hnswlib-0.7.6-cp311-cp311-macosx_11_0_arm64.whl (185 kB)\\n\",\n",
      "      \"Collecting fastapi>=0.95.2 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/54/c4/148d5046a96c428464557264877ae5a9338a83bbe0df045088749ec89820/fastapi-0.115.5-py3-none-any.whl (94 kB)\\n\",\n",
      "      \"Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/eb/14/78bd0e95dd2444b6caacbca2b730671d4295ccb628ef58b81bee903629df/uvicorn-0.32.0-py3-none-any.whl (63 kB)\\n\",\n",
      "      \"Requirement already satisfied: numpy>=1.22.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (2.1.3)\\n\",\n",
      "      \"Collecting posthog>=2.4.0 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/71/23/1e7b25c4b8181da03431c57f234f6b8c883fe9b68128110e217e870d1250/posthog-3.7.2-py2.py3-none-any.whl (54 kB)\\n\",\n",
      "      \"Requirement already satisfied: typing-extensions>=4.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (4.12.2)\\n\",\n",
      "      \"Collecting onnxruntime>=1.14.1 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/43/d3/3b7e17266a4d360af0a93965021ef8192d833233658a9d59501fbaf1341a/onnxruntime-1.20.0-cp311-cp311-macosx_13_0_universal2.whl (31.0 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m31.0/31.0 MB\\u001b[0m \\u001b[31m224.3 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m00:01\\u001b[0m00:05\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/dd/7e/6af5a7de87988cfc951db86f7fd0ecaabc20bc112fd9cfe06b8a01f11400/opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\\n\",\n",
      "      \"Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d3/a9/ef2678c16caf5dc2f84628bfafdbc90139e3c78d9017afd07fbd51b1eeef/opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\\n\",\n",
      "      \"Requirement already satisfied: tokenizers>=0.13.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (0.20.3)\\n\",\n",
      "      \"Collecting pypika>=0.48.9 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c7/2c/94ed7b91db81d61d7096ac8f2d325ec562fc75e35f3baea8749c85b28784/PyPika-0.48.9.tar.gz (67 kB)\\n\",\n",
      "      \"  Installing build dependencies ... \\u001b[?25ldone\\n\",\n",
      "      \"\\u001b[?25h  Getting requirements to build wheel ... \\u001b[?25ldone\\n\",\n",
      "      \"\\u001b[?25h  Preparing metadata (pyproject.toml) ... \\u001b[?25ldone\\n\",\n",
      "      \"\\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (4.67.0)\\n\",\n",
      "      \"Requirement already satisfied: overrides>=7.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (7.7.0)\\n\",\n",
      "      \"Collecting importlib-resources (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl (36 kB)\\n\",\n",
      "      \"Collecting grpcio>=1.58.0 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7b/59/34dae935bbb42f3e8929c90e9dfff49090cef412cf767cf4f14cd01ded18/grpcio-1.68.0-cp311-cp311-macosx_10_9_universal2.whl (11.2 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m11.2/11.2 MB\\u001b[0m \\u001b[31m338.3 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m00:01\\u001b[0m00:02\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting bcrypt>=4.0.1 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/96/86/8c6a84daed4dd878fbab094400c9174c43d9b838ace077a2f8ee8bc3ae12/bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl (472 kB)\\n\",\n",
      "      \"Collecting typer>=0.9.0 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/22/69/e90a0b4d0c16e095901679216c8ecdc728110c7c54e7b5f43a623bc4c789/typer-0.13.1-py3-none-any.whl (44 kB)\\n\",\n",
      "      \"Collecting kubernetes>=28.1.0 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/fb/a8/17f5e28cecdbd6d48127c22abdb794740803491f422a11905c4569d8e139/kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m1.9/1.9 MB\\u001b[0m \\u001b[31m302.3 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (9.0.0)\\n\",\n",
      "      \"Requirement already satisfied: PyYAML>=6.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (6.0.2)\\n\",\n",
      "      \"Collecting mmh3>=4.0.1 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/13/f0/2d3daca276a4673f82af859e4b0b18befd4e6e54f1017ba48ea9735b2f1b/mmh3-5.0.1-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\\n\",\n",
      "      \"Collecting orjson>=3.9.12 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1e/25/c869a1fbd481dcb02c70032fd6a7243de7582bc48c7cae03d6f0985a11c0/orjson-3.10.11-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (266 kB)\\n\",\n",
      "      \"Requirement already satisfied: httpx>=0.27.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (0.27.2)\\n\",\n",
      "      \"Collecting rich>=10.11.0 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl (242 kB)\\n\",\n",
      "      \"Requirement already satisfied: beautifulsoup4>=4.12.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai-tools>=0.14.0->crewai) (4.12.3)\\n\",\n",
      "      \"Requirement already satisfied: docker>=7.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai-tools>=0.14.0->crewai) (7.1.0)\\n\",\n",
      "      \"Collecting docx2txt>=0.8 (from crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7d/7d/60ee3f2b16d9bfdfa72e8599470a2c1a5b759cb113c6fe1006be28359327/docx2txt-0.8.tar.gz (2.8 kB)\\n\",\n",
      "      \"  Preparing metadata (setup.py) ... \\u001b[?25ldone\\n\",\n",
      "      \"\\u001b[?25hCollecting embedchain>=0.1.114 (from crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/52/82/3d0355c22bc68cfbb8fbcf670da4c01b31bd7eb516974a08cf7533e89887/embedchain-0.1.125-py3-none-any.whl (211 kB)\\n\",\n",
      "      \"Collecting lancedb>=0.5.4 (from crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/b9/25/25f8494e164ec83212002018053271865ae06ca4cc5976e3987515fdeb2a/lancedb-0.16.0-cp38-abi3-macosx_11_0_arm64.whl (22.6 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m22.6/22.6 MB\\u001b[0m \\u001b[31m328.1 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m00:01\\u001b[0m00:02\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting pyright>=1.1.350 (from crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1b/26/c288cabf8cfc5a27e1aa9e5029b7682c0f920b8074f45d22bf844314d66a/pyright-1.1.389-py3-none-any.whl (18 kB)\\n\",\n",
      "      \"Collecting pytest>=8.0.0 (from crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/6b/77/7440a06a8ead44c7757a64362dd22df5760f9b12dc5f11b6188cd2fc27a0/pytest-8.3.3-py3-none-any.whl (342 kB)\\n\",\n",
      "      \"Collecting pytube>=15.0.0 (from crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/51/64/bcf8632ed2b7a36bbf84a0544885ffa1d0b4bcf25cc0903dba66ec5fdad9/pytube-15.0.0-py3-none-any.whl (57 kB)\\n\",\n",
      "      \"Collecting selenium>=4.18.1 (from crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/91/08/10cff8463b3510b78f9e3dcef6b37c542b06d71ed1240a8940ba0c75d3bc/selenium-4.26.1-py3-none-any.whl (9.7 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m9.7/9.7 MB\\u001b[0m \\u001b[31m271.9 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting docstring-parser<0.17,>=0.16 (from instructor>=1.3.3->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d5/7c/e9fcff7623954d86bdc17782036cbf715ecab1bec4847c008557affe1ca8/docstring_parser-0.16-py3-none-any.whl (36 kB)\\n\",\n",
      "      \"Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from instructor>=1.3.3->crewai) (3.1.4)\\n\",\n",
      "      \"Collecting jiter<0.7,>=0.6.1 (from instructor>=1.3.3->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/91/35/85ef9eaef7dec14f28dd9b8a2116c07075bb2731a405b650a55fda4c74d7/jiter-0.6.1-cp311-cp311-macosx_11_0_arm64.whl (302 kB)\\n\",\n",
      "      \"Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from instructor>=1.3.3->crewai) (2.23.4)\\n\",\n",
      "      \"Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from langchain>=0.2.16->crewai) (2.0.36)\\n\",\n",
      "      \"Collecting langchain-core<0.4.0,>=0.3.15 (from langchain>=0.2.16->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a1/25/5bd49cda589e98908e40591214c98cac52f7eb37230bbe493dbd883b9a89/langchain_core-0.3.19-py3-none-any.whl (409 kB)\\n\",\n",
      "      \"Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain>=0.2.16->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ee/c6/5ba25c8bad647e92a92b3066177ab10d78efbd16c0b9919948cdcd18b027/langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\\n\",\n",
      "      \"Collecting langsmith<0.2.0,>=0.1.17 (from langchain>=0.2.16->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/f8/53/0a22394aa520176b1981e9b7f02090425731b575e9ae28f86a7f5341208c/langsmith-0.1.143-py3-none-any.whl (306 kB)\\n\",\n",
      "      \"Collecting numpy>=1.22.5 (from chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1a/2e/151484f49fd03944c4a3ad9c418ed193cfd02724e138ac8a9505d056c582/numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m14.0/14.0 MB\\u001b[0m \\u001b[31m307.8 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m00:01\\u001b[0m00:02\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hRequirement already satisfied: importlib-metadata>=6.8.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from litellm>=1.44.22->crewai) (8.5.0)\\n\",\n",
      "      \"Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from litellm>=1.44.22->crewai) (4.23.0)\\n\",\n",
      "      \"Collecting tiktoken>=0.7.0 (from litellm>=1.44.22->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/8c/f8/f0101d98d661b34534769c3818f5af631e59c36ac6d07268fbfc89e539ce/tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl (982 kB)\\n\",\n",
      "      \"Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from openai>=1.13.3->crewai) (4.6.2.post1)\\n\",\n",
      "      \"Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from openai>=1.13.3->crewai) (1.9.0)\\n\",\n",
      "      \"Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from openai>=1.13.3->crewai) (1.3.1)\\n\",\n",
      "      \"Requirement already satisfied: deprecated>=1.2.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-api>=1.22.0->crewai) (1.2.15)\\n\",\n",
      "      \"Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a0/0f/c0713fb2b3d28af4b2fded3291df1c4d4f79a00d15c2374a9e010870016c/googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\\n\",\n",
      "      \"Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/2a/4d/769f3b1b1c6af5e603da50349ba31af757897540a75d666de22d39461055/opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\\n\",\n",
      "      \"Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1d/12/646f48d6d698a6df0437a22b591387440dc4888c8752d1a1300f730da710/opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\\n\",\n",
      "      \"Requirement already satisfied: protobuf<6.0,>=5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-proto==1.28.2->opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai) (5.28.3)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-sdk>=1.22.0->crewai) (0.49b2)\\n\",\n",
      "      \"Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic>=2.4.2->crewai) (0.7.0)\\n\",\n",
      "      \"Requirement already satisfied: ipython>=5.3.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyvis>=0.3.2->crewai) (8.29.0)\\n\",\n",
      "      \"Collecting jsonpickle>=1.4.1 (from pyvis>=0.3.2->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a1/64/815460f86d94c9e1431800a75061719824c6fef14d88a6117eba3126cd5b/jsonpickle-4.0.0-py3-none-any.whl (46 kB)\\n\",\n",
      "      \"Collecting networkx>=1.11 (from pyvis>=0.3.2->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl (1.7 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m1.7/1.7 MB\\u001b[0m \\u001b[31m118.7 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:02\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/f7/d8/120cd0fe3e8530df0539e71ba9683eade12cae103dd7543e50d15f737917/aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\\n\",\n",
      "      \"Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\\n\",\n",
      "      \"Requirement already satisfied: attrs>=17.3.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (24.2.0)\\n\",\n",
      "      \"Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/2c/31/ab01375682f14f7613a1ade30149f684c84f9b8823a4391ed950c8285656/frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl (52 kB)\\n\",\n",
      "      \"Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/70/0f/6dc70ddf5d442702ed74f298d69977f904960b82368532c88e854b79f72b/multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\\n\",\n",
      "      \"Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c0/1d/c700d16d1d6903aeab28372fe9999762f074b80b96a0ccc953175b858743/propcache-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\\n\",\n",
      "      \"Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/19/71/f7241b745f0f9b3120de1b2a63c08b5bae5ec6d42890026a58545a068c4e/yarl-1.17.2-cp311-cp311-macosx_11_0_arm64.whl (91 kB)\\n\",\n",
      "      \"Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.13.3->crewai) (3.10)\\n\",\n",
      "      \"Requirement already satisfied: soupsieve>1.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from beautifulsoup4>=4.12.3->crewai-tools>=0.14.0->crewai) (2.6)\\n\",\n",
      "      \"Requirement already satisfied: packaging>=19.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from build>=1.0.3->chromadb>=0.4.24->crewai) (24.2)\\n\",\n",
      "      \"Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/bd/24/12818598c362d7f300f18e74db45963dbcb85150324092410c8b49405e42/pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\\n\",\n",
      "      \"Requirement already satisfied: cffi>=1.12 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\\n\",\n",
      "      \"Requirement already satisfied: wrapt<2,>=1.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->crewai) (1.16.0)\\n\",\n",
      "      \"Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (1.14.0)\\n\",\n",
      "      \"Collecting cohere<6.0,>=5.3 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/53/5c/909862a2eb2a0eaf3bc2024058207e342286e015d60ff03fe38f3efdde6d/cohere-5.11.4-py3-none-any.whl (249 kB)\\n\",\n",
      "      \"Collecting google-cloud-aiplatform<2.0.0,>=1.26.1 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7d/c7/276023cb0f2b2e9bea17df73894113b3ce25b5742198e1a3e2175ade5b90/google_cloud_aiplatform-1.72.0-py2.py3-none-any.whl (6.2 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m6.2/6.2 MB\\u001b[0m \\u001b[31m262.2 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/49/87/8dde0a3757bc207805f751b47878888b09db4a464ae48a55f386f091b488/gptcache-0.1.44-py3-none-any.whl (131 kB)\\n\",\n",
      "      \"Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/64/5e/bbfb1b33703a973e7eef6582b523ae932e7e64c9b84ac7eecaa8af71475e/langchain_cohere-0.3.1-py3-none-any.whl (43 kB)\\n\",\n",
      "      \"Collecting langchain-community<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/cc/19/f8af1cdefe326730ae02bd653f7382693153baf0bac7a69537d7811cad5f/langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m2.4/2.4 MB\\u001b[0m \\u001b[31m292.1 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/56/f3/b8767fd4f33fb811139292943083f9bef0f8cc4a43edeff2c19b501df75f/langchain_openai-0.2.9-py3-none-any.whl (50 kB)\\n\",\n",
      "      \"Collecting mem0ai<0.2.0,>=0.1.29 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/65/9b/755be84f669415b3b513cfd935e768c4c84ac5c1ab6ff6ac2dab990a261a/mem0ai-0.1.29-py3-none-any.whl (79 kB)\\n\",\n",
      "      \"Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/04/fc/6f52588ac1cb4400a7804ef88d0d4e00cfe57a7ac6793ec3b00de5a8758b/pypdf-5.1.0-py3-none-any.whl (297 kB)\\n\",\n",
      "      \"Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl (71 kB)\\n\",\n",
      "      \"Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ad/1b/81855a88c6db2b114d5b2e9f96339190d5ee4d1b981d217fa32127bb00e0/schema-0.7.7-py2.py3-none-any.whl (18 kB)\\n\",\n",
      "      \"Collecting tiktoken>=0.7.0 (from litellm>=1.44.22->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/30/ef/e07dbfcb2f85c84abaa1b035a9279575a8da0236305491dc22ae099327f7/tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl (907 kB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m907.0/907.0 kB\\u001b[0m \\u001b[31m483.8 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/96/00/2b325970b3060c7cecebab6d295afe763365822b1306a12eeab198f74323/starlette-0.41.3-py3-none-any.whl (73 kB)\\n\",\n",
      "      \"Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.4.24->crewai) (2024.8.30)\\n\",\n",
      "      \"Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.4.24->crewai) (1.0.7)\\n\",\n",
      "      \"Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.24->crewai) (0.14.0)\\n\",\n",
      "      \"Requirement already satisfied: zipp>=3.20 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm>=1.44.22->crewai) (3.21.0)\\n\",\n",
      "      \"Requirement already satisfied: decorator in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.1.1)\\n\",\n",
      "      \"Requirement already satisfied: jedi>=0.16 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.19.2)\\n\",\n",
      "      \"Requirement already satisfied: matplotlib-inline in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\\n\",\n",
      "      \"Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.48)\\n\",\n",
      "      \"Requirement already satisfied: pygments>=2.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.18.0)\\n\",\n",
      "      \"Requirement already satisfied: stack-data in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.6.3)\\n\",\n",
      "      \"Requirement already satisfied: traitlets>=5.13.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.14.3)\\n\",\n",
      "      \"Requirement already satisfied: pexpect>4.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\\n\",\n",
      "      \"Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.3.3->crewai) (3.0.2)\\n\",\n",
      "      \"Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (2024.10.1)\\n\",\n",
      "      \"Requirement already satisfied: referencing>=0.28.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (0.35.1)\\n\",\n",
      "      \"Requirement already satisfied: rpds-py>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (0.21.0)\\n\",\n",
      "      \"Requirement already satisfied: six>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (1.16.0)\\n\",\n",
      "      \"Requirement already satisfied: python-dateutil>=2.5.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (2.9.0.post0)\\n\",\n",
      "      \"Requirement already satisfied: google-auth>=1.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (2.36.0)\\n\",\n",
      "      \"Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (1.8.0)\\n\",\n",
      "      \"Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\\n\",\n",
      "      \"Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl (151 kB)\\n\",\n",
      "      \"Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/4c/a3/ac312faeceffd2d8f86bc6dcb5c401188ba5a01bc88e69bed97578a0dfcd/durationpy-0.9-py3-none-any.whl (3.5 kB)\\n\",\n",
      "      \"Collecting deprecation (from lancedb>=0.5.4->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\\n\",\n",
      "      \"Requirement already satisfied: nest-asyncio~=1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from lancedb>=0.5.4->crewai-tools>=0.14.0->crewai) (1.6.0)\\n\",\n",
      "      \"Collecting pylance==0.19.2 (from lancedb>=0.5.4->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/8b/f5/6c2f04869747cb382f0f561362d354e132c2adb9b299aa28f28bb1847209/pylance-0.19.2-cp39-abi3-macosx_11_0_arm64.whl (26.7 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m26.7/26.7 MB\\u001b[0m \\u001b[31m303.6 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m00:01\\u001b[0m00:03\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hRequirement already satisfied: pyarrow>=12 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pylance==0.19.2->lancedb>=0.5.4->crewai-tools>=0.14.0->crewai) (18.0.0)\\n\",\n",
      "      \"Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.15->langchain>=0.2.16->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\\n\",\n",
      "      \"Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain>=0.2.16->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\\n\",\n",
      "      \"Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\\n\",\n",
      "      \"Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\\n\",\n",
      "      \"Collecting sympy (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/99/ff/c87e0622b1dadea79d2fb0b25ade9ed98954c9033722eb707053d310d4f3/sympy-1.13.3-py3-none-any.whl (6.2 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m6.2/6.2 MB\\u001b[0m \\u001b[31m266.9 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3f/82/06a56e786de3ea0ef4703ed313d9d8395fb4bc9ae740cc71415178ae8bff/opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\\n\",\n",
      "      \"Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ef/e3/ad23372525653b0221212d5e2a71bd97aae64cc35f90cbf0c70de57dfa4e/opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\\n\",\n",
      "      \"Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/19/22/9128f10d1c2868ee42df7e10937d00f154a69bee87c416ca9b20a6af6c54/opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\\n\",\n",
      "      \"Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/39/e3/893e8757be2612e6c266d9bb58ad2e3651524b5b40cf56761e985a28b13e/asgiref-3.8.1-py3-none-any.whl (23 kB)\\n\",\n",
      "      \"Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\\n\",\n",
      "      \"Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl (15 kB)\\n\",\n",
      "      \"Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d2/1d/1b658dbd2b9fa9c4c9f32accbfc0205d532c8c6194dc0f2a4c0428e7128a/nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\\n\",\n",
      "      \"Collecting iniconfig (from pytest>=8.0.0->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ef/a6/62565a6e1cf69e10f5727360368e451d4b7f58beeac6173dc9db836a5b46/iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\\n\",\n",
      "      \"Collecting pluggy<2,>=1.5 (from pytest>=8.0.0->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/88/5f/e351af9a41f866ac3f1fac4ca0613908d9a41741cfcf2228f4ad853b697d/pluggy-1.5.0-py3-none-any.whl (20 kB)\\n\",\n",
      "      \"Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->auth0-python>=4.7.1->crewai) (3.4.0)\\n\",\n",
      "      \"Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\\n\",\n",
      "      \"Collecting trio~=0.17 (from selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3c/83/ec3196c360afffbc5b342ead48d1eb7393dd74fa70bca75d33905a86f211/trio-0.27.0-py3-none-any.whl (481 kB)\\n\",\n",
      "      \"Collecting trio-websocket~=0.9 (from selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl (17 kB)\\n\",\n",
      "      \"Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb>=0.4.24->crewai) (0.26.2)\\n\",\n",
      "      \"Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\\n\",\n",
      "      \"Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a6/17/3e0d3e9b901c732987a45f4f94d4e2c62b89a041d93db89eafb262afd8d5/httptools-0.6.4-cp311-cp311-macosx_11_0_arm64.whl (103 kB)\\n\",\n",
      "      \"Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/57/a7/4cf0334105c1160dd6819f3297f8700fda7fc30ab4f61fbf3e725acbc7cc/uvloop-0.21.0-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m1.4/1.4 MB\\u001b[0m \\u001b[31m395.1 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/bc/67/d8c9d256791fe312fea118a8a051411337c948101a24586e2df237507976/watchfiles-0.24.0-cp311-cp311-macosx_11_0_arm64.whl (367 kB)\\n\",\n",
      "      \"Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ff/b8/7185212adad274c2b42b6a24e1ee6b916b7809ed611cbebc33b227e5c215/websockets-14.1-cp311-cp311-macosx_11_0_arm64.whl (159 kB)\\n\",\n",
      "      \"Requirement already satisfied: Mako in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (1.3.6)\\n\",\n",
      "      \"Requirement already satisfied: pycparser in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\\n\",\n",
      "      \"Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/89/61/b8b18aebc01e5d5a77042f6d555fe091d3279242edd5639252c9fcb9a3b7/fastavro-1.9.7-cp311-cp311-macosx_10_9_universal2.whl (1.0 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m1.0/1.0 MB\\u001b[0m \\u001b[31m369.7 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\\n\",\n",
      "      \"Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/00/2f/804f58f0b856ab3bf21617cccf5b39206e6c4c94c2cd227bde125ea6105f/parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\\n\",\n",
      "      \"Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d7/01/485b3026ff90e5190b5e24f1711522e06c79f4a56c8f4b95848ac072e20f/types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\\n\",\n",
      "      \"Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (5.5.0)\\n\",\n",
      "      \"Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (0.4.1)\\n\",\n",
      "      \"Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (4.9)\\n\",\n",
      "      \"Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/17/a4/c26886d57d90032c5f74c2e80aefdc38ec58551fc46bd4ce79fb2c9389fa/google_api_core-2.23.0-py3-none-any.whl (156 kB)\\n\",\n",
      "      \"Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/dd/25/0b7cc838ae3d76d46539020ec39fc92bfc9acc29367e58fe912702c2a79e/proto_plus-1.25.0-py3-none-any.whl (50 kB)\\n\",\n",
      "      \"Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/fc/da/95db7bd4f0bd1644378ac1702c565c0210b004754d925a74f526a710c087/google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\\n\",\n",
      "      \"Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/f5/40/4b11a4a8839de8ce802a3ccd60b34e70ce10d13d434a560534ba98f0ea3f/google_cloud_bigquery-3.27.0-py2.py3-none-any.whl (240 kB)\\n\",\n",
      "      \"Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/dd/cf/68ba6b60d1363a7e3193f457badc3cb4003552b11fa37152be9db2a3d0ac/google_cloud_resource_manager-1.13.1-py2.py3-none-any.whl (358 kB)\\n\",\n",
      "      \"Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/37/63/e182e43081fffa0a2d970c480f2ef91647a6ab94098f61748c23c2a485f2/shapely-2.0.6-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m1.3/1.3 MB\\u001b[0m \\u001b[31m343.1 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hRequirement already satisfied: filelock in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.24->crewai) (3.16.1)\\n\",\n",
      "      \"Requirement already satisfied: fsspec>=2023.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.24->crewai) (2024.10.0)\\n\",\n",
      "      \"Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\\n\",\n",
      "      \"Requirement already satisfied: jsonpointer>=1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain>=0.2.16->crewai) (3.0.0)\\n\",\n",
      "      \"Collecting langchain-experimental>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/56/fb/50a7181c318495c5481757d2606c22c6b30a4c50d75236898bb1a5437069/langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\\n\",\n",
      "      \"Requirement already satisfied: pandas>=1.4.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (2.2.3)\\n\",\n",
      "      \"Collecting tabulate<0.10.0,>=0.9.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl (35 kB)\\n\",\n",
      "      \"Collecting SQLAlchemy<3,>=1.4 (from langchain>=0.2.16->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1e/69/919673c5101a0c633658d58b11b454b251ca82300941fba801201434755d/SQLAlchemy-2.0.35-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m2.1/2.1 MB\\u001b[0m \\u001b[31m317.2 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0ma \\u001b[36m0:00:01\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\\n\",\n",
      "      \"Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/5e/f9/ff95fd7d760af42f647ea87f9b8a383d891cdb5e5dbd4613edaeb094252a/pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\\n\",\n",
      "      \"Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl (10.0 kB)\\n\",\n",
      "      \"Requirement already satisfied: pytz<2025.0,>=2024.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (2024.2)\\n\",\n",
      "      \"Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/68/c0/eef4fe9dad6d41333f7dc6567fa8144ffc1837c8a0edfc2317d50715335f/qdrant_client-1.12.1-py3-none-any.whl (267 kB)\\n\",\n",
      "      \"Requirement already satisfied: ptyprocess>=0.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\\n\",\n",
      "      \"Requirement already satisfied: wcwidth in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\\n\",\n",
      "      \"Collecting sortedcontainers (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\\n\",\n",
      "      \"Collecting outcome (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\\n\",\n",
      "      \"Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl (24 kB)\\n\",\n",
      "      \"Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/8d/59/b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9/PySocks-1.7.1-py3-none-any.whl (16 kB)\\n\",\n",
      "      \"Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\\n\",\n",
      "      \"Requirement already satisfied: executing>=1.2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.1.0)\\n\",\n",
      "      \"Requirement already satisfied: asttokens>=2.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.4.1)\\n\",\n",
      "      \"Requirement already satisfied: pure-eval in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.3)\\n\",\n",
      "      \"Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl (536 kB)\\n\",\n",
      "      \"Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ac/a7/a78ff54e67ef92a3d12126b98eb98ab8abab3de4a8c46d240c87e514d6bb/marshmallow-3.23.1-py3-none-any.whl (49 kB)\\n\",\n",
      "      \"Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\\n\",\n",
      "      \"Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/40/ba/dc535631a9dffa421b327ebfc961911af54c396aa5324efd122a94f72464/grpcio_status-1.68.0-py3-none-any.whl (14 kB)\\n\",\n",
      "      \"Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/5e/0f/2e2061e3fbcb9d535d5da3f58cc8de4947df1786fe6a1355960feb05a681/google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\\n\",\n",
      "      \"Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/82/35/b8d3baf8c46695858cb9d8835a53baa1eeb9906ddaf2f728a5f5b640fd1e/google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\\n\",\n",
      "      \"Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a8/7d/da3875b7728bc700eeb28b513754ce237c04ac7cbf8559d76b0464ee01cb/grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\\n\",\n",
      "      \"Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7d/14/ab47972ac79b6e7b03c8be3a7ef44b530a60e69555668dbbf08fc5692a98/google_crc32c-1.6.0-cp311-cp311-macosx_12_0_arm64.whl (30 kB)\\n\",\n",
      "      \"Requirement already satisfied: tzdata>=2022.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (2024.2)\\n\",\n",
      "      \"Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (0.6.1)\\n\",\n",
      "      \"Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c4/a2/78a4c5c3e3ae3bd209519da5a4fc6669a5f3d06423d466028d01e7fbbbce/grpcio_tools-1.68.0-cp311-cp311-macosx_10_9_universal2.whl (5.6 MB)\\n\",\n",
      "      \"\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m5.6/5.6 MB\\u001b[0m \\u001b[31m264.4 kB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m00:01\\u001b[0m00:02\\u001b[0m\\n\",\n",
      "      \"\\u001b[?25hCollecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/9b/fb/a70a4214956182e0d7a9099ab17d50bfcba1056188e9b14f35b9e2b62a0d/portalocker-2.10.1-py3-none-any.whl (18 kB)\\n\",\n",
      "      \"Requirement already satisfied: setuptools in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (75.5.0)\\n\",\n",
      "      \"Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/2a/e5/db6d438da759efbb488c4f3fbdab7764492ff3c3f953132efa6b9f0e9e53/h2-4.1.0-py3-none-any.whl (57 kB)\\n\",\n",
      "      \"Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\\n\",\n",
      "      \"Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d7/de/85a784bcc4a3779d1753a7ec2dee5de90e18c7bcf402e71b51fcf150b129/hyperframe-6.0.1-py3-none-any.whl (12 kB)\\n\",\n",
      "      \"Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\\n\",\n",
      "      \"  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d5/34/e8b383f35b77c402d28563d2b8f83159319b509bc5f760b15d60b0abf165/hpack-4.0.0-py3-none-any.whl (32 kB)\\n\",\n",
      "      \"Building wheels for collected packages: docx2txt, pypika\\n\",\n",
      "      \"  Building wheel for docx2txt (setup.py) ... \\u001b[?25ldone\\n\",\n",
      "      \"\\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=26746b7841d8f93ebcc82a30ff0b0c915d7f5bbd371225b4b55240f87cddb01c\\n\",\n",
      "      \"  Stored in directory: /Users/ganga/Library/Caches/pip/wheels/c4/03/59/df04cbcd5d012f3ecfb3670eb6ad72a5d29a8e651dabbd38ee\\n\",\n",
      "      \"  Building wheel for pypika (pyproject.toml) ... \\u001b[?25ldone\\n\",\n",
      "      \"\\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=cfeed010bf0ccccbdce8bf0f9cf921c15ab53e362d510992888e0b5c36393eea\\n\",\n",
      "      \"  Stored in directory: /Users/ganga/Library/Caches/pip/wheels/25/f2/c2/d448de95a3b62d6a57978ebc61d80c7b4ae79ca0a2bcfdcb5b\\n\",\n",
      "      \"Successfully built docx2txt pypika\\n\",\n",
      "      \"Installing collected packages: sortedcontainers, schema, pypika, mpmath, monotonic, flatbuffers, durationpy, docx2txt, appdirs, wsproto, websockets, uvloop, uvicorn, uv, types-requests, tomli-w, tomli, tabulate, sympy, SQLAlchemy, shellingham, pytube, pysocks, pysbd, pyproject_hooks, pypdf, pyjwt, proto-plus, propcache, portalocker, pluggy, parameterized, outcome, orjson, opentelemetry-util-http, opentelemetry-proto, oauthlib, numpy, nodeenv, networkx, mypy-extensions, multidict, mmh3, mdurl, marshmallow, jsonref, jsonpickle, jsonpatch, json-repair, jiter, iniconfig, importlib-resources, hyperframe, humanfriendly, httpx-sse, httptools, hpack, grpcio, googleapis-common-protos, google-crc32c, frozenlist, fastavro, docstring-parser, deprecation, bcrypt, backoff, asgiref, aiohappyeyeballs, yarl, watchfiles, typing-inspect, trio, tiktoken, starlette, shapely, requests-toolbelt, requests-oauthlib, pytest, pyright, pylance, posthog, opentelemetry-exporter-otlp-proto-common, markdown-it-py, h2, grpcio-tools, grpcio-status, gptcache, google-resumable-media, cryptography, coloredlogs, chroma-hnswlib, build, aiosignal, trio-websocket, rich, pydantic-settings, openai, onnxruntime, langsmith, lancedb, kubernetes, grpc-google-iam-v1, google-api-core, fastapi, dataclasses-json, aiohttp, typer, selenium, qdrant-client, pyvis, opentelemetry-instrumentation, litellm, langchain-core, google-cloud-core, cohere, auth0-python, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mem0ai, langchain-text-splitters, langchain-openai, instructor, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, opentelemetry-instrumentation-fastapi, langchain, google-cloud-aiplatform, langchain-community, chromadb, langchain-experimental, langchain-cohere, embedchain, crewai-tools, crewai\\n\",\n",
      "      \"  Attempting uninstall: SQLAlchemy\\n\",\n",
      "      \"    Found existing installation: SQLAlchemy 2.0.36\\n\",\n",
      "      \"    Uninstalling SQLAlchemy-2.0.36:\\n\",\n",
      "      \"      Successfully uninstalled SQLAlchemy-2.0.36\\n\",\n",
      "      \"  Attempting uninstall: numpy\\n\",\n",
      "      \"    Found existing installation: numpy 2.1.3\\n\",\n",
      "      \"    Uninstalling numpy-2.1.3:\\n\",\n",
      "      \"      Successfully uninstalled numpy-2.1.3\\n\",\n",
      "      \"Successfully installed SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.3 aiohttp-3.11.4 aiosignal-1.3.1 appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.7.2 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.20 cohere-5.11.4 coloredlogs-15.0.1 crewai-0.80.0 crewai-tools-0.14.0 cryptography-43.0.3 dataclasses-json-0.6.7 deprecation-2.1.0 docstring-parser-0.16 docx2txt-0.8 durationpy-0.9 embedchain-0.1.125 fastapi-0.115.5 fastavro-1.9.7 flatbuffers-24.3.25 frozenlist-1.5.0 google-api-core-2.23.0 google-cloud-aiplatform-1.72.0 google-cloud-bigquery-3.27.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.13.1 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.66.0 gptcache-0.1.44 grpc-google-iam-v1-0.13.1 grpcio-1.68.0 grpcio-status-1.68.0 grpcio-tools-1.68.0 h2-4.1.0 hpack-4.0.0 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 hyperframe-6.0.1 importlib-resources-6.4.5 iniconfig-2.0.0 instructor-1.6.4 jiter-0.6.1 json-repair-0.30.2 jsonpatch-1.33 jsonpickle-4.0.0 jsonref-1.1.0 kubernetes-31.0.0 lancedb-0.16.0 langchain-0.3.7 langchain-cohere-0.3.1 langchain-community-0.3.7 langchain-core-0.3.19 langchain-experimental-0.3.3 langchain-openai-0.2.9 langchain-text-splitters-0.3.2 langsmith-0.1.143 litellm-1.52.10 markdown-it-py-3.0.0 marshmallow-3.23.1 mdurl-0.1.2 mem0ai-0.1.29 mmh3-5.0.1 monotonic-1.6 mpmath-1.3.0 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 nodeenv-1.9.1 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.20.0 openai-1.54.5 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-exporter-otlp-proto-http-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-util-http-0.49b2 orjson-3.10.11 outcome-1.3.0.post0 parameterized-0.9.0 pluggy-1.5.0 portalocker-2.10.1 posthog-3.7.2 propcache-0.2.0 proto-plus-1.25.0 pydantic-settings-2.6.1 pyjwt-2.10.0 pylance-0.19.2 pypdf-5.1.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.389 pysbd-0.3.4 pysocks-1.7.1 pytest-8.3.3 pytube-15.0.0 pyvis-0.3.2 qdrant-client-1.12.1 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-13.9.4 schema-0.7.7 selenium-4.26.1 shapely-2.0.6 shellingham-1.5.4 sortedcontainers-2.4.0 starlette-0.41.3 sympy-1.13.3 tabulate-0.9.0 tiktoken-0.7.0 tomli-2.1.0 tomli-w-1.1.0 trio-0.27.0 trio-websocket-0.11.1 typer-0.13.1 types-requests-2.32.0.20241016 typing-inspect-0.9.0 uv-0.5.2 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0 websockets-14.1 wsproto-1.2.0 yarl-1.17.2\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"!pip install crewai\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"ename\": \"OSError\",\n",
      "     \"evalue\": \"source code not available\",\n",
      "     \"output_type\": \"error\",\n",
      "     \"traceback\": [\n",
      "      \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
      "      \"\\u001b[0;31mOSError\\u001b[0m                                   Traceback (most recent call last)\",\n",
      "      \"Cell \\u001b[0;32mIn[2], line 6\\u001b[0m\\n\\u001b[1;32m      3\\u001b[0m \\u001b[38;5;28;01mfrom\\u001b[39;00m \\u001b[38;5;21;01mcrewai\\u001b[39;00m\\u001b[38;5;21;01m.\\u001b[39;00m\\u001b[38;5;21;01mproject\\u001b[39;00m \\u001b[38;5;28;01mimport\\u001b[39;00m CrewBase, agent, crew, task\\n\\u001b[1;32m      4\\u001b[0m \\u001b[38;5;28;01mfrom\\u001b[39;00m \\u001b[38;5;21;01mcrewai_tools\\u001b[39;00m \\u001b[38;5;28;01mimport\\u001b[39;00m SerperDevTool\\n\\u001b[0;32m----> 6\\u001b[0m \\u001b[38;5;129;43m@CrewBase\\u001b[39;49m\\n\\u001b[1;32m      7\\u001b[0m \\u001b[38;5;28;43;01mclass\\u001b[39;49;00m\\u001b[43m \\u001b[49m\\u001b[38;5;21;43;01mLatestAiDevelopmentCrew\\u001b[39;49;00m\\u001b[43m(\\u001b[49m\\u001b[43m)\\u001b[49m\\u001b[43m:\\u001b[49m\\n\\u001b[1;32m      8\\u001b[0m \\u001b[38;5;250;43m    \\u001b[39;49m\\u001b[38;5;124;43;03m\\\"\\\"\\\"LatestAiDevelopment crew\\\"\\\"\\\"\\u001b[39;49;00m\\n\\u001b[1;32m     10\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[38;5;129;43m@agent\\u001b[39;49m\\n\\u001b[1;32m     11\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[38;5;28;43;01mdef\\u001b[39;49;00m\\u001b[43m \\u001b[49m\\u001b[38;5;21;43mresearcher\\u001b[39;49m\\u001b[43m(\\u001b[49m\\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[43m)\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;241;43m-\\u001b[39;49m\\u001b[38;5;241;43m>\\u001b[39;49m\\u001b[43m \\u001b[49m\\u001b[43mAgent\\u001b[49m\\u001b[43m:\\u001b[49m\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/crewai/project/crew_base.py:14\\u001b[0m, in \\u001b[0;36mCrewBase\\u001b[0;34m(cls)\\u001b[0m\\n\\u001b[1;32m     13\\u001b[0m \\u001b[38;5;28;01mdef\\u001b[39;00m \\u001b[38;5;21mCrewBase\\u001b[39m(\\u001b[38;5;28mcls\\u001b[39m: T) \\u001b[38;5;241m-\\u001b[39m\\u001b[38;5;241m>\\u001b[39m T:\\n\\u001b[0;32m---> 14\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[38;5;28;43;01mclass\\u001b[39;49;00m\\u001b[43m \\u001b[49m\\u001b[38;5;21;43;01mWrappedClass\\u001b[39;49;00m\\u001b[43m(\\u001b[49m\\u001b[38;5;28;43mcls\\u001b[39;49m\\u001b[43m)\\u001b[49m\\u001b[43m:\\u001b[49m\\u001b[43m  \\u001b[49m\\u001b[38;5;66;43;03m# type: ignore\\u001b[39;49;00m\\n\\u001b[1;32m     15\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mis_crew_class\\u001b[49m\\u001b[43m:\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;28;43mbool\\u001b[39;49m\\u001b[43m \\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43m \\u001b[49m\\u001b[38;5;28;43;01mTrue\\u001b[39;49;00m\\u001b[43m  \\u001b[49m\\u001b[38;5;66;43;03m# type: ignore\\u001b[39;49;00m\\n\\u001b[1;32m     17\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[38;5;66;43;03m# Get the directory of the class being decorated\\u001b[39;49;00m\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/crewai/project/crew_base.py:18\\u001b[0m, in \\u001b[0;36mCrewBase.<locals>.WrappedClass\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m     15\\u001b[0m is_crew_class: \\u001b[38;5;28mbool\\u001b[39m \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mTrue\\u001b[39;00m  \\u001b[38;5;66;03m# type: ignore\\u001b[39;00m\\n\\u001b[1;32m     17\\u001b[0m \\u001b[38;5;66;03m# Get the directory of the class being decorated\\u001b[39;00m\\n\\u001b[0;32m---> 18\\u001b[0m base_directory \\u001b[38;5;241m=\\u001b[39m Path(\\u001b[43minspect\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mgetfile\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;28;43mcls\\u001b[39;49m\\u001b[43m)\\u001b[49m)\\u001b[38;5;241m.\\u001b[39mparent\\n\\u001b[1;32m     20\\u001b[0m original_agents_config_path \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mgetattr\\u001b[39m(\\n\\u001b[1;32m     21\\u001b[0m     \\u001b[38;5;28mcls\\u001b[39m, \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124magents_config\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m, \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mconfig/agents.yaml\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m     22\\u001b[0m )\\n\\u001b[1;32m     23\\u001b[0m original_tasks_config_path \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mgetattr\\u001b[39m(\\u001b[38;5;28mcls\\u001b[39m, \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mtasks_config\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m, \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mconfig/tasks.yaml\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m)\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/inspect.py:904\\u001b[0m, in \\u001b[0;36mgetfile\\u001b[0;34m(object)\\u001b[0m\\n\\u001b[1;32m    902\\u001b[0m             \\u001b[38;5;28;01mreturn\\u001b[39;00m module\\u001b[38;5;241m.\\u001b[39m\\u001b[38;5;18m__file__\\u001b[39m\\n\\u001b[1;32m    903\\u001b[0m         \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;28mobject\\u001b[39m\\u001b[38;5;241m.\\u001b[39m\\u001b[38;5;18m__module__\\u001b[39m \\u001b[38;5;241m==\\u001b[39m \\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124m__main__\\u001b[39m\\u001b[38;5;124m'\\u001b[39m:\\n\\u001b[0;32m--> 904\\u001b[0m             \\u001b[38;5;28;01mraise\\u001b[39;00m \\u001b[38;5;167;01mOSError\\u001b[39;00m(\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124msource code not available\\u001b[39m\\u001b[38;5;124m'\\u001b[39m)\\n\\u001b[1;32m    905\\u001b[0m     \\u001b[38;5;28;01mraise\\u001b[39;00m \\u001b[38;5;167;01mTypeError\\u001b[39;00m(\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;132;01m{!r}\\u001b[39;00m\\u001b[38;5;124m is a built-in class\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;241m.\\u001b[39mformat(\\u001b[38;5;28mobject\\u001b[39m))\\n\\u001b[1;32m    906\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m ismethod(\\u001b[38;5;28mobject\\u001b[39m):\\n\",\n",
      "      \"\\u001b[0;31mOSError\\u001b[0m: source code not available\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# src/latest_ai_development/crew.py\\n\",\n",
      "    \"from crewai import Agent, Crew, Process, Task\\n\",\n",
      "    \"from crewai.project import CrewBase, agent, crew, task\\n\",\n",
      "    \"from crewai_tools import SerperDevTool\\n\",\n",
      "    \"\\n\",\n",
      "    \"@CrewBase\\n\",\n",
      "    \"class LatestAiDevelopmentCrew():\\n\",\n",
      "    \"    \\\"\\\"\\\"LatestAiDevelopment crew\\\"\\\"\\\"\\n\",\n",
      "    \"\\n\",\n",
      "    \"    @agent\\n\",\n",
      "    \"    def researcher(self) -> Agent:\\n\",\n",
      "    \"        return Agent(\\n\",\n",
      "    \"        config=self.agents_config['researcher'],\\n\",\n",
      "    \"        verbose=True,\\n\",\n",
      "    \"        tools=[SerperDevTool()]\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"\\n\",\n",
      "    \"    @agent\\n\",\n",
      "    \"    def reporting_analyst(self) -> Agent:\\n\",\n",
      "    \"        return Agent(\\n\",\n",
      "    \"        config=self.agents_config['reporting_analyst'],\\n\",\n",
      "    \"        verbose=True\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"\\n\",\n",
      "    \"    @task\\n\",\n",
      "    \"    def research_task(self) -> Task:\\n\",\n",
      "    \"        return Task(\\n\",\n",
      "    \"        config=self.tasks_config['research_task'],\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"\\n\",\n",
      "    \"    @task\\n\",\n",
      "    \"    def reporting_task(self) -> Task:\\n\",\n",
      "    \"        return Task(\\n\",\n",
      "    \"        config=self.tasks_config['reporting_task'],\\n\",\n",
      "    \"        output_file='output/report.md' # This is the file that will be contain the final report.\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"\\n\",\n",
      "    \"    @crew\\n\",\n",
      "    \"    def crew(self) -> Crew:\\n\",\n",
      "    \"        \\\"\\\"\\\"Creates the LatestAiDevelopment crew\\\"\\\"\\\"\\n\",\n",
      "    \"        return Crew(\\n\",\n",
      "    \"        agents=self.agents, # Automatically created by the @agent decorator\\n\",\n",
      "    \"        tasks=self.tasks, # Automatically created by the @task decorator\\n\",\n",
      "    \"        process=Process.sequential,\\n\",\n",
      "    \"        verbose=True,\\n\",\n",
      "    \"        ) \\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"#!/usr/bin/env python\\n\",\n",
      "    \"# src/latest_ai_development/main.py\\n\",\n",
      "    \"import sys\\n\",\n",
      "    \"from latest_ai_development.crew import LatestAiDevelopmentCrew\\n\",\n",
      "    \"\\n\",\n",
      "    \"def run():\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Run the crew.\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    inputs = {\\n\",\n",
      "    \"      'topic': 'AI Agents'\\n\",\n",
      "    \"    }\\n\",\n",
      "    \"    LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)\\n\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"llmops\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 2\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# tasks.yaml\n",
      "================================================================================\n",
      "\n",
      "# src/latest_ai_development/config/tasks.yaml\n",
      "research_task:\n",
      "  description: >\n",
      "    Conduct a thorough research about {topic}\n",
      "    Make sure you find any interesting and relevant information given\n",
      "    the current year is 2024.\n",
      "  expected_output: >\n",
      "    A list with 10 bullet points of the most relevant information about {topic}\n",
      "  agent: researcher\n",
      "\n",
      "reporting_task:\n",
      "  description: >\n",
      "    Review the context you got and expand each topic into a full section for a report.\n",
      "    Make sure the report is detailed and contains any and all relevant information.\n",
      "  expected_output: >\n",
      "    A fully fledge reports with the mains topics, each with a full section of information.\n",
      "    Formatted as markdown without '```'\n",
      "  agent: reporting_analyst\n",
      "  output_file: report.md\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461\n",
      "creation_time: 1732004080697\n",
      "experiment_id: '336741345537322461'\n",
      "last_update_time: 1732004080697\n",
      "lifecycle_stage: active\n",
      "name: youtube-summarizer\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts\n",
      "end_time: 1732004251458\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 907f1ecd64ca4ec2919e1657da05494b\n",
      "run_name: abrasive-cod-859\n",
      "run_uuid: 907f1ecd64ca4ec2919e1657da05494b\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004249085\n",
      "status: 3\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/03_MLFlow_monitoring.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Model Evaluation for YouTube Summarizer with MLflow\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook evaluates the YouTube summarizer model using MLflow to track metrics and experiments.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"import pandas as pd\\n\",\n",
      "    \"import numpy as np\\n\",\n",
      "    \"from transformers import pipeline\\n\",\n",
      "    \"from rouge_score import rouge_scorer\\n\",\n",
      "    \"from nltk.translate.bleu_score import sentence_bleu\\n\",\n",
      "    \"import nltk\\n\",\n",
      "    \"import matplotlib.pyplot as plt\\n\",\n",
      "    \"import seaborn as sns\\n\",\n",
      "    \"import mlflow\\n\",\n",
      "    \"import json\\n\",\n",
      "    \"from typing import Dict, List, Any\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Download required NLTK data\\n\",\n",
      "    \"nltk.download('punkt')\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Load Model from MLflow\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def load_model_from_mlflow(run_id: str):\\n\",\n",
      "    \"    \\\"\\\"\\\"Load the YouTube summarizer model from MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    model_uri = f\\\"runs:/{run_id}/youtube_summarizer\\\"\\n\",\n",
      "    \"    return mlflow.pyfunc.load_model(model_uri)\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Replace with your run_id from the training notebook\\n\",\n",
      "    \"RUN_ID = \\\"your_run_id_here\\\"\\n\",\n",
      "    \"model = load_model_from_mlflow(RUN_ID)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Prepare Test Data\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def prepare_test_data() -> List[Dict[str, str]]:\\n\",\n",
      "    \"    \\\"\\\"\\\"Prepare test data with YouTube videos and reference summaries\\\"\\\"\\\"\\n\",\n",
      "    \"    # Replace with your actual test data\\n\",\n",
      "    \"    return [\\n\",\n",
      "    \"        {\\n\",\n",
      "    \"            \\\"video_url\\\": \\\"https://www.youtube.com/watch?v=example1\\\",\\n\",\n",
      "    \"            \\\"reference_summary\\\": \\\"Reference summary for video 1\\\"\\n\",\n",
      "    \"        },\\n\",\n",
      "    \"        {\\n\",\n",
      "    \"            \\\"video_url\\\": \\\"https://www.youtube.com/watch?v=example2\\\",\\n\",\n",
      "    \"            \\\"reference_summary\\\": \\\"Reference summary for video 2\\\"\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    ]\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Evaluation Metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def calculate_metrics(predicted_summary: str, reference_summary: str) -> Dict[str, float]:\\n\",\n",
      "    \"    \\\"\\\"\\\"Calculate various evaluation metrics\\\"\\\"\\\"\\n\",\n",
      "    \"    # ROUGE scores\\n\",\n",
      "    \"    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\\n\",\n",
      "    \"    rouge_scores = scorer.score(reference_summary, predicted_summary)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # BLEU score\\n\",\n",
      "    \"    reference = [reference_summary.split()]\\n\",\n",
      "    \"    candidate = predicted_summary.split()\\n\",\n",
      "    \"    bleu = sentence_bleu(reference, candidate)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Summary length metrics\\n\",\n",
      "    \"    pred_length = len(predicted_summary.split())\\n\",\n",
      "    \"    ref_length = len(reference_summary.split())\\n\",\n",
      "    \"    length_ratio = pred_length / ref_length if ref_length > 0 else 0\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return {\\n\",\n",
      "    \"        'rouge1_precision': rouge_scores['rouge1'].precision,\\n\",\n",
      "    \"        'rouge1_recall': rouge_scores['rouge1'].recall,\\n\",\n",
      "    \"        'rouge1_f1': rouge_scores['rouge1'].fmeasure,\\n\",\n",
      "    \"        'rouge2_f1': rouge_scores['rouge2'].fmeasure,\\n\",\n",
      "    \"        'rougeL_f1': rouge_scores['rougeL'].fmeasure,\\n\",\n",
      "    \"        'bleu_score': bleu,\\n\",\n",
      "    \"        'summary_length_ratio': length_ratio,\\n\",\n",
      "    \"        'predicted_length': pred_length,\\n\",\n",
      "    \"        'reference_length': ref_length\\n\",\n",
      "    \"    }\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## MLflow Evaluation Pipeline\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def evaluate_model_with_mlflow(model, test_data: List[Dict[str, str]]):\\n\",\n",
      "    \"    \\\"\\\"\\\"Evaluate model and log results to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    mlflow.set_experiment(\\\"youtube-summarizer-evaluation\\\")\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    with mlflow.start_run(run_name=\\\"model_evaluation\\\") as run:\\n\",\n",
      "    \"        all_metrics = []\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log model parameters\\n\",\n",
      "    \"        model_params = model.get_config() if hasattr(model, 'get_config') else {}\\n\",\n",
      "    \"        mlflow.log_params(model_params)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Evaluate each test example\\n\",\n",
      "    \"        for i, example in enumerate(test_data):\\n\",\n",
      "    \"            # Generate summary\\n\",\n",
      "    \"            predicted_summary = model(example['video_url'])\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Calculate metrics\\n\",\n",
      "    \"            metrics = calculate_metrics(predicted_summary, example['reference_summary'])\\n\",\n",
      "    \"            all_metrics.append(metrics)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Log metrics for each example\\n\",\n",
      "    \"            for metric_name, value in metrics.items():\\n\",\n",
      "    \"                mlflow.log_metric(f\\\"example_{i}_{metric_name}\\\", value)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Log summaries as artifacts\\n\",\n",
      "    \"            example_dir = f\\\"example_{i}\\\"\\n\",\n",
      "    \"            os.makedirs(example_dir, exist_ok=True)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            with open(f\\\"{example_dir}/predicted_summary.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"                f.write(predicted_summary)\\n\",\n",
      "    \"            with open(f\\\"{example_dir}/reference_summary.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"                f.write(example['reference_summary'])\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            mlflow.log_artifacts(example_dir)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Calculate and log average metrics\\n\",\n",
      "    \"        avg_metrics = {}\\n\",\n",
      "    \"        for metric in all_metrics[0].keys():\\n\",\n",
      "    \"            avg_value = np.mean([m[metric] for m in all_metrics])\\n\",\n",
      "    \"            avg_metrics[f\\\"avg_{metric}\\\"] = avg_value\\n\",\n",
      "    \"            mlflow.log_metric(f\\\"avg_{metric}\\\", avg_value)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Create and log visualizations\\n\",\n",
      "    \"        create_and_log_visualizations(all_metrics)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return run.info.run_id, avg_metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Create Visualizations\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def create_and_log_visualizations(metrics_list: List[Dict[str, float]]):\\n\",\n",
      "    \"    \\\"\\\"\\\"Create and log visualizations to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    # Convert metrics to DataFrame\\n\",\n",
      "    \"    df = pd.DataFrame(metrics_list)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # ROUGE scores comparison\\n\",\n",
      "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
      "    \"    rouge_metrics = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']\\n\",\n",
      "    \"    df[rouge_metrics].mean().plot(kind='bar')\\n\",\n",
      "    \"    plt.title('Average ROUGE Scores')\\n\",\n",
      "    \"    plt.ylabel('Score')\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('rouge_scores.png')\\n\",\n",
      "    \"    mlflow.log_artifact('rouge_scores.png')\\n\",\n",
      "    \"    plt.close()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Summary length analysis\\n\",\n",
      "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
      "    \"    plt.scatter(df['reference_length'], df['predicted_length'])\\n\",\n",
      "    \"    plt.plot([0, max(df['reference_length'])], [0, max(df['reference_length'])], '--', color='red')\\n\",\n",
      "    \"    plt.xlabel('Reference Summary Length')\\n\",\n",
      "    \"    plt.ylabel('Predicted Summary Length')\\n\",\n",
      "    \"    plt.title('Summary Length Comparison')\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('length_comparison.png')\\n\",\n",
      "    \"    mlflow.log_artifact('length_comparison.png')\\n\",\n",
      "    \"    plt.close()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Metrics distribution\\n\",\n",
      "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
      "    \"    metrics_to_plot = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1', 'bleu_score']\\n\",\n",
      "    \"    df[metrics_to_plot].boxplot()\\n\",\n",
      "    \"    plt.title('Distribution of Evaluation Metrics')\\n\",\n",
      "    \"    plt.ylabel('Score')\\n\",\n",
      "    \"    plt.xticks(rotation=45)\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('metrics_distribution.png')\\n\",\n",
      "    \"    mlflow.log_artifact('metrics_distribution.png')\\n\",\n",
      "    \"    plt.close()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Run Evaluation\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Prepare test data\\n\",\n",
      "    \"test_data = prepare_test_data()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Run evaluation\\n\",\n",
      "    \"run_id, avg_metrics = evaluate_model_with_mlflow(model, test_data)\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(\\\"\\\\nEvaluation Results:\\\")\\n\",\n",
      "    \"print(\\\"==================\\\")\\n\",\n",
      "    \"for metric, value in avg_metrics.items():\\n\",\n",
      "    \"    print(f\\\"{metric}: {value:.4f}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(f\\\"\\\\nMLflow run ID: {run_id}\\\")\\n\",\n",
      "    \"print(\\\"View detailed results in the MLflow UI\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## View Results in MLflow UI\\n\",\n",
      "    \"\\n\",\n",
      "    \"To view the detailed results and visualizations:\\n\",\n",
      "    \"1. Start the MLflow UI by running `mlflow ui` in your terminal\\n\",\n",
      "    \"2. Open http://localhost:5000 in your browser\\n\",\n",
      "    \"3. Navigate to the experiment \\\"youtube-summarizer-evaluation\\\"\\n\",\n",
      "    \"4. Click on the run ID printed above to see detailed metrics and artifacts\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.8.0\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/__init__.py\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/04_MLFlow_evaluation.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Summarizer: Model Setup and Monitoring\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to:\\n\",\n",
      "    \"1. Set up the YouTube summarizer model\\n\",\n",
      "    \"2. Implement monitoring using MLflow\\n\",\n",
      "    \"3. Track model performance metrics\\n\",\n",
      "    \"4. Monitor system resources and latency\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Import required libraries\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"import time\\n\",\n",
      "    \"import mlflow\\n\",\n",
      "    \"import numpy as np\\n\",\n",
      "    \"import pandas as pd\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"from transformers import pipeline\\n\",\n",
      "    \"from rouge_score import rouge_scorer\\n\",\n",
      "    \"import psutil\\n\",\n",
      "    \"import plotly.express as px\\n\",\n",
      "    \"import plotly.graph_objects as go\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 1. Model Setup\\n\",\n",
      "    \"\\n\",\n",
      "    \"First, we'll set up our summarization model using the Hugging Face Transformers library.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def initialize_model():\\n\",\n",
      "    \"    \\\"\\\"\\\"Initialize the summarization model\\\"\\\"\\\"\\n\",\n",
      "    \"    model_name = \\\"facebook/bart-large-cnn\\\"  # You can change this to other models\\n\",\n",
      "    \"    summarizer = pipeline(\\\"summarization\\\", model=model_name)\\n\",\n",
      "    \"    return summarizer\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize the model\\n\",\n",
      "    \"summarizer = initialize_model()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 2. MLflow Setup\\n\",\n",
      "    \"\\n\",\n",
      "    \"Set up MLflow to track experiments and model performance.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Configure MLflow\\n\",\n",
      "    \"mlflow.set_tracking_uri(\\\"sqlite:///mlflow.db\\\")\\n\",\n",
      "    \"mlflow.set_experiment(\\\"youtube_summarizer_monitoring\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"def log_metrics(metrics_dict):\\n\",\n",
      "    \"    \\\"\\\"\\\"Log metrics to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    with mlflow.start_run():\\n\",\n",
      "    \"        mlflow.log_metrics(metrics_dict)\\n\",\n",
      "    \"        mlflow.log_param(\\\"model_name\\\", \\\"facebook/bart-large-cnn\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 3. Performance Monitoring Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"class PerformanceMonitor:\\n\",\n",
      "    \"    def __init__(self):\\n\",\n",
      "    \"        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\\n\",\n",
      "    \"        self.metrics_history = []\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def measure_latency(self, func, *args, **kwargs):\\n\",\n",
      "    \"        \\\"\\\"\\\"Measure execution time of a function\\\"\\\"\\\"\\n\",\n",
      "    \"        start_time = time.time()\\n\",\n",
      "    \"        result = func(*args, **kwargs)\\n\",\n",
      "    \"        end_time = time.time()\\n\",\n",
      "    \"        return result, end_time - start_time\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def measure_resource_usage(self):\\n\",\n",
      "    \"        \\\"\\\"\\\"Measure CPU and memory usage\\\"\\\"\\\"\\n\",\n",
      "    \"        cpu_percent = psutil.cpu_percent()\\n\",\n",
      "    \"        memory_info = psutil.Process().memory_info()\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            'cpu_percent': cpu_percent,\\n\",\n",
      "    \"            'memory_mb': memory_info.rss / 1024 / 1024\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def calculate_rouge_scores(self, prediction, reference):\\n\",\n",
      "    \"        \\\"\\\"\\\"Calculate ROUGE scores\\\"\\\"\\\"\\n\",\n",
      "    \"        scores = self.scorer.score(prediction, reference)\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            'rouge1_f1': scores['rouge1'].fmeasure,\\n\",\n",
      "    \"            'rouge2_f1': scores['rouge2'].fmeasure,\\n\",\n",
      "    \"            'rougeL_f1': scores['rougeL'].fmeasure\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def log_performance(self, latency, rouge_scores, resource_usage):\\n\",\n",
      "    \"        \\\"\\\"\\\"Log all performance metrics\\\"\\\"\\\"\\n\",\n",
      "    \"        metrics = {\\n\",\n",
      "    \"            'latency': latency,\\n\",\n",
      "    \"            **rouge_scores,\\n\",\n",
      "    \"            **resource_usage\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"        self.metrics_history.append(metrics)\\n\",\n",
      "    \"        log_metrics(metrics)\\n\",\n",
      "    \"        return metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 4. Visualization Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def plot_metrics_over_time(metrics_history):\\n\",\n",
      "    \"    \\\"\\\"\\\"Create interactive plots for metrics over time\\\"\\\"\\\"\\n\",\n",
      "    \"    df = pd.DataFrame(metrics_history)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Latency plot\\n\",\n",
      "    \"    fig_latency = px.line(df, y='latency', title='Inference Latency Over Time')\\n\",\n",
      "    \"    fig_latency.show()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Resource usage plot\\n\",\n",
      "    \"    fig_resources = go.Figure()\\n\",\n",
      "    \"    fig_resources.add_trace(go.Scatter(y=df['cpu_percent'], name='CPU %'))\\n\",\n",
      "    \"    fig_resources.add_trace(go.Scatter(y=df['memory_mb'], name='Memory (MB)'))\\n\",\n",
      "    \"    fig_resources.update_layout(title='Resource Usage Over Time')\\n\",\n",
      "    \"    fig_resources.show()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # ROUGE scores plot\\n\",\n",
      "    \"    fig_rouge = go.Figure()\\n\",\n",
      "    \"    for metric in ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']:\\n\",\n",
      "    \"        fig_rouge.add_trace(go.Scatter(y=df[metric], name=metric))\\n\",\n",
      "    \"    fig_rouge.update_layout(title='ROUGE Scores Over Time')\\n\",\n",
      "    \"    fig_rouge.show()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 5. Example Usage\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Initialize the performance monitor\\n\",\n",
      "    \"monitor = PerformanceMonitor()\\n\",\n",
      "    \"\\n\",\n",
      "    \"def process_video(video_id, reference_summary=None):\\n\",\n",
      "    \"    \\\"\\\"\\\"Process a video with monitoring\\\"\\\"\\\"\\n\",\n",
      "    \"    # Get transcript\\n\",\n",
      "    \"    transcript = YouTubeTranscriptApi.get_transcript(video_id)\\n\",\n",
      "    \"    text = ' '.join([t['text'] for t in transcript])\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Generate summary with latency measurement\\n\",\n",
      "    \"    summary, latency = monitor.measure_latency(\\n\",\n",
      "    \"        lambda: summarizer(text, max_length=130, min_length=30)[0]['summary_text']\\n\",\n",
      "    \"    )\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Measure resource usage\\n\",\n",
      "    \"    resource_usage = monitor.measure_resource_usage()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Calculate ROUGE scores if reference summary is provided\\n\",\n",
      "    \"    rouge_scores = monitor.calculate_rouge_scores(summary, reference_summary) if reference_summary else {}\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Log all metrics\\n\",\n",
      "    \"    metrics = monitor.log_performance(latency, rouge_scores, resource_usage)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return summary, metrics\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Example usage\\n\",\n",
      "    \"# video_id = \\\"YOUR_VIDEO_ID\\\"\\n\",\n",
      "    \"# summary, metrics = process_video(video_id)\\n\",\n",
      "    \"# plot_metrics_over_time(monitor.metrics_history)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.8.0\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/README.md\n",
      "================================================================================\n",
      "\n",
      "# YouTube Video Summarizer\n",
      "\n",
      "This project provides a Jupyter notebook that can summarize YouTube videos using their transcripts and Groq's AI model. The summarizer extracts the video's transcription and generates a comprehensive summary focusing on main points, key insights, and important conclusions.\n",
      "\n",
      "## Features\n",
      "\n",
      "- Extract YouTube video transcripts\n",
      "- Process transcripts using Groq's Mixtral-8x7b model\n",
      "- Generate structured summaries with main topics, key points, and conclusions\n",
      "- Support for both standard YouTube URLs and shortened (youtu.be) links\n",
      "\n",
      "## Prerequisites\n",
      "\n",
      "- Python 3.8+\n",
      "- Groq API key\n",
      "- Internet connection for accessing YouTube and Groq API\n",
      "\n",
      "## Installation\n",
      "\n",
      "1. Clone this repository\n",
      "2. Install the required packages:\n",
      "   ```bash\n",
      "   pip install -r requirements.txt\n",
      "   ```\n",
      "3. Create a `.env` file in the project directory and add your Groq API key:\n",
      "   ```\n",
      "   GROQ_API_KEY=your_api_key_here\n",
      "   ```\n",
      "\n",
      "## Usage\n",
      "\n",
      "1. Start Jupyter Notebook:\n",
      "   ```bash\n",
      "   jupyter notebook\n",
      "   ```\n",
      "2. Open `youtube_summarizer.ipynb`\n",
      "3. Run all cells in the notebook\n",
      "4. Replace the example YouTube URL with your desired video URL\n",
      "5. Run the cell to get your summary\n",
      "\n",
      "## Example\n",
      "\n",
      "```python\n",
      "youtube_url = \"https://www.youtube.com/watch?v=your_video_id\"\n",
      "summary = summarize_youtube_video(youtube_url)\n",
      "print(summary)\n",
      "```\n",
      "\n",
      "## Note\n",
      "\n",
      "- The video must have available transcripts (either auto-generated or manually created)\n",
      "- The quality of the summary depends on the quality of the transcript and the video content\n",
      "- Make sure you have sufficient API credits in your Groq account\n",
      "\n",
      "## License\n",
      "\n",
      "This project is open-source and available under the MIT License.\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/01_PoC.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Video Summarizer using Groq\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to create a YouTube video summarizer that:\\n\",\n",
      "    \"1. Takes a YouTube URL as input\\n\",\n",
      "    \"2. Extracts the video's transcription\\n\",\n",
      "    \"3. Uses Groq to generate a concise summary\\n\",\n",
      "    \"\\n\",\n",
      "    \"## Setup and Requirements\\n\",\n",
      "    \"First, we'll install the required packages:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"!pip install youtube-transcript-api groq python-dotenv -q\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Import Required Libraries\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 12,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"import groq\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from urllib.parse import urlparse, parse_qs\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load environment variables\\n\",\n",
      "    \"load_dotenv()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize Groq client\\n\",\n",
      "    \"client = groq.Groq(\\n\",\n",
      "    \"    api_key=os.getenv('GROQ_API_KEY')\\n\",\n",
      "    \")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Helper Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 13,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def extract_video_id(url):\\n\",\n",
      "    \"    \\\"\\\"\\\"Extract YouTube video ID from URL\\\"\\\"\\\"\\n\",\n",
      "    \"    parsed_url = urlparse(url)\\n\",\n",
      "    \"    if parsed_url.hostname == 'youtu.be':\\n\",\n",
      "    \"        return parsed_url.path[1:]\\n\",\n",
      "    \"    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\\n\",\n",
      "    \"        if parsed_url.path == '/watch':\\n\",\n",
      "    \"            return parse_qs(parsed_url.query)['v'][0]\\n\",\n",
      "    \"    return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"def get_transcript(video_id):\\n\",\n",
      "    \"    \\\"\\\"\\\"Get transcript for a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\\n\",\n",
      "    \"        return ' '.join([t['text'] for t in transcript_list])\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error getting transcript: {e}\\\")\\n\",\n",
      "    \"        return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"def summarize_text(text, language=\\\"spanish\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"Summarize text using Groq\\\"\\\"\\\"\\n\",\n",
      "    \"    prompt = f\\\"\\\"\\\"Please provide a comprehensive summary of the following video transcript in {language}. \\n\",\n",
      "    \"    Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"    {text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"    Please structure the summary with:\\n\",\n",
      "    \"    1. Main Topic/Theme\\n\",\n",
      "    \"    2. Key Points\\n\",\n",
      "    \"    3. Important Details\\n\",\n",
      "    \"    4. Conclusions\\\"\\\"\\\"\\n\",\n",
      "    \"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        completion = client.chat.completions.create(\\n\",\n",
      "    \"            model=\\\"llama-3.2-90b-vision-preview\\\",\\n\",\n",
      "    \"            messages=[\\n\",\n",
      "    \"                {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
      "    \"            ],\\n\",\n",
      "    \"            temperature=0.3,\\n\",\n",
      "    \"            max_tokens=2048\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"        return completion.choices[0].message.content\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error in summarization: {e}\\\")\\n\",\n",
      "    \"        return None\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Main Function to Summarize YouTube Video\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 16,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def summarize_youtube_video(url, language=\\\"spanish\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"Main function to summarize a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"    # Extract video ID\\n\",\n",
      "    \"    video_id = extract_video_id(url)\\n\",\n",
      "    \"    if not video_id:\\n\",\n",
      "    \"        return \\\"Invalid YouTube URL\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Get transcript\\n\",\n",
      "    \"    transcript = get_transcript(video_id)\\n\",\n",
      "    \"    if not transcript:\\n\",\n",
      "    \"        return \\\"Could not retrieve transcript\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Generate summary\\n\",\n",
      "    \"    summary = summarize_text(transcript, language)\\n\",\n",
      "    \"    if not summary:\\n\",\n",
      "    \"        return \\\"Could not generate summary\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return summary\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Example Usage\\n\",\n",
      "    \"\\n\",\n",
      "    \"To use this summarizer, you'll need to:\\n\",\n",
      "    \"1. Create a `.env` file in the same directory as this notebook\\n\",\n",
      "    \"2. Add your Groq API key to the `.env` file: `GROQ_API_KEY=your_api_key_here`\\n\",\n",
      "    \"\\n\",\n",
      "    \"Then you can use the summarizer as shown below:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 17,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"**Resumen del video transcript**\\n\",\n",
      "      \"\\n\",\n",
      "      \"**1. Tema principal/Tema**: La venta de acciones de EPM en UNE, una empresa de telecomunicaciones, y su impacto en la industria y la economía local.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**2. Puntos clave**:\\n\",\n",
      "      \"\\n\",\n",
      "      \"* EPM busca vender sus acciones en UNE debido a la intensidad de capital y la rápida evolución tecnológica en la industria de las telecomunicaciones.\\n\",\n",
      "      \"* La venta de acciones se realizará a través de un proceso de enajenación, que requiere la aprobación del Consejo de Medellín.\\n\",\n",
      "      \"* El valor de las acciones se estima en 1,6 billones de pesos, según el valor en libros y la capitalización de UNE.\\n\",\n",
      "      \"* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**3. Detalles importantes**:\\n\",\n",
      "      \"\\n\",\n",
      "      \"* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\\n\",\n",
      "      \"* EPM tiene otros negocios estratégicos, como la generación y distribución de energía, agua y gas, que requieren inversiones importantes.\\n\",\n",
      "      \"* La venta de acciones se realizará a través de un proceso de enajenación, que incluye la oferta a sectores solidarios y especiales, y luego al mercado.\\n\",\n",
      "      \"* El gobierno también está considerando la venta de sus acciones en UNE, lo que podría cambiar el panorama de la industria de las telecomunicaciones en Colombia.\\n\",\n",
      "      \"* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**4. Conclusión**:\\n\",\n",
      "      \"\\n\",\n",
      "      \"* La venta de acciones de EPM en UNE es un proceso complejo que requiere la aprobación del Consejo de Medellín y la valoración de las acciones en el mercado.\\n\",\n",
      "      \"* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, que beneficiarán a la comunidad y la economía local.\\n\",\n",
      "      \"* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\\n\",\n",
      "      \"* La venta de acciones de EPM en UNE puede tener un impacto significativo en el panorama de la industria de las telecomunicaciones en Colombia.\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Example usage\\n\",\n",
      "    \"youtube_url = \\\"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\\\"\\n\",\n",
      "    \"language = \\\"spanish\\\"\\n\",\n",
      "    \"summary = summarize_youtube_video(youtube_url, language)\\n\",\n",
      "    \"print(summary)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/02_MLFlow_implementation.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Video Summarizer with MLflow Integration\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to:\\n\",\n",
      "    \"1. Create a YouTube video summarization chain\\n\",\n",
      "    \"2. Track the chain and prompts using MLflow\\n\",\n",
      "    \"3. Load and use the tracked model\\n\",\n",
      "    \"\\n\",\n",
      "    \"## Setup and Requirements\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 1,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\\n\",\n",
      "      \"Requirement already satisfied: youtube-transcript-api in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.6.3)\\n\",\n",
      "      \"Requirement already satisfied: groq in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.12.0)\\n\",\n",
      "      \"Requirement already satisfied: python-dotenv in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (1.0.1)\\n\",\n",
      "      \"Requirement already satisfied: mlflow in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (2.18.0)\\n\",\n",
      "      \"Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\\n\",\n",
      "      \"Requirement already satisfied: requests in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\\n\",\n",
      "      \"Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.6.2.post1)\\n\",\n",
      "      \"Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.9.0)\\n\",\n",
      "      \"Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (0.27.2)\\n\",\n",
      "      \"Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (2.9.2)\\n\",\n",
      "      \"Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.3.1)\\n\",\n",
      "      \"Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.12.2)\\n\",\n",
      "      \"Requirement already satisfied: mlflow-skinny==2.18.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.18.0)\\n\",\n",
      "      \"Requirement already satisfied: Flask<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.0)\\n\",\n",
      "      \"Requirement already satisfied: alembic!=1.10.0,<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.0)\\n\",\n",
      "      \"Requirement already satisfied: docker<8,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (7.1.0)\\n\",\n",
      "      \"Requirement already satisfied: graphene<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.4.3)\\n\",\n",
      "      \"Requirement already satisfied: markdown<4,>=3.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.7)\\n\",\n",
      "      \"Requirement already satisfied: matplotlib<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.9.2)\\n\",\n",
      "      \"Requirement already satisfied: numpy<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.1.3)\\n\",\n",
      "      \"Requirement already satisfied: pandas<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.2.3)\\n\",\n",
      "      \"Requirement already satisfied: pyarrow<19,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (18.0.0)\\n\",\n",
      "      \"Requirement already satisfied: scikit-learn<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.5.2)\\n\",\n",
      "      \"Requirement already satisfied: scipy<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.1)\\n\",\n",
      "      \"Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.0.36)\\n\",\n",
      "      \"Requirement already satisfied: Jinja2<4,>=2.11 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.4)\\n\",\n",
      "      \"Requirement already satisfied: gunicorn<24 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (23.0.0)\\n\",\n",
      "      \"Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\\n\",\n",
      "      \"Requirement already satisfied: click<9,>=7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\\n\",\n",
      "      \"Requirement already satisfied: cloudpickle<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\\n\",\n",
      "      \"Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.38.0)\\n\",\n",
      "      \"Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\\n\",\n",
      "      \"Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\\n\",\n",
      "      \"Requirement already satisfied: packaging<25 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\\n\",\n",
      "      \"Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.28.3)\\n\",\n",
      "      \"Requirement already satisfied: pyyaml<7,>=5.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\\n\",\n",
      "      \"Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\\n\",\n",
      "      \"Requirement already satisfied: Mako in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\\n\",\n",
      "      \"Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\\n\",\n",
      "      \"Requirement already satisfied: urllib3>=1.26.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\\n\",\n",
      "      \"Requirement already satisfied: Werkzeug>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\\n\",\n",
      "      \"Requirement already satisfied: itsdangerous>=2.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\\n\",\n",
      "      \"Requirement already satisfied: blinker>=1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\\n\",\n",
      "      \"Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.5)\\n\",\n",
      "      \"Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\\n\",\n",
      "      \"Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\\n\",\n",
      "      \"Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\\n\",\n",
      "      \"Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\\n\",\n",
      "      \"Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\\n\",\n",
      "      \"Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\\n\",\n",
      "      \"Requirement already satisfied: contourpy>=1.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.1)\\n\",\n",
      "      \"Requirement already satisfied: cycler>=0.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\\n\",\n",
      "      \"Requirement already satisfied: fonttools>=4.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.55.0)\\n\",\n",
      "      \"Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.7)\\n\",\n",
      "      \"Requirement already satisfied: pillow>=8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.0.0)\\n\",\n",
      "      \"Requirement already satisfied: pyparsing>=2.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.0)\\n\",\n",
      "      \"Requirement already satisfied: pytz>=2020.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\\n\",\n",
      "      \"Requirement already satisfied: tzdata>=2022.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\\n\",\n",
      "      \"Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\\n\",\n",
      "      \"Requirement already satisfied: pydantic-core==2.23.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\\n\",\n",
      "      \"Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.0)\\n\",\n",
      "      \"Requirement already satisfied: joblib>=1.2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.4.2)\\n\",\n",
      "      \"Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.5.0)\\n\",\n",
      "      \"Requirement already satisfied: google-auth~=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.36.0)\\n\",\n",
      "      \"Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\\n\",\n",
      "      \"Requirement already satisfied: zipp>=3.20 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\\n\",\n",
      "      \"Requirement already satisfied: deprecated>=1.2.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\\n\",\n",
      "      \"Requirement already satisfied: six>=1.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\\n\",\n",
      "      \"Requirement already satisfied: wrapt<2,>=1.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\\n\",\n",
      "      \"Requirement already satisfied: smmap<6,>=3.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\\n\",\n",
      "      \"Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\\n\",\n",
      "      \"Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\\n\",\n",
      "      \"Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"!pip install youtube-transcript-api groq python-dotenv mlflow -q\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"import mlflow\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"import groq\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from urllib.parse import urlparse, parse_qs\\n\",\n",
      "    \"import json\\n\",\n",
      "    \"from typing import Dict, Any\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load environment variables\\n\",\n",
      "    \"load_dotenv()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize Groq client\\n\",\n",
      "    \"client = groq.Groq(\\n\",\n",
      "    \"    api_key=os.getenv('GROQ_API_KEY')\\n\",\n",
      "    \")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Define Chain Components\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 8,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"class YouTubeSummaryChain:\\n\",\n",
      "    \"    def __init__(self, model_name: str = \\\"mixtral-8x7b-32768\\\", temperature: float = 0.3):\\n\",\n",
      "    \"        self.model_name = model_name\\n\",\n",
      "    \"        self.temperature = temperature\\n\",\n",
      "    \"        self.prompt_template = \\\"\\\"\\\"\\n\",\n",
      "    \"        Please provide a comprehensive summary of the following video transcript. \\n\",\n",
      "    \"        Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"        {text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"        Please structure the summary with:\\n\",\n",
      "    \"        1. Main Topic/Theme\\n\",\n",
      "    \"        2. Key Points\\n\",\n",
      "    \"        3. Important Details\\n\",\n",
      "    \"        4. Conclusions\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"    def _get_groq_client(self):\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        Initialize and return Groq client\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        :return: Initialized Groq client\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        return groq.Groq(api_key=os.getenv('GROQ_API_KEY'))\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def extract_video_id(self, url: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Extract YouTube video ID from URL\\\"\\\"\\\"\\n\",\n",
      "    \"        parsed_url = urlparse(url)\\n\",\n",
      "    \"        if parsed_url.hostname == 'youtu.be':\\n\",\n",
      "    \"            return parsed_url.path[1:]\\n\",\n",
      "    \"        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\\n\",\n",
      "    \"            if parsed_url.path == '/watch':\\n\",\n",
      "    \"                return parse_qs(parsed_url.query)['v'][0]\\n\",\n",
      "    \"        return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def get_transcript(self, video_id: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Get transcript for a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"        try:\\n\",\n",
      "    \"            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\\n\",\n",
      "    \"            return ' '.join([t['text'] for t in transcript_list])\\n\",\n",
      "    \"        except Exception as e:\\n\",\n",
      "    \"            print(f\\\"Error getting transcript: {e}\\\")\\n\",\n",
      "    \"            return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def summarize_text(self, text: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Summarize text using Groq\\\"\\\"\\\"\\n\",\n",
      "    \"        prompt = self.prompt_template.format(text=text)\\n\",\n",
      "    \"\\n\",\n",
      "    \"        try:\\n\",\n",
      "    \"            # Initialize client only when needed\\n\",\n",
      "    \"            client = self._get_groq_client()\\n\",\n",
      "    \"            completion = client.chat.completions.create(\\n\",\n",
      "    \"                model=self.model_name,\\n\",\n",
      "    \"                messages=[\\n\",\n",
      "    \"                    {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
      "    \"                ],\\n\",\n",
      "    \"                temperature=self.temperature,\\n\",\n",
      "    \"                max_tokens=2048\\n\",\n",
      "    \"            )\\n\",\n",
      "    \"            return completion.choices[0].message.content\\n\",\n",
      "    \"        except Exception as e:\\n\",\n",
      "    \"            print(f\\\"Error in summarization: {e}\\\")\\n\",\n",
      "    \"            return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def __call__(self, url: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Process a YouTube URL and return summary\\\"\\\"\\\"\\n\",\n",
      "    \"        video_id = self.extract_video_id(url)\\n\",\n",
      "    \"        if not video_id:\\n\",\n",
      "    \"            return \\\"Invalid YouTube URL\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        transcript = self.get_transcript(video_id)\\n\",\n",
      "    \"        if not transcript:\\n\",\n",
      "    \"            return \\\"Could not retrieve transcript\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        summary = self.summarize_text(transcript)\\n\",\n",
      "    \"        if not summary:\\n\",\n",
      "    \"            return \\\"Could not generate summary\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return summary\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def get_config(self) -> Dict[str, Any]:\\n\",\n",
      "    \"        \\\"\\\"\\\"Get chain configuration for MLflow tracking\\\"\\\"\\\"\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            \\\"model_name\\\": self.model_name,\\n\",\n",
      "    \"            \\\"temperature\\\": self.temperature,\\n\",\n",
      "    \"            \\\"prompt_template\\\": self.prompt_template\\n\",\n",
      "    \"        }\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## MLflow Integration\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 6,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def log_chain_to_mlflow(chain: YouTubeSummaryChain, experiment_name: str = \\\"youtube-summarizer\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Log the chain configuration and prompt to MLflow\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param chain: YouTubeSummaryChain instance to log\\n\",\n",
      "    \"    :param experiment_name: Name of the MLflow experiment\\n\",\n",
      "    \"    :return: MLflow run ID\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    mlflow.set_experiment(experiment_name)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    with mlflow.start_run() as run:\\n\",\n",
      "    \"        # Log parameters\\n\",\n",
      "    \"        config = chain.get_config()\\n\",\n",
      "    \"        mlflow.log_params({\\n\",\n",
      "    \"            \\\"model_name\\\": config[\\\"model_name\\\"],\\n\",\n",
      "    \"            \\\"temperature\\\": config[\\\"temperature\\\"]\\n\",\n",
      "    \"        })\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log prompt template as artifact\\n\",\n",
      "    \"        with open(\\\"prompt_template.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"            f.write(config[\\\"prompt_template\\\"])\\n\",\n",
      "    \"        mlflow.log_artifact(\\\"prompt_template.txt\\\")\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Create an input example\\n\",\n",
      "    \"        input_example = \\\"https://www.youtube.com/watch?v=example\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log the chain as a custom model\\n\",\n",
      "    \"        mlflow.pyfunc.log_model(\\n\",\n",
      "    \"            artifact_path=\\\"youtube_summarizer\\\",\\n\",\n",
      "    \"            python_model=chain,\\n\",\n",
      "    \"            artifacts={\\\"prompt_template\\\": \\\"prompt_template.txt\\\"},\\n\",\n",
      "    \"            code_path=[\\\".\\\"],\\n\",\n",
      "    \"            pip_requirements=[\\\"youtube-transcript-api\\\", \\\"groq\\\", \\\"python-dotenv\\\"],\\n\",\n",
      "    \"            input_example=input_example\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return run.info.run_id\\n\",\n",
      "    \"\\n\",\n",
      "    \"def load_chain_from_mlflow(run_id: str) -> YouTubeSummaryChain:\\n\",\n",
      "    \"    \\\"\\\"\\\"Load a chain from MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    model_uri = f\\\"runs:/{run_id}/youtube_summarizer\\\"\\n\",\n",
      "    \"    chain = mlflow.pyfunc.load_model(model_uri)\\n\",\n",
      "    \"    return chain\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Example Usage\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 7,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"/Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:2852: UserWarning: The `code_path` argument is replaced by `code_paths` and is deprecated as of MLflow version 2.12.0. This argument will be removed in a future release of MLflow.\\n\",\n",
      "      \"  warnings.warn(\\n\",\n",
      "      \"2024/11/19 03:15:45 INFO mlflow.types.utils: Unsupported type hint: <class 'str'>, skipping schema inference\\n\",\n",
      "      \"2024/11/19 03:15:46 INFO mlflow.types.utils: Unsupported type hint: <class 'str'>, skipping schema inference\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Error getting transcript: \\n\",\n",
      "      \"Could not retrieve a transcript for the video https://www.youtube.com/watch?v=example! This is most likely caused by:\\n\",\n",
      "      \"\\n\",\n",
      "      \"Subtitles are disabled for this video\\n\",\n",
      "      \"\\n\",\n",
      "      \"If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"ename\": \"MlflowException\",\n",
      "     \"evalue\": \"Failed to serialize Python model. Please audit your class variables (e.g. in `__init__()`) for any unpicklable objects. If you're trying to save an external model in your custom pyfunc, Please use the `artifacts` parameter in `mlflow.pyfunc.save_model()`, and load your external model in the `load_context()` method instead. For example:\\n\\nclass MyModel(mlflow.pyfunc.PythonModel):\\n    def load_context(self, context):\\n        model_path = context.artifacts['my_model_path']\\n        // custom load logic here\\n        self.model = load_model(model_path)\\n\\nFor more information, see our full tutorial at: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\\n\\nFull serialization error: cannot pickle '_thread.RLock' object\",\n",
      "     \"output_type\": \"error\",\n",
      "     \"traceback\": [\n",
      "      \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
      "      \"\\u001b[0;31mMlflowException\\u001b[0m                           Traceback (most recent call last)\",\n",
      "      \"Cell \\u001b[0;32mIn[7], line 3\\u001b[0m\\n\\u001b[1;32m      1\\u001b[0m \\u001b[38;5;66;03m# Create and log the chain\\u001b[39;00m\\n\\u001b[1;32m      2\\u001b[0m chain \\u001b[38;5;241m=\\u001b[39m YouTubeSummaryChain()\\n\\u001b[0;32m----> 3\\u001b[0m run_id \\u001b[38;5;241m=\\u001b[39m \\u001b[43mlog_chain_to_mlflow\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mchain\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m      4\\u001b[0m \\u001b[38;5;28mprint\\u001b[39m(\\u001b[38;5;124mf\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mChain logged with run_id: \\u001b[39m\\u001b[38;5;132;01m{\\u001b[39;00mrun_id\\u001b[38;5;132;01m}\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m)\\n\\u001b[1;32m      6\\u001b[0m \\u001b[38;5;66;03m# Load the chain\\u001b[39;00m\\n\",\n",
      "      \"Cell \\u001b[0;32mIn[6], line 28\\u001b[0m, in \\u001b[0;36mlog_chain_to_mlflow\\u001b[0;34m(chain, experiment_name)\\u001b[0m\\n\\u001b[1;32m     25\\u001b[0m input_example \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mhttps://www.youtube.com/watch?v=example\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m     27\\u001b[0m \\u001b[38;5;66;03m# Log the chain as a custom model\\u001b[39;00m\\n\\u001b[0;32m---> 28\\u001b[0m \\u001b[43mmlflow\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpyfunc\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mlog_model\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m     29\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43martifact_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43myoutube_summarizer\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     30\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43mpython_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mchain\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     31\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43martifacts\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43m{\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mprompt_template\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m:\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mprompt_template.txt\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m}\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     32\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43mcode_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43m[\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43m.\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m]\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     33\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43m[\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43myoutube-transcript-api\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mgroq\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mpython-dotenv\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m]\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     34\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43minput_example\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43minput_example\\u001b[49m\\n\\u001b[1;32m     35\\u001b[0m \\u001b[43m\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m     37\\u001b[0m \\u001b[38;5;28;01mreturn\\u001b[39;00m run\\u001b[38;5;241m.\\u001b[39minfo\\u001b[38;5;241m.\\u001b[39mrun_id\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/tracing/provider.py:268\\u001b[0m, in \\u001b[0;36mtrace_disabled.<locals>.wrapper\\u001b[0;34m(*args, **kwargs)\\u001b[0m\\n\\u001b[1;32m    266\\u001b[0m disable()\\n\\u001b[1;32m    267\\u001b[0m \\u001b[38;5;28;01mtry\\u001b[39;00m:\\n\\u001b[0;32m--> 268\\u001b[0m     is_func_called, result \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mTrue\\u001b[39;00m, \\u001b[43mf\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43margs\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43mkwargs\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    269\\u001b[0m \\u001b[38;5;28;01mfinally\\u001b[39;00m:\\n\\u001b[1;32m    270\\u001b[0m     enable()\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3246\\u001b[0m, in \\u001b[0;36mlog_model\\u001b[0;34m(artifact_path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources)\\u001b[0m\\n\\u001b[1;32m   3024\\u001b[0m \\u001b[38;5;129m@format_docstring\\u001b[39m(LOG_MODEL_PARAM_DOCS\\u001b[38;5;241m.\\u001b[39mformat(package_name\\u001b[38;5;241m=\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mscikit-learn\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m))\\n\\u001b[1;32m   3025\\u001b[0m \\u001b[38;5;129m@trace_disabled\\u001b[39m  \\u001b[38;5;66;03m# Suppress traces for internal predict calls while logging model\\u001b[39;00m\\n\\u001b[1;32m   3026\\u001b[0m \\u001b[38;5;28;01mdef\\u001b[39;00m \\u001b[38;5;21mlog_model\\u001b[39m(\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m   3046\\u001b[0m     resources: Optional[Union[\\u001b[38;5;28mstr\\u001b[39m, \\u001b[38;5;28mlist\\u001b[39m[Resource]]] \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mNone\\u001b[39;00m,\\n\\u001b[1;32m   3047\\u001b[0m ):\\n\\u001b[1;32m   3048\\u001b[0m \\u001b[38;5;250m    \\u001b[39m\\u001b[38;5;124;03m\\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[1;32m   3049\\u001b[0m \\u001b[38;5;124;03m    Log a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\\u001b[39;00m\\n\\u001b[1;32m   3050\\u001b[0m \\u001b[38;5;124;03m    artifact for the current run.\\u001b[39;00m\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m   3244\\u001b[0m \\u001b[38;5;124;03m        metadata of the logged model.\\u001b[39;00m\\n\\u001b[1;32m   3245\\u001b[0m \\u001b[38;5;124;03m    \\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[0;32m-> 3246\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[43mModel\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mlog\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m   3247\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43martifact_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43martifact_path\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3248\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mflavor\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmlflow\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpyfunc\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3249\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mloader_module\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mloader_module\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3250\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mdata_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mdata_path\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3251\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mcode_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mcode_path\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m  \\u001b[49m\\u001b[38;5;66;43;03m# deprecated\\u001b[39;49;00m\\n\\u001b[1;32m   3252\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mcode_paths\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mcode_paths\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3253\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpython_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpython_model\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3254\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43martifacts\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43martifacts\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3255\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mconda_env\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconda_env\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3256\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mregistered_model_name\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mregistered_model_name\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3257\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43msignature\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43msignature\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3258\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43minput_example\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43minput_example\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3259\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mawait_registration_for\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mawait_registration_for\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3260\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3261\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mextra_pip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mextra_pip_requirements\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3262\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmetadata\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmetadata\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3263\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmodel_config\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmodel_config\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3264\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mexample_no_conversion\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mexample_no_conversion\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3265\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mstreamable\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mstreamable\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3266\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mresources\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mresources\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3267\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43minfer_code_paths\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43minfer_code_paths\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3268\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43m)\\u001b[49m\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/models/model.py:776\\u001b[0m, in \\u001b[0;36mModel.log\\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\\u001b[0m\\n\\u001b[1;32m    772\\u001b[0m     run_id \\u001b[38;5;241m=\\u001b[39m mlflow\\u001b[38;5;241m.\\u001b[39mtracking\\u001b[38;5;241m.\\u001b[39mfluent\\u001b[38;5;241m.\\u001b[39m_get_or_start_run()\\u001b[38;5;241m.\\u001b[39minfo\\u001b[38;5;241m.\\u001b[39mrun_id\\n\\u001b[1;32m    773\\u001b[0m mlflow_model \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mcls\\u001b[39m(\\n\\u001b[1;32m    774\\u001b[0m     artifact_path\\u001b[38;5;241m=\\u001b[39martifact_path, run_id\\u001b[38;5;241m=\\u001b[39mrun_id, metadata\\u001b[38;5;241m=\\u001b[39mmetadata, resources\\u001b[38;5;241m=\\u001b[39mresources\\n\\u001b[1;32m    775\\u001b[0m )\\n\\u001b[0;32m--> 776\\u001b[0m \\u001b[43mflavor\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43msave_model\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mpath\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mlocal_path\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mmlflow_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmlflow_model\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43mkwargs\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    777\\u001b[0m \\u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\\u001b[39;00m\\n\\u001b[1;32m    778\\u001b[0m \\u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\\u001b[39;00m\\n\\u001b[1;32m    779\\u001b[0m \\u001b[38;5;28;01mfor\\u001b[39;00m pycache \\u001b[38;5;129;01min\\u001b[39;00m Path(local_path)\\u001b[38;5;241m.\\u001b[39mrglob(\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m__pycache__\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m):\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/tracing/provider.py:272\\u001b[0m, in \\u001b[0;36mtrace_disabled.<locals>.wrapper\\u001b[0;34m(*args, **kwargs)\\u001b[0m\\n\\u001b[1;32m    270\\u001b[0m             enable()\\n\\u001b[1;32m    271\\u001b[0m     \\u001b[38;5;28;01melse\\u001b[39;00m:\\n\\u001b[0;32m--> 272\\u001b[0m         is_func_called, result \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mTrue\\u001b[39;00m, \\u001b[43mf\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43margs\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43mkwargs\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    273\\u001b[0m \\u001b[38;5;66;03m# We should only catch the exception from disable() and enable()\\u001b[39;00m\\n\\u001b[1;32m    274\\u001b[0m \\u001b[38;5;66;03m# and let other exceptions propagate.\\u001b[39;00m\\n\\u001b[1;32m    275\\u001b[0m \\u001b[38;5;28;01mexcept\\u001b[39;00m MlflowTracingException \\u001b[38;5;28;01mas\\u001b[39;00m e:\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3006\\u001b[0m, in \\u001b[0;36msave_model\\u001b[0;34m(path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources, **kwargs)\\u001b[0m\\n\\u001b[1;32m   2992\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m _save_model_with_loader_module_and_data_path(\\n\\u001b[1;32m   2993\\u001b[0m         path\\u001b[38;5;241m=\\u001b[39mpath,\\n\\u001b[1;32m   2994\\u001b[0m         loader_module\\u001b[38;5;241m=\\u001b[39mloader_module,\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m   3003\\u001b[0m         infer_code_paths\\u001b[38;5;241m=\\u001b[39minfer_code_paths,\\n\\u001b[1;32m   3004\\u001b[0m     )\\n\\u001b[1;32m   3005\\u001b[0m \\u001b[38;5;28;01melif\\u001b[39;00m second_argument_set_specified:\\n\\u001b[0;32m-> 3006\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[43mmlflow\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpyfunc\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mmodel\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43m_save_model_with_class_artifacts_params\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m   3007\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpath\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpath\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3008\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43msignature\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43msignature\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3009\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mhints\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mhints\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3010\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpython_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpython_model\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3011\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43martifacts\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43martifacts\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3012\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mconda_env\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconda_env\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3013\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mcode_paths\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mcode_paths\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3014\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmlflow_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmlflow_model\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3015\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3016\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mextra_pip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mextra_pip_requirements\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3017\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmodel_config\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmodel_config\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3018\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mstreamable\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mstreamable\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3019\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmodel_code_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmodel_code_path\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3020\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43minfer_code_paths\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43minfer_code_paths\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3021\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43m)\\u001b[49m\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/model.py:382\\u001b[0m, in \\u001b[0;36m_save_model_with_class_artifacts_params\\u001b[0;34m(path, python_model, signature, hints, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config, streamable, model_code_path, infer_code_paths)\\u001b[0m\\n\\u001b[1;32m    378\\u001b[0m \\u001b[38;5;28;01mexcept\\u001b[39;00m \\u001b[38;5;167;01mException\\u001b[39;00m \\u001b[38;5;28;01mas\\u001b[39;00m e:\\n\\u001b[1;32m    379\\u001b[0m     \\u001b[38;5;66;03m# cloudpickle sometimes raises TypeError instead of PicklingError.\\u001b[39;00m\\n\\u001b[1;32m    380\\u001b[0m     \\u001b[38;5;66;03m# catching generic Exception and checking message to handle both cases.\\u001b[39;00m\\n\\u001b[1;32m    381\\u001b[0m     \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mcannot pickle\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m \\u001b[38;5;129;01min\\u001b[39;00m \\u001b[38;5;28mstr\\u001b[39m(e)\\u001b[38;5;241m.\\u001b[39mlower():\\n\\u001b[0;32m--> 382\\u001b[0m         \\u001b[38;5;28;01mraise\\u001b[39;00m MlflowException(\\n\\u001b[1;32m    383\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mFailed to serialize Python model. Please audit your \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    384\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mclass variables (e.g. in `__init__()`) for any \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    385\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124munpicklable objects. If you\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mre trying to save an external model \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    386\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124min your custom pyfunc, Please use the `artifacts` parameter \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    387\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124min `mlflow.pyfunc.save_model()`, and load your external model \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    388\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124min the `load_context()` method instead. For example:\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    389\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mclass MyModel(mlflow.pyfunc.PythonModel):\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    390\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m    def load_context(self, context):\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    391\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m        model_path = context.artifacts[\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mmy_model_path\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124m]\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    392\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m        // custom load logic here\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    393\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m        self.model = load_model(model_path)\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    394\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mFor more information, see our full tutorial at: \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    395\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mhttps://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    396\\u001b[0m             \\u001b[38;5;124mf\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124mFull serialization error: \\u001b[39m\\u001b[38;5;132;01m{\\u001b[39;00me\\u001b[38;5;132;01m}\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    397\\u001b[0m         ) \\u001b[38;5;28;01mfrom\\u001b[39;00m \\u001b[38;5;28;01mNone\\u001b[39;00m\\n\\u001b[1;32m    398\\u001b[0m     \\u001b[38;5;28;01melse\\u001b[39;00m:\\n\\u001b[1;32m    399\\u001b[0m         \\u001b[38;5;28;01mraise\\u001b[39;00m e\\n\",\n",
      "      \"\\u001b[0;31mMlflowException\\u001b[0m: Failed to serialize Python model. Please audit your class variables (e.g. in `__init__()`) for any unpicklable objects. If you're trying to save an external model in your custom pyfunc, Please use the `artifacts` parameter in `mlflow.pyfunc.save_model()`, and load your external model in the `load_context()` method instead. For example:\\n\\nclass MyModel(mlflow.pyfunc.PythonModel):\\n    def load_context(self, context):\\n        model_path = context.artifacts['my_model_path']\\n        // custom load logic here\\n        self.model = load_model(model_path)\\n\\nFor more information, see our full tutorial at: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\\n\\nFull serialization error: cannot pickle '_thread.RLock' object\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Create and log the chain\\n\",\n",
      "    \"chain = YouTubeSummaryChain()\\n\",\n",
      "    \"run_id = log_chain_to_mlflow(chain)\\n\",\n",
      "    \"print(f\\\"Chain logged with run_id: {run_id}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load the chain\\n\",\n",
      "    \"loaded_chain = load_chain_from_mlflow(run_id)\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Use the loaded chain\\n\",\n",
      "    \"youtube_url = \\\"https://www.youtube.com/watch?v=your_video_id\\\"\\n\",\n",
      "    \"summary = loaded_chain(youtube_url)\\n\",\n",
      "    \"print(summary)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## View MLflow Experiment Results\\n\",\n",
      "    \"\\n\",\n",
      "    \"You can view the tracked experiments by running:\\n\",\n",
      "    \"```bash\\n\",\n",
      "    \"mlflow ui\\n\",\n",
      "    \"```\\n\",\n",
      "    \"\\n\",\n",
      "    \"This will start the MLflow UI server where you can see:\\n\",\n",
      "    \"1. All experiment runs\\n\",\n",
      "    \"2. Chain configurations\\n\",\n",
      "    \"3. Prompt templates\\n\",\n",
      "    \"4. Performance metrics (if added)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461\n",
      "creation_time: 1732004080697\n",
      "experiment_id: '336741345537322461'\n",
      "last_update_time: 1732004080697\n",
      "lifecycle_stage: active\n",
      "name: youtube-summarizer\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts\n",
      "end_time: null\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 907f1ecd64ca4ec2919e1657da05494b\n",
      "run_name: abrasive-cod-859\n",
      "run_uuid: 907f1ecd64ca4ec2919e1657da05494b\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004249085\n",
      "status: 1\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/artifacts\n",
      "end_time: 1732004146098\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 0e7459a9e3524678a1970c2b02be4ee9\n",
      "run_name: indecisive-mole-683\n",
      "run_uuid: 0e7459a9e3524678a1970c2b02be4ee9\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004145291\n",
      "status: 4\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/artifacts\n",
      "end_time: 1732004080824\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 0df34b8b49744c4d91061ee809b80f5b\n",
      "run_name: intrigued-koi-579\n",
      "run_uuid: 0df34b8b49744c4d91061ee809b80f5b\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004080797\n",
      "status: 4\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/0/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/0\n",
      "creation_time: 1732004080692\n",
      "experiment_id: '0'\n",
      "last_update_time: 1732004080692\n",
      "lifecycle_stage: active\n",
      "name: Default\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/artifacts\n",
      "end_time: 1732004146098\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 0e7459a9e3524678a1970c2b02be4ee9\n",
      "run_name: indecisive-mole-683\n",
      "run_uuid: 0e7459a9e3524678a1970c2b02be4ee9\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004145291\n",
      "status: 4\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/artifacts\n",
      "end_time: 1732004080824\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 0df34b8b49744c4d91061ee809b80f5b\n",
      "run_name: intrigued-koi-579\n",
      "run_uuid: 0df34b8b49744c4d91061ee809b80f5b\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004080797\n",
      "status: 4\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/0/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/0\n",
      "creation_time: 1732004080692\n",
      "experiment_id: '0'\n",
      "last_update_time: 1732004080692\n",
      "lifecycle_stage: active\n",
      "name: Default\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/a3e0cf31be6941898f90784e623e20ae/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/a3e0cf31be6941898f90784e623e20ae/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/3353294078c140ef8b9ebaee52ff842c/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/3353294078c140ef8b9ebaee52ff842c/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/b4423718012a4c4f8ce1ec028a380915/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/b4423718012a4c4f8ce1ec028a380915/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/3d42bc27e4d9459cb9af992afbb16765/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/3d42bc27e4d9459cb9af992afbb16765/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/5d00f8009c5c49349dbc80b888baeb0f/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/5d00f8009c5c49349dbc80b888baeb0f/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/03_MLFlow_monitoring.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Model Evaluation for YouTube Summarizer with MLflow\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook evaluates the YouTube summarizer model using MLflow to track metrics and experiments.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"import pandas as pd\\n\",\n",
      "    \"import numpy as np\\n\",\n",
      "    \"from transformers import pipeline\\n\",\n",
      "    \"from rouge_score import rouge_scorer\\n\",\n",
      "    \"from nltk.translate.bleu_score import sentence_bleu\\n\",\n",
      "    \"import nltk\\n\",\n",
      "    \"import matplotlib.pyplot as plt\\n\",\n",
      "    \"import seaborn as sns\\n\",\n",
      "    \"import mlflow\\n\",\n",
      "    \"import json\\n\",\n",
      "    \"from typing import Dict, List, Any\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Download required NLTK data\\n\",\n",
      "    \"nltk.download('punkt')\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Load Model from MLflow\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def load_model_from_mlflow(run_id: str):\\n\",\n",
      "    \"    \\\"\\\"\\\"Load the YouTube summarizer model from MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    model_uri = f\\\"runs:/{run_id}/youtube_summarizer\\\"\\n\",\n",
      "    \"    return mlflow.pyfunc.load_model(model_uri)\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Replace with your run_id from the training notebook\\n\",\n",
      "    \"RUN_ID = \\\"your_run_id_here\\\"\\n\",\n",
      "    \"model = load_model_from_mlflow(RUN_ID)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Prepare Test Data\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def prepare_test_data() -> List[Dict[str, str]]:\\n\",\n",
      "    \"    \\\"\\\"\\\"Prepare test data with YouTube videos and reference summaries\\\"\\\"\\\"\\n\",\n",
      "    \"    # Replace with your actual test data\\n\",\n",
      "    \"    return [\\n\",\n",
      "    \"        {\\n\",\n",
      "    \"            \\\"video_url\\\": \\\"https://www.youtube.com/watch?v=example1\\\",\\n\",\n",
      "    \"            \\\"reference_summary\\\": \\\"Reference summary for video 1\\\"\\n\",\n",
      "    \"        },\\n\",\n",
      "    \"        {\\n\",\n",
      "    \"            \\\"video_url\\\": \\\"https://www.youtube.com/watch?v=example2\\\",\\n\",\n",
      "    \"            \\\"reference_summary\\\": \\\"Reference summary for video 2\\\"\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    ]\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Evaluation Metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def calculate_metrics(predicted_summary: str, reference_summary: str) -> Dict[str, float]:\\n\",\n",
      "    \"    \\\"\\\"\\\"Calculate various evaluation metrics\\\"\\\"\\\"\\n\",\n",
      "    \"    # ROUGE scores\\n\",\n",
      "    \"    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\\n\",\n",
      "    \"    rouge_scores = scorer.score(reference_summary, predicted_summary)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # BLEU score\\n\",\n",
      "    \"    reference = [reference_summary.split()]\\n\",\n",
      "    \"    candidate = predicted_summary.split()\\n\",\n",
      "    \"    bleu = sentence_bleu(reference, candidate)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Summary length metrics\\n\",\n",
      "    \"    pred_length = len(predicted_summary.split())\\n\",\n",
      "    \"    ref_length = len(reference_summary.split())\\n\",\n",
      "    \"    length_ratio = pred_length / ref_length if ref_length > 0 else 0\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return {\\n\",\n",
      "    \"        'rouge1_precision': rouge_scores['rouge1'].precision,\\n\",\n",
      "    \"        'rouge1_recall': rouge_scores['rouge1'].recall,\\n\",\n",
      "    \"        'rouge1_f1': rouge_scores['rouge1'].fmeasure,\\n\",\n",
      "    \"        'rouge2_f1': rouge_scores['rouge2'].fmeasure,\\n\",\n",
      "    \"        'rougeL_f1': rouge_scores['rougeL'].fmeasure,\\n\",\n",
      "    \"        'bleu_score': bleu,\\n\",\n",
      "    \"        'summary_length_ratio': length_ratio,\\n\",\n",
      "    \"        'predicted_length': pred_length,\\n\",\n",
      "    \"        'reference_length': ref_length\\n\",\n",
      "    \"    }\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## MLflow Evaluation Pipeline\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def evaluate_model_with_mlflow(model, test_data: List[Dict[str, str]]):\\n\",\n",
      "    \"    \\\"\\\"\\\"Evaluate model and log results to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    mlflow.set_experiment(\\\"youtube-summarizer-evaluation\\\")\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    with mlflow.start_run(run_name=\\\"model_evaluation\\\") as run:\\n\",\n",
      "    \"        all_metrics = []\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log model parameters\\n\",\n",
      "    \"        model_params = model.get_config() if hasattr(model, 'get_config') else {}\\n\",\n",
      "    \"        mlflow.log_params(model_params)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Evaluate each test example\\n\",\n",
      "    \"        for i, example in enumerate(test_data):\\n\",\n",
      "    \"            # Generate summary\\n\",\n",
      "    \"            predicted_summary = model(example['video_url'])\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Calculate metrics\\n\",\n",
      "    \"            metrics = calculate_metrics(predicted_summary, example['reference_summary'])\\n\",\n",
      "    \"            all_metrics.append(metrics)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Log metrics for each example\\n\",\n",
      "    \"            for metric_name, value in metrics.items():\\n\",\n",
      "    \"                mlflow.log_metric(f\\\"example_{i}_{metric_name}\\\", value)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Log summaries as artifacts\\n\",\n",
      "    \"            example_dir = f\\\"example_{i}\\\"\\n\",\n",
      "    \"            os.makedirs(example_dir, exist_ok=True)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            with open(f\\\"{example_dir}/predicted_summary.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"                f.write(predicted_summary)\\n\",\n",
      "    \"            with open(f\\\"{example_dir}/reference_summary.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"                f.write(example['reference_summary'])\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            mlflow.log_artifacts(example_dir)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Calculate and log average metrics\\n\",\n",
      "    \"        avg_metrics = {}\\n\",\n",
      "    \"        for metric in all_metrics[0].keys():\\n\",\n",
      "    \"            avg_value = np.mean([m[metric] for m in all_metrics])\\n\",\n",
      "    \"            avg_metrics[f\\\"avg_{metric}\\\"] = avg_value\\n\",\n",
      "    \"            mlflow.log_metric(f\\\"avg_{metric}\\\", avg_value)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Create and log visualizations\\n\",\n",
      "    \"        create_and_log_visualizations(all_metrics)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return run.info.run_id, avg_metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Create Visualizations\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def create_and_log_visualizations(metrics_list: List[Dict[str, float]]):\\n\",\n",
      "    \"    \\\"\\\"\\\"Create and log visualizations to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    # Convert metrics to DataFrame\\n\",\n",
      "    \"    df = pd.DataFrame(metrics_list)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # ROUGE scores comparison\\n\",\n",
      "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
      "    \"    rouge_metrics = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']\\n\",\n",
      "    \"    df[rouge_metrics].mean().plot(kind='bar')\\n\",\n",
      "    \"    plt.title('Average ROUGE Scores')\\n\",\n",
      "    \"    plt.ylabel('Score')\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('rouge_scores.png')\\n\",\n",
      "    \"    mlflow.log_artifact('rouge_scores.png')\\n\",\n",
      "    \"    plt.close()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Summary length analysis\\n\",\n",
      "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
      "    \"    plt.scatter(df['reference_length'], df['predicted_length'])\\n\",\n",
      "    \"    plt.plot([0, max(df['reference_length'])], [0, max(df['reference_length'])], '--', color='red')\\n\",\n",
      "    \"    plt.xlabel('Reference Summary Length')\\n\",\n",
      "    \"    plt.ylabel('Predicted Summary Length')\\n\",\n",
      "    \"    plt.title('Summary Length Comparison')\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('length_comparison.png')\\n\",\n",
      "    \"    mlflow.log_artifact('length_comparison.png')\\n\",\n",
      "    \"    plt.close()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Metrics distribution\\n\",\n",
      "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
      "    \"    metrics_to_plot = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1', 'bleu_score']\\n\",\n",
      "    \"    df[metrics_to_plot].boxplot()\\n\",\n",
      "    \"    plt.title('Distribution of Evaluation Metrics')\\n\",\n",
      "    \"    plt.ylabel('Score')\\n\",\n",
      "    \"    plt.xticks(rotation=45)\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('metrics_distribution.png')\\n\",\n",
      "    \"    mlflow.log_artifact('metrics_distribution.png')\\n\",\n",
      "    \"    plt.close()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Run Evaluation\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Prepare test data\\n\",\n",
      "    \"test_data = prepare_test_data()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Run evaluation\\n\",\n",
      "    \"run_id, avg_metrics = evaluate_model_with_mlflow(model, test_data)\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(\\\"\\\\nEvaluation Results:\\\")\\n\",\n",
      "    \"print(\\\"==================\\\")\\n\",\n",
      "    \"for metric, value in avg_metrics.items():\\n\",\n",
      "    \"    print(f\\\"{metric}: {value:.4f}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(f\\\"\\\\nMLflow run ID: {run_id}\\\")\\n\",\n",
      "    \"print(\\\"View detailed results in the MLflow UI\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## View Results in MLflow UI\\n\",\n",
      "    \"\\n\",\n",
      "    \"To view the detailed results and visualizations:\\n\",\n",
      "    \"1. Start the MLflow UI by running `mlflow ui` in your terminal\\n\",\n",
      "    \"2. Open http://localhost:5000 in your browser\\n\",\n",
      "    \"3. Navigate to the experiment \\\"youtube-summarizer-evaluation\\\"\\n\",\n",
      "    \"4. Click on the run ID printed above to see detailed metrics and artifacts\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.8.0\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/__init__.py\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/04_MLFlow_evaluation.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Summarizer: Model Setup and Monitoring\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to:\\n\",\n",
      "    \"1. Set up the YouTube summarizer model\\n\",\n",
      "    \"2. Implement monitoring using MLflow\\n\",\n",
      "    \"3. Track model performance metrics\\n\",\n",
      "    \"4. Monitor system resources and latency\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Import required libraries\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"import time\\n\",\n",
      "    \"import mlflow\\n\",\n",
      "    \"import numpy as np\\n\",\n",
      "    \"import pandas as pd\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"from transformers import pipeline\\n\",\n",
      "    \"from rouge_score import rouge_scorer\\n\",\n",
      "    \"import psutil\\n\",\n",
      "    \"import plotly.express as px\\n\",\n",
      "    \"import plotly.graph_objects as go\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 1. Model Setup\\n\",\n",
      "    \"\\n\",\n",
      "    \"First, we'll set up our summarization model using the Hugging Face Transformers library.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def initialize_model():\\n\",\n",
      "    \"    \\\"\\\"\\\"Initialize the summarization model\\\"\\\"\\\"\\n\",\n",
      "    \"    model_name = \\\"facebook/bart-large-cnn\\\"  # You can change this to other models\\n\",\n",
      "    \"    summarizer = pipeline(\\\"summarization\\\", model=model_name)\\n\",\n",
      "    \"    return summarizer\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize the model\\n\",\n",
      "    \"summarizer = initialize_model()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 2. MLflow Setup\\n\",\n",
      "    \"\\n\",\n",
      "    \"Set up MLflow to track experiments and model performance.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Configure MLflow\\n\",\n",
      "    \"mlflow.set_tracking_uri(\\\"sqlite:///mlflow.db\\\")\\n\",\n",
      "    \"mlflow.set_experiment(\\\"youtube_summarizer_monitoring\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"def log_metrics(metrics_dict):\\n\",\n",
      "    \"    \\\"\\\"\\\"Log metrics to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    with mlflow.start_run():\\n\",\n",
      "    \"        mlflow.log_metrics(metrics_dict)\\n\",\n",
      "    \"        mlflow.log_param(\\\"model_name\\\", \\\"facebook/bart-large-cnn\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 3. Performance Monitoring Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"class PerformanceMonitor:\\n\",\n",
      "    \"    def __init__(self):\\n\",\n",
      "    \"        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\\n\",\n",
      "    \"        self.metrics_history = []\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def measure_latency(self, func, *args, **kwargs):\\n\",\n",
      "    \"        \\\"\\\"\\\"Measure execution time of a function\\\"\\\"\\\"\\n\",\n",
      "    \"        start_time = time.time()\\n\",\n",
      "    \"        result = func(*args, **kwargs)\\n\",\n",
      "    \"        end_time = time.time()\\n\",\n",
      "    \"        return result, end_time - start_time\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def measure_resource_usage(self):\\n\",\n",
      "    \"        \\\"\\\"\\\"Measure CPU and memory usage\\\"\\\"\\\"\\n\",\n",
      "    \"        cpu_percent = psutil.cpu_percent()\\n\",\n",
      "    \"        memory_info = psutil.Process().memory_info()\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            'cpu_percent': cpu_percent,\\n\",\n",
      "    \"            'memory_mb': memory_info.rss / 1024 / 1024\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def calculate_rouge_scores(self, prediction, reference):\\n\",\n",
      "    \"        \\\"\\\"\\\"Calculate ROUGE scores\\\"\\\"\\\"\\n\",\n",
      "    \"        scores = self.scorer.score(prediction, reference)\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            'rouge1_f1': scores['rouge1'].fmeasure,\\n\",\n",
      "    \"            'rouge2_f1': scores['rouge2'].fmeasure,\\n\",\n",
      "    \"            'rougeL_f1': scores['rougeL'].fmeasure\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def log_performance(self, latency, rouge_scores, resource_usage):\\n\",\n",
      "    \"        \\\"\\\"\\\"Log all performance metrics\\\"\\\"\\\"\\n\",\n",
      "    \"        metrics = {\\n\",\n",
      "    \"            'latency': latency,\\n\",\n",
      "    \"            **rouge_scores,\\n\",\n",
      "    \"            **resource_usage\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"        self.metrics_history.append(metrics)\\n\",\n",
      "    \"        log_metrics(metrics)\\n\",\n",
      "    \"        return metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 4. Visualization Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def plot_metrics_over_time(metrics_history):\\n\",\n",
      "    \"    \\\"\\\"\\\"Create interactive plots for metrics over time\\\"\\\"\\\"\\n\",\n",
      "    \"    df = pd.DataFrame(metrics_history)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Latency plot\\n\",\n",
      "    \"    fig_latency = px.line(df, y='latency', title='Inference Latency Over Time')\\n\",\n",
      "    \"    fig_latency.show()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Resource usage plot\\n\",\n",
      "    \"    fig_resources = go.Figure()\\n\",\n",
      "    \"    fig_resources.add_trace(go.Scatter(y=df['cpu_percent'], name='CPU %'))\\n\",\n",
      "    \"    fig_resources.add_trace(go.Scatter(y=df['memory_mb'], name='Memory (MB)'))\\n\",\n",
      "    \"    fig_resources.update_layout(title='Resource Usage Over Time')\\n\",\n",
      "    \"    fig_resources.show()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # ROUGE scores plot\\n\",\n",
      "    \"    fig_rouge = go.Figure()\\n\",\n",
      "    \"    for metric in ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']:\\n\",\n",
      "    \"        fig_rouge.add_trace(go.Scatter(y=df[metric], name=metric))\\n\",\n",
      "    \"    fig_rouge.update_layout(title='ROUGE Scores Over Time')\\n\",\n",
      "    \"    fig_rouge.show()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 5. Example Usage\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Initialize the performance monitor\\n\",\n",
      "    \"monitor = PerformanceMonitor()\\n\",\n",
      "    \"\\n\",\n",
      "    \"def process_video(video_id, reference_summary=None):\\n\",\n",
      "    \"    \\\"\\\"\\\"Process a video with monitoring\\\"\\\"\\\"\\n\",\n",
      "    \"    # Get transcript\\n\",\n",
      "    \"    transcript = YouTubeTranscriptApi.get_transcript(video_id)\\n\",\n",
      "    \"    text = ' '.join([t['text'] for t in transcript])\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Generate summary with latency measurement\\n\",\n",
      "    \"    summary, latency = monitor.measure_latency(\\n\",\n",
      "    \"        lambda: summarizer(text, max_length=130, min_length=30)[0]['summary_text']\\n\",\n",
      "    \"    )\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Measure resource usage\\n\",\n",
      "    \"    resource_usage = monitor.measure_resource_usage()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Calculate ROUGE scores if reference summary is provided\\n\",\n",
      "    \"    rouge_scores = monitor.calculate_rouge_scores(summary, reference_summary) if reference_summary else {}\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Log all metrics\\n\",\n",
      "    \"    metrics = monitor.log_performance(latency, rouge_scores, resource_usage)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return summary, metrics\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Example usage\\n\",\n",
      "    \"# video_id = \\\"YOUR_VIDEO_ID\\\"\\n\",\n",
      "    \"# summary, metrics = process_video(video_id)\\n\",\n",
      "    \"# plot_metrics_over_time(monitor.metrics_history)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.8.0\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/README.md\n",
      "================================================================================\n",
      "\n",
      "# YouTube Video Summarizer\n",
      "\n",
      "This project provides a Jupyter notebook that can summarize YouTube videos using their transcripts and Groq's AI model. The summarizer extracts the video's transcription and generates a comprehensive summary focusing on main points, key insights, and important conclusions.\n",
      "\n",
      "## Features\n",
      "\n",
      "- Extract YouTube video transcripts\n",
      "- Process transcripts using Groq's Mixtral-8x7b model\n",
      "- Generate structured summaries with main topics, key points, and conclusions\n",
      "- Support for both standard YouTube URLs and shortened (youtu.be) links\n",
      "\n",
      "## Prerequisites\n",
      "\n",
      "- Python 3.8+\n",
      "- Groq API key\n",
      "- Internet connection for accessing YouTube and Groq API\n",
      "\n",
      "## Installation\n",
      "\n",
      "1. Clone this repository\n",
      "2. Install the required packages:\n",
      "   ```bash\n",
      "   pip install -r requirements.txt\n",
      "   ```\n",
      "3. Create a `.env` file in the project directory and add your Groq API key:\n",
      "   ```\n",
      "   GROQ_API_KEY=your_api_key_here\n",
      "   ```\n",
      "\n",
      "## Usage\n",
      "\n",
      "1. Start Jupyter Notebook:\n",
      "   ```bash\n",
      "   jupyter notebook\n",
      "   ```\n",
      "2. Open `youtube_summarizer.ipynb`\n",
      "3. Run all cells in the notebook\n",
      "4. Replace the example YouTube URL with your desired video URL\n",
      "5. Run the cell to get your summary\n",
      "\n",
      "## Example\n",
      "\n",
      "```python\n",
      "youtube_url = \"https://www.youtube.com/watch?v=your_video_id\"\n",
      "summary = summarize_youtube_video(youtube_url)\n",
      "print(summary)\n",
      "```\n",
      "\n",
      "## Note\n",
      "\n",
      "- The video must have available transcripts (either auto-generated or manually created)\n",
      "- The quality of the summary depends on the quality of the transcript and the video content\n",
      "- Make sure you have sufficient API credits in your Groq account\n",
      "\n",
      "## License\n",
      "\n",
      "This project is open-source and available under the MIT License.\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/01_PoC.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Video Summarizer using Groq\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to create a YouTube video summarizer that:\\n\",\n",
      "    \"1. Takes a YouTube URL as input\\n\",\n",
      "    \"2. Extracts the video's transcription\\n\",\n",
      "    \"3. Uses Groq to generate a concise summary\\n\",\n",
      "    \"\\n\",\n",
      "    \"## Setup and Requirements\\n\",\n",
      "    \"First, we'll install the required packages:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"!pip install youtube-transcript-api groq python-dotenv -q\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Import Required Libraries\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 12,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"import groq\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from urllib.parse import urlparse, parse_qs\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load environment variables\\n\",\n",
      "    \"load_dotenv()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize Groq client\\n\",\n",
      "    \"client = groq.Groq(\\n\",\n",
      "    \"    api_key=os.getenv('GROQ_API_KEY')\\n\",\n",
      "    \")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Helper Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 13,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def extract_video_id(url):\\n\",\n",
      "    \"    \\\"\\\"\\\"Extract YouTube video ID from URL\\\"\\\"\\\"\\n\",\n",
      "    \"    parsed_url = urlparse(url)\\n\",\n",
      "    \"    if parsed_url.hostname == 'youtu.be':\\n\",\n",
      "    \"        return parsed_url.path[1:]\\n\",\n",
      "    \"    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\\n\",\n",
      "    \"        if parsed_url.path == '/watch':\\n\",\n",
      "    \"            return parse_qs(parsed_url.query)['v'][0]\\n\",\n",
      "    \"    return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"def get_transcript(video_id):\\n\",\n",
      "    \"    \\\"\\\"\\\"Get transcript for a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\\n\",\n",
      "    \"        return ' '.join([t['text'] for t in transcript_list])\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error getting transcript: {e}\\\")\\n\",\n",
      "    \"        return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"def summarize_text(text, language=\\\"spanish\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"Summarize text using Groq\\\"\\\"\\\"\\n\",\n",
      "    \"    prompt = f\\\"\\\"\\\"Please provide a comprehensive summary of the following video transcript in {language}. \\n\",\n",
      "    \"    Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"    {text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"    Please structure the summary with:\\n\",\n",
      "    \"    1. Main Topic/Theme\\n\",\n",
      "    \"    2. Key Points\\n\",\n",
      "    \"    3. Important Details\\n\",\n",
      "    \"    4. Conclusions\\\"\\\"\\\"\\n\",\n",
      "    \"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        completion = client.chat.completions.create(\\n\",\n",
      "    \"            model=\\\"llama-3.2-90b-vision-preview\\\",\\n\",\n",
      "    \"            messages=[\\n\",\n",
      "    \"                {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
      "    \"            ],\\n\",\n",
      "    \"            temperature=0.3,\\n\",\n",
      "    \"            max_tokens=2048\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"        return completion.choices[0].message.content\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error in summarization: {e}\\\")\\n\",\n",
      "    \"        return None\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Main Function to Summarize YouTube Video\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 16,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def summarize_youtube_video(url, language=\\\"spanish\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"Main function to summarize a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"    # Extract video ID\\n\",\n",
      "    \"    video_id = extract_video_id(url)\\n\",\n",
      "    \"    if not video_id:\\n\",\n",
      "    \"        return \\\"Invalid YouTube URL\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Get transcript\\n\",\n",
      "    \"    transcript = get_transcript(video_id)\\n\",\n",
      "    \"    if not transcript:\\n\",\n",
      "    \"        return \\\"Could not retrieve transcript\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Generate summary\\n\",\n",
      "    \"    summary = summarize_text(transcript, language)\\n\",\n",
      "    \"    if not summary:\\n\",\n",
      "    \"        return \\\"Could not generate summary\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return summary\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Example Usage\\n\",\n",
      "    \"\\n\",\n",
      "    \"To use this summarizer, you'll need to:\\n\",\n",
      "    \"1. Create a `.env` file in the same directory as this notebook\\n\",\n",
      "    \"2. Add your Groq API key to the `.env` file: `GROQ_API_KEY=your_api_key_here`\\n\",\n",
      "    \"\\n\",\n",
      "    \"Then you can use the summarizer as shown below:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 17,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"**Resumen del video transcript**\\n\",\n",
      "      \"\\n\",\n",
      "      \"**1. Tema principal/Tema**: La venta de acciones de EPM en UNE, una empresa de telecomunicaciones, y su impacto en la industria y la economía local.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**2. Puntos clave**:\\n\",\n",
      "      \"\\n\",\n",
      "      \"* EPM busca vender sus acciones en UNE debido a la intensidad de capital y la rápida evolución tecnológica en la industria de las telecomunicaciones.\\n\",\n",
      "      \"* La venta de acciones se realizará a través de un proceso de enajenación, que requiere la aprobación del Consejo de Medellín.\\n\",\n",
      "      \"* El valor de las acciones se estima en 1,6 billones de pesos, según el valor en libros y la capitalización de UNE.\\n\",\n",
      "      \"* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**3. Detalles importantes**:\\n\",\n",
      "      \"\\n\",\n",
      "      \"* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\\n\",\n",
      "      \"* EPM tiene otros negocios estratégicos, como la generación y distribución de energía, agua y gas, que requieren inversiones importantes.\\n\",\n",
      "      \"* La venta de acciones se realizará a través de un proceso de enajenación, que incluye la oferta a sectores solidarios y especiales, y luego al mercado.\\n\",\n",
      "      \"* El gobierno también está considerando la venta de sus acciones en UNE, lo que podría cambiar el panorama de la industria de las telecomunicaciones en Colombia.\\n\",\n",
      "      \"* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**4. Conclusión**:\\n\",\n",
      "      \"\\n\",\n",
      "      \"* La venta de acciones de EPM en UNE es un proceso complejo que requiere la aprobación del Consejo de Medellín y la valoración de las acciones en el mercado.\\n\",\n",
      "      \"* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, que beneficiarán a la comunidad y la economía local.\\n\",\n",
      "      \"* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\\n\",\n",
      "      \"* La venta de acciones de EPM en UNE puede tener un impacto significativo en el panorama de la industria de las telecomunicaciones en Colombia.\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Example usage\\n\",\n",
      "    \"youtube_url = \\\"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\\\"\\n\",\n",
      "    \"language = \\\"spanish\\\"\\n\",\n",
      "    \"summary = summarize_youtube_video(youtube_url, language)\\n\",\n",
      "    \"print(summary)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/02_MLFlow_implementation.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Video Summarizer with MLflow Integration\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to:\\n\",\n",
      "    \"1. Create a YouTube video summarization chain\\n\",\n",
      "    \"2. Track the chain and prompts using MLflow\\n\",\n",
      "    \"3. Load and use the tracked model\\n\",\n",
      "    \"\\n\",\n",
      "    \"## Setup and Requirements\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 1,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\\n\",\n",
      "      \"Requirement already satisfied: youtube-transcript-api in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.6.3)\\n\",\n",
      "      \"Requirement already satisfied: groq in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.12.0)\\n\",\n",
      "      \"Requirement already satisfied: python-dotenv in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (1.0.1)\\n\",\n",
      "      \"Requirement already satisfied: mlflow in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (2.18.0)\\n\",\n",
      "      \"Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\\n\",\n",
      "      \"Requirement already satisfied: requests in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\\n\",\n",
      "      \"Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.6.2.post1)\\n\",\n",
      "      \"Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.9.0)\\n\",\n",
      "      \"Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (0.27.2)\\n\",\n",
      "      \"Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (2.9.2)\\n\",\n",
      "      \"Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.3.1)\\n\",\n",
      "      \"Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.12.2)\\n\",\n",
      "      \"Requirement already satisfied: mlflow-skinny==2.18.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.18.0)\\n\",\n",
      "      \"Requirement already satisfied: Flask<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.0)\\n\",\n",
      "      \"Requirement already satisfied: alembic!=1.10.0,<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.0)\\n\",\n",
      "      \"Requirement already satisfied: docker<8,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (7.1.0)\\n\",\n",
      "      \"Requirement already satisfied: graphene<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.4.3)\\n\",\n",
      "      \"Requirement already satisfied: markdown<4,>=3.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.7)\\n\",\n",
      "      \"Requirement already satisfied: matplotlib<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.9.2)\\n\",\n",
      "      \"Requirement already satisfied: numpy<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.1.3)\\n\",\n",
      "      \"Requirement already satisfied: pandas<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.2.3)\\n\",\n",
      "      \"Requirement already satisfied: pyarrow<19,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (18.0.0)\\n\",\n",
      "      \"Requirement already satisfied: scikit-learn<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.5.2)\\n\",\n",
      "      \"Requirement already satisfied: scipy<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.1)\\n\",\n",
      "      \"Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.0.36)\\n\",\n",
      "      \"Requirement already satisfied: Jinja2<4,>=2.11 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.4)\\n\",\n",
      "      \"Requirement already satisfied: gunicorn<24 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (23.0.0)\\n\",\n",
      "      \"Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\\n\",\n",
      "      \"Requirement already satisfied: click<9,>=7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\\n\",\n",
      "      \"Requirement already satisfied: cloudpickle<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\\n\",\n",
      "      \"Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.38.0)\\n\",\n",
      "      \"Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\\n\",\n",
      "      \"Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\\n\",\n",
      "      \"Requirement already satisfied: packaging<25 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\\n\",\n",
      "      \"Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.28.3)\\n\",\n",
      "      \"Requirement already satisfied: pyyaml<7,>=5.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\\n\",\n",
      "      \"Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\\n\",\n",
      "      \"Requirement already satisfied: Mako in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\\n\",\n",
      "      \"Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\\n\",\n",
      "      \"Requirement already satisfied: urllib3>=1.26.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\\n\",\n",
      "      \"Requirement already satisfied: Werkzeug>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\\n\",\n",
      "      \"Requirement already satisfied: itsdangerous>=2.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\\n\",\n",
      "      \"Requirement already satisfied: blinker>=1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\\n\",\n",
      "      \"Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.5)\\n\",\n",
      "      \"Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\\n\",\n",
      "      \"Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\\n\",\n",
      "      \"Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\\n\",\n",
      "      \"Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\\n\",\n",
      "      \"Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\\n\",\n",
      "      \"Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\\n\",\n",
      "      \"Requirement already satisfied: contourpy>=1.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.1)\\n\",\n",
      "      \"Requirement already satisfied: cycler>=0.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\\n\",\n",
      "      \"Requirement already satisfied: fonttools>=4.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.55.0)\\n\",\n",
      "      \"Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.7)\\n\",\n",
      "      \"Requirement already satisfied: pillow>=8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.0.0)\\n\",\n",
      "      \"Requirement already satisfied: pyparsing>=2.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.0)\\n\",\n",
      "      \"Requirement already satisfied: pytz>=2020.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\\n\",\n",
      "      \"Requirement already satisfied: tzdata>=2022.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\\n\",\n",
      "      \"Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\\n\",\n",
      "      \"Requirement already satisfied: pydantic-core==2.23.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\\n\",\n",
      "      \"Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.0)\\n\",\n",
      "      \"Requirement already satisfied: joblib>=1.2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.4.2)\\n\",\n",
      "      \"Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.5.0)\\n\",\n",
      "      \"Requirement already satisfied: google-auth~=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.36.0)\\n\",\n",
      "      \"Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\\n\",\n",
      "      \"Requirement already satisfied: zipp>=3.20 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\\n\",\n",
      "      \"Requirement already satisfied: deprecated>=1.2.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\\n\",\n",
      "      \"Requirement already satisfied: six>=1.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\\n\",\n",
      "      \"Requirement already satisfied: wrapt<2,>=1.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\\n\",\n",
      "      \"Requirement already satisfied: smmap<6,>=3.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\\n\",\n",
      "      \"Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\\n\",\n",
      "      \"Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\\n\",\n",
      "      \"Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"!pip install youtube-transcript-api groq python-dotenv mlflow -q\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"import mlflow\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"import groq\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from urllib.parse import urlparse, parse_qs\\n\",\n",
      "    \"import json\\n\",\n",
      "    \"from typing import Dict, Any\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load environment variables\\n\",\n",
      "    \"load_dotenv()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize Groq client\\n\",\n",
      "    \"client = groq.Groq(\\n\",\n",
      "    \"    api_key=os.getenv('GROQ_API_KEY')\\n\",\n",
      "    \")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Define Chain Components\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 8,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"class YouTubeSummaryChain:\\n\",\n",
      "    \"    def __init__(self, model_name: str = \\\"mixtral-8x7b-32768\\\", temperature: float = 0.3):\\n\",\n",
      "    \"        self.model_name = model_name\\n\",\n",
      "    \"        self.temperature = temperature\\n\",\n",
      "    \"        self.prompt_template = \\\"\\\"\\\"\\n\",\n",
      "    \"        Please provide a comprehensive summary of the following video transcript. \\n\",\n",
      "    \"        Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"        {text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"        Please structure the summary with:\\n\",\n",
      "    \"        1. Main Topic/Theme\\n\",\n",
      "    \"        2. Key Points\\n\",\n",
      "    \"        3. Important Details\\n\",\n",
      "    \"        4. Conclusions\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"    def _get_groq_client(self):\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        Initialize and return Groq client\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        :return: Initialized Groq client\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        return groq.Groq(api_key=os.getenv('GROQ_API_KEY'))\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def extract_video_id(self, url: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Extract YouTube video ID from URL\\\"\\\"\\\"\\n\",\n",
      "    \"        parsed_url = urlparse(url)\\n\",\n",
      "    \"        if parsed_url.hostname == 'youtu.be':\\n\",\n",
      "    \"            return parsed_url.path[1:]\\n\",\n",
      "    \"        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\\n\",\n",
      "    \"            if parsed_url.path == '/watch':\\n\",\n",
      "    \"                return parse_qs(parsed_url.query)['v'][0]\\n\",\n",
      "    \"        return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def get_transcript(self, video_id: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Get transcript for a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"        try:\\n\",\n",
      "    \"            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\\n\",\n",
      "    \"            return ' '.join([t['text'] for t in transcript_list])\\n\",\n",
      "    \"        except Exception as e:\\n\",\n",
      "    \"            print(f\\\"Error getting transcript: {e}\\\")\\n\",\n",
      "    \"            return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def summarize_text(self, text: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Summarize text using Groq\\\"\\\"\\\"\\n\",\n",
      "    \"        prompt = self.prompt_template.format(text=text)\\n\",\n",
      "    \"\\n\",\n",
      "    \"        try:\\n\",\n",
      "    \"            # Initialize client only when needed\\n\",\n",
      "    \"            client = self._get_groq_client()\\n\",\n",
      "    \"            completion = client.chat.completions.create(\\n\",\n",
      "    \"                model=self.model_name,\\n\",\n",
      "    \"                messages=[\\n\",\n",
      "    \"                    {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
      "    \"                ],\\n\",\n",
      "    \"                temperature=self.temperature,\\n\",\n",
      "    \"                max_tokens=2048\\n\",\n",
      "    \"            )\\n\",\n",
      "    \"            return completion.choices[0].message.content\\n\",\n",
      "    \"        except Exception as e:\\n\",\n",
      "    \"            print(f\\\"Error in summarization: {e}\\\")\\n\",\n",
      "    \"            return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def __call__(self, url: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Process a YouTube URL and return summary\\\"\\\"\\\"\\n\",\n",
      "    \"        video_id = self.extract_video_id(url)\\n\",\n",
      "    \"        if not video_id:\\n\",\n",
      "    \"            return \\\"Invalid YouTube URL\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        transcript = self.get_transcript(video_id)\\n\",\n",
      "    \"        if not transcript:\\n\",\n",
      "    \"            return \\\"Could not retrieve transcript\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        summary = self.summarize_text(transcript)\\n\",\n",
      "    \"        if not summary:\\n\",\n",
      "    \"            return \\\"Could not generate summary\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return summary\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def get_config(self) -> Dict[str, Any]:\\n\",\n",
      "    \"        \\\"\\\"\\\"Get chain configuration for MLflow tracking\\\"\\\"\\\"\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            \\\"model_name\\\": self.model_name,\\n\",\n",
      "    \"            \\\"temperature\\\": self.temperature,\\n\",\n",
      "    \"            \\\"prompt_template\\\": self.prompt_template\\n\",\n",
      "    \"        }\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## MLflow Integration\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 11,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# Add this after the imports\\n\",\n",
      "    \"# Set up MLflow tracking\\n\",\n",
      "    \"\\n\",\n",
      "    \"mlflow.set_tracking_uri(\\\"sqlite:///mlflow.db\\\")  # Local SQLite database\\n\",\n",
      "    \"# Or use a local directory\\n\",\n",
      "    \"# mlflow.set_tracking_uri(\\\"file:./mlruns\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"def log_chain_to_mlflow(chain: YouTubeSummaryChain, experiment_name: str = \\\"youtube-summarizer\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Log the chain configuration and prompt to MLflow\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param chain: YouTubeSummaryChain instance to log\\n\",\n",
      "    \"    :param experiment_name: Name of the MLflow experiment\\n\",\n",
      "    \"    :return: MLflow run ID\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    # Create experiment if it doesn't exist\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        mlflow.create_experiment(experiment_name)\\n\",\n",
      "    \"    except:\\n\",\n",
      "    \"        pass\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    mlflow.set_experiment(experiment_name)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    with mlflow.start_run() as run:\\n\",\n",
      "    \"        # Log parameters\\n\",\n",
      "    \"        config = chain.get_config()\\n\",\n",
      "    \"        mlflow.log_params({\\n\",\n",
      "    \"            \\\"model_name\\\": config[\\\"model_name\\\"],\\n\",\n",
      "    \"            \\\"temperature\\\": config[\\\"temperature\\\"]\\n\",\n",
      "    \"        })\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log prompt template as artifact\\n\",\n",
      "    \"        with open(\\\"prompt_template.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"            f.write(config[\\\"prompt_template\\\"])\\n\",\n",
      "    \"        mlflow.log_artifact(\\\"prompt_template.txt\\\")\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log additional metadata\\n\",\n",
      "    \"        mlflow.set_tags({\\n\",\n",
      "    \"            \\\"model_type\\\": \\\"youtube_summarizer\\\",\\n\",\n",
      "    \"            \\\"version\\\": \\\"1.0\\\",\\n\",\n",
      "    \"            \\\"framework\\\": \\\"groq\\\"\\n\",\n",
      "    \"        })\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Create an input example\\n\",\n",
      "    \"        input_example = \\\"https://www.youtube.com/watch?v=example\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log the chain as a custom model\\n\",\n",
      "    \"        mlflow.pyfunc.log_model(\\n\",\n",
      "    \"            artifact_path=\\\"youtube_summarizer\\\",\\n\",\n",
      "    \"            python_model=chain,\\n\",\n",
      "    \"            artifacts={\\\"prompt_template\\\": \\\"prompt_template.txt\\\"},\\n\",\n",
      "    \"            code_path=[\\\".\\\"],\\n\",\n",
      "    \"            pip_requirements=[\\\"youtube-transcript-api\\\", \\\"groq\\\", \\\"python-dotenv\\\"],\\n\",\n",
      "    \"            input_example=input_example\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return run.info.run_id\\n\",\n",
      "    \"\\n\",\n",
      "    \"def load_chain_from_mlflow(run_id: str) -> YouTubeSummaryChain:\\n\",\n",
      "    \"    \\\"\\\"\\\"Load a chain from MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    model_uri = f\\\"runs:/{run_id}/youtube_summarizer\\\"\\n\",\n",
      "    \"    chain = mlflow.pyfunc.load_model(model_uri)\\n\",\n",
      "    \"    return chain\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Example Usage\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 12,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# Create and log the chain\\n\",\n",
      "    \"chain = YouTubeSummaryChain()\\n\",\n",
      "    \"run_id = log_chain_to_mlflow(chain)\\n\",\n",
      "    \"print(f\\\"Chain logged with run_id: {run_id}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load the chain\\n\",\n",
      "    \"loaded_chain = load_chain_from_mlflow(run_id)\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Use the loaded chain\\n\",\n",
      "    \"youtube_url = \\\"https://www.youtube.com/watch?v=your_video_id\\\"\\n\",\n",
      "    \"summary = loaded_chain(youtube_url)\\n\",\n",
      "    \"print(summary)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## View MLflow Experiment Results\\n\",\n",
      "    \"\\n\",\n",
      "    \"You can view the tracked experiments by running:\\n\",\n",
      "    \"```bash\\n\",\n",
      "    \"mlflow ui\\n\",\n",
      "    \"```\\n\",\n",
      "    \"\\n\",\n",
      "    \"This will start the MLflow UI server where you can see:\\n\",\n",
      "    \"1. All experiment runs\\n\",\n",
      "    \"2. Chain configurations\\n\",\n",
      "    \"3. Prompt templates\\n\",\n",
      "    \"4. Performance metrics (if added)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461\n",
      "creation_time: 1732004080697\n",
      "experiment_id: '336741345537322461'\n",
      "last_update_time: 1732004080697\n",
      "lifecycle_stage: active\n",
      "name: youtube-summarizer\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts\n",
      "end_time: 1732004251458\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 907f1ecd64ca4ec2919e1657da05494b\n",
      "run_name: abrasive-cod-859\n",
      "run_uuid: 907f1ecd64ca4ec2919e1657da05494b\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004249085\n",
      "status: 3\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/03_MLFlow_monitoring.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Model Evaluation for YouTube Summarizer with MLflow\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook evaluates the YouTube summarizer model using MLflow to track metrics and experiments.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"import pandas as pd\\n\",\n",
      "    \"import numpy as np\\n\",\n",
      "    \"from transformers import pipeline\\n\",\n",
      "    \"from rouge_score import rouge_scorer\\n\",\n",
      "    \"from nltk.translate.bleu_score import sentence_bleu\\n\",\n",
      "    \"import nltk\\n\",\n",
      "    \"import matplotlib.pyplot as plt\\n\",\n",
      "    \"import seaborn as sns\\n\",\n",
      "    \"import mlflow\\n\",\n",
      "    \"import json\\n\",\n",
      "    \"from typing import Dict, List, Any\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Download required NLTK data\\n\",\n",
      "    \"nltk.download('punkt')\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Load Model from MLflow\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def load_model_from_mlflow(run_id: str):\\n\",\n",
      "    \"    \\\"\\\"\\\"Load the YouTube summarizer model from MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    model_uri = f\\\"runs:/{run_id}/youtube_summarizer\\\"\\n\",\n",
      "    \"    return mlflow.pyfunc.load_model(model_uri)\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Replace with your run_id from the training notebook\\n\",\n",
      "    \"RUN_ID = \\\"your_run_id_here\\\"\\n\",\n",
      "    \"model = load_model_from_mlflow(RUN_ID)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Prepare Test Data\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def prepare_test_data() -> List[Dict[str, str]]:\\n\",\n",
      "    \"    \\\"\\\"\\\"Prepare test data with YouTube videos and reference summaries\\\"\\\"\\\"\\n\",\n",
      "    \"    # Replace with your actual test data\\n\",\n",
      "    \"    return [\\n\",\n",
      "    \"        {\\n\",\n",
      "    \"            \\\"video_url\\\": \\\"https://www.youtube.com/watch?v=example1\\\",\\n\",\n",
      "    \"            \\\"reference_summary\\\": \\\"Reference summary for video 1\\\"\\n\",\n",
      "    \"        },\\n\",\n",
      "    \"        {\\n\",\n",
      "    \"            \\\"video_url\\\": \\\"https://www.youtube.com/watch?v=example2\\\",\\n\",\n",
      "    \"            \\\"reference_summary\\\": \\\"Reference summary for video 2\\\"\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    ]\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Evaluation Metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def calculate_metrics(predicted_summary: str, reference_summary: str) -> Dict[str, float]:\\n\",\n",
      "    \"    \\\"\\\"\\\"Calculate various evaluation metrics\\\"\\\"\\\"\\n\",\n",
      "    \"    # ROUGE scores\\n\",\n",
      "    \"    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\\n\",\n",
      "    \"    rouge_scores = scorer.score(reference_summary, predicted_summary)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # BLEU score\\n\",\n",
      "    \"    reference = [reference_summary.split()]\\n\",\n",
      "    \"    candidate = predicted_summary.split()\\n\",\n",
      "    \"    bleu = sentence_bleu(reference, candidate)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Summary length metrics\\n\",\n",
      "    \"    pred_length = len(predicted_summary.split())\\n\",\n",
      "    \"    ref_length = len(reference_summary.split())\\n\",\n",
      "    \"    length_ratio = pred_length / ref_length if ref_length > 0 else 0\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return {\\n\",\n",
      "    \"        'rouge1_precision': rouge_scores['rouge1'].precision,\\n\",\n",
      "    \"        'rouge1_recall': rouge_scores['rouge1'].recall,\\n\",\n",
      "    \"        'rouge1_f1': rouge_scores['rouge1'].fmeasure,\\n\",\n",
      "    \"        'rouge2_f1': rouge_scores['rouge2'].fmeasure,\\n\",\n",
      "    \"        'rougeL_f1': rouge_scores['rougeL'].fmeasure,\\n\",\n",
      "    \"        'bleu_score': bleu,\\n\",\n",
      "    \"        'summary_length_ratio': length_ratio,\\n\",\n",
      "    \"        'predicted_length': pred_length,\\n\",\n",
      "    \"        'reference_length': ref_length\\n\",\n",
      "    \"    }\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## MLflow Evaluation Pipeline\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def evaluate_model_with_mlflow(model, test_data: List[Dict[str, str]]):\\n\",\n",
      "    \"    \\\"\\\"\\\"Evaluate model and log results to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    mlflow.set_experiment(\\\"youtube-summarizer-evaluation\\\")\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    with mlflow.start_run(run_name=\\\"model_evaluation\\\") as run:\\n\",\n",
      "    \"        all_metrics = []\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log model parameters\\n\",\n",
      "    \"        model_params = model.get_config() if hasattr(model, 'get_config') else {}\\n\",\n",
      "    \"        mlflow.log_params(model_params)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Evaluate each test example\\n\",\n",
      "    \"        for i, example in enumerate(test_data):\\n\",\n",
      "    \"            # Generate summary\\n\",\n",
      "    \"            predicted_summary = model(example['video_url'])\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Calculate metrics\\n\",\n",
      "    \"            metrics = calculate_metrics(predicted_summary, example['reference_summary'])\\n\",\n",
      "    \"            all_metrics.append(metrics)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Log metrics for each example\\n\",\n",
      "    \"            for metric_name, value in metrics.items():\\n\",\n",
      "    \"                mlflow.log_metric(f\\\"example_{i}_{metric_name}\\\", value)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            # Log summaries as artifacts\\n\",\n",
      "    \"            example_dir = f\\\"example_{i}\\\"\\n\",\n",
      "    \"            os.makedirs(example_dir, exist_ok=True)\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            with open(f\\\"{example_dir}/predicted_summary.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"                f.write(predicted_summary)\\n\",\n",
      "    \"            with open(f\\\"{example_dir}/reference_summary.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"                f.write(example['reference_summary'])\\n\",\n",
      "    \"            \\n\",\n",
      "    \"            mlflow.log_artifacts(example_dir)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Calculate and log average metrics\\n\",\n",
      "    \"        avg_metrics = {}\\n\",\n",
      "    \"        for metric in all_metrics[0].keys():\\n\",\n",
      "    \"            avg_value = np.mean([m[metric] for m in all_metrics])\\n\",\n",
      "    \"            avg_metrics[f\\\"avg_{metric}\\\"] = avg_value\\n\",\n",
      "    \"            mlflow.log_metric(f\\\"avg_{metric}\\\", avg_value)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Create and log visualizations\\n\",\n",
      "    \"        create_and_log_visualizations(all_metrics)\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return run.info.run_id, avg_metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Create Visualizations\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def create_and_log_visualizations(metrics_list: List[Dict[str, float]]):\\n\",\n",
      "    \"    \\\"\\\"\\\"Create and log visualizations to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    # Convert metrics to DataFrame\\n\",\n",
      "    \"    df = pd.DataFrame(metrics_list)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # ROUGE scores comparison\\n\",\n",
      "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
      "    \"    rouge_metrics = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']\\n\",\n",
      "    \"    df[rouge_metrics].mean().plot(kind='bar')\\n\",\n",
      "    \"    plt.title('Average ROUGE Scores')\\n\",\n",
      "    \"    plt.ylabel('Score')\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('rouge_scores.png')\\n\",\n",
      "    \"    mlflow.log_artifact('rouge_scores.png')\\n\",\n",
      "    \"    plt.close()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Summary length analysis\\n\",\n",
      "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
      "    \"    plt.scatter(df['reference_length'], df['predicted_length'])\\n\",\n",
      "    \"    plt.plot([0, max(df['reference_length'])], [0, max(df['reference_length'])], '--', color='red')\\n\",\n",
      "    \"    plt.xlabel('Reference Summary Length')\\n\",\n",
      "    \"    plt.ylabel('Predicted Summary Length')\\n\",\n",
      "    \"    plt.title('Summary Length Comparison')\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('length_comparison.png')\\n\",\n",
      "    \"    mlflow.log_artifact('length_comparison.png')\\n\",\n",
      "    \"    plt.close()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Metrics distribution\\n\",\n",
      "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
      "    \"    metrics_to_plot = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1', 'bleu_score']\\n\",\n",
      "    \"    df[metrics_to_plot].boxplot()\\n\",\n",
      "    \"    plt.title('Distribution of Evaluation Metrics')\\n\",\n",
      "    \"    plt.ylabel('Score')\\n\",\n",
      "    \"    plt.xticks(rotation=45)\\n\",\n",
      "    \"    plt.tight_layout()\\n\",\n",
      "    \"    plt.savefig('metrics_distribution.png')\\n\",\n",
      "    \"    mlflow.log_artifact('metrics_distribution.png')\\n\",\n",
      "    \"    plt.close()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Run Evaluation\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Prepare test data\\n\",\n",
      "    \"test_data = prepare_test_data()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Run evaluation\\n\",\n",
      "    \"run_id, avg_metrics = evaluate_model_with_mlflow(model, test_data)\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(\\\"\\\\nEvaluation Results:\\\")\\n\",\n",
      "    \"print(\\\"==================\\\")\\n\",\n",
      "    \"for metric, value in avg_metrics.items():\\n\",\n",
      "    \"    print(f\\\"{metric}: {value:.4f}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"print(f\\\"\\\\nMLflow run ID: {run_id}\\\")\\n\",\n",
      "    \"print(\\\"View detailed results in the MLflow UI\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## View Results in MLflow UI\\n\",\n",
      "    \"\\n\",\n",
      "    \"To view the detailed results and visualizations:\\n\",\n",
      "    \"1. Start the MLflow UI by running `mlflow ui` in your terminal\\n\",\n",
      "    \"2. Open http://localhost:5000 in your browser\\n\",\n",
      "    \"3. Navigate to the experiment \\\"youtube-summarizer-evaluation\\\"\\n\",\n",
      "    \"4. Click on the run ID printed above to see detailed metrics and artifacts\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.8.0\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/__init__.py\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/04_MLFlow_evaluation.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Summarizer: Model Setup and Monitoring\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to:\\n\",\n",
      "    \"1. Set up the YouTube summarizer model\\n\",\n",
      "    \"2. Implement monitoring using MLflow\\n\",\n",
      "    \"3. Track model performance metrics\\n\",\n",
      "    \"4. Monitor system resources and latency\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Import required libraries\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"import time\\n\",\n",
      "    \"import mlflow\\n\",\n",
      "    \"import numpy as np\\n\",\n",
      "    \"import pandas as pd\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"from transformers import pipeline\\n\",\n",
      "    \"from rouge_score import rouge_scorer\\n\",\n",
      "    \"import psutil\\n\",\n",
      "    \"import plotly.express as px\\n\",\n",
      "    \"import plotly.graph_objects as go\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 1. Model Setup\\n\",\n",
      "    \"\\n\",\n",
      "    \"First, we'll set up our summarization model using the Hugging Face Transformers library.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def initialize_model():\\n\",\n",
      "    \"    \\\"\\\"\\\"Initialize the summarization model\\\"\\\"\\\"\\n\",\n",
      "    \"    model_name = \\\"facebook/bart-large-cnn\\\"  # You can change this to other models\\n\",\n",
      "    \"    summarizer = pipeline(\\\"summarization\\\", model=model_name)\\n\",\n",
      "    \"    return summarizer\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize the model\\n\",\n",
      "    \"summarizer = initialize_model()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 2. MLflow Setup\\n\",\n",
      "    \"\\n\",\n",
      "    \"Set up MLflow to track experiments and model performance.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Configure MLflow\\n\",\n",
      "    \"mlflow.set_tracking_uri(\\\"sqlite:///mlflow.db\\\")\\n\",\n",
      "    \"mlflow.set_experiment(\\\"youtube_summarizer_monitoring\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"def log_metrics(metrics_dict):\\n\",\n",
      "    \"    \\\"\\\"\\\"Log metrics to MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    with mlflow.start_run():\\n\",\n",
      "    \"        mlflow.log_metrics(metrics_dict)\\n\",\n",
      "    \"        mlflow.log_param(\\\"model_name\\\", \\\"facebook/bart-large-cnn\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 3. Performance Monitoring Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"class PerformanceMonitor:\\n\",\n",
      "    \"    def __init__(self):\\n\",\n",
      "    \"        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\\n\",\n",
      "    \"        self.metrics_history = []\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def measure_latency(self, func, *args, **kwargs):\\n\",\n",
      "    \"        \\\"\\\"\\\"Measure execution time of a function\\\"\\\"\\\"\\n\",\n",
      "    \"        start_time = time.time()\\n\",\n",
      "    \"        result = func(*args, **kwargs)\\n\",\n",
      "    \"        end_time = time.time()\\n\",\n",
      "    \"        return result, end_time - start_time\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def measure_resource_usage(self):\\n\",\n",
      "    \"        \\\"\\\"\\\"Measure CPU and memory usage\\\"\\\"\\\"\\n\",\n",
      "    \"        cpu_percent = psutil.cpu_percent()\\n\",\n",
      "    \"        memory_info = psutil.Process().memory_info()\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            'cpu_percent': cpu_percent,\\n\",\n",
      "    \"            'memory_mb': memory_info.rss / 1024 / 1024\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def calculate_rouge_scores(self, prediction, reference):\\n\",\n",
      "    \"        \\\"\\\"\\\"Calculate ROUGE scores\\\"\\\"\\\"\\n\",\n",
      "    \"        scores = self.scorer.score(prediction, reference)\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            'rouge1_f1': scores['rouge1'].fmeasure,\\n\",\n",
      "    \"            'rouge2_f1': scores['rouge2'].fmeasure,\\n\",\n",
      "    \"            'rougeL_f1': scores['rougeL'].fmeasure\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def log_performance(self, latency, rouge_scores, resource_usage):\\n\",\n",
      "    \"        \\\"\\\"\\\"Log all performance metrics\\\"\\\"\\\"\\n\",\n",
      "    \"        metrics = {\\n\",\n",
      "    \"            'latency': latency,\\n\",\n",
      "    \"            **rouge_scores,\\n\",\n",
      "    \"            **resource_usage\\n\",\n",
      "    \"        }\\n\",\n",
      "    \"        self.metrics_history.append(metrics)\\n\",\n",
      "    \"        log_metrics(metrics)\\n\",\n",
      "    \"        return metrics\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 4. Visualization Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"def plot_metrics_over_time(metrics_history):\\n\",\n",
      "    \"    \\\"\\\"\\\"Create interactive plots for metrics over time\\\"\\\"\\\"\\n\",\n",
      "    \"    df = pd.DataFrame(metrics_history)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Latency plot\\n\",\n",
      "    \"    fig_latency = px.line(df, y='latency', title='Inference Latency Over Time')\\n\",\n",
      "    \"    fig_latency.show()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Resource usage plot\\n\",\n",
      "    \"    fig_resources = go.Figure()\\n\",\n",
      "    \"    fig_resources.add_trace(go.Scatter(y=df['cpu_percent'], name='CPU %'))\\n\",\n",
      "    \"    fig_resources.add_trace(go.Scatter(y=df['memory_mb'], name='Memory (MB)'))\\n\",\n",
      "    \"    fig_resources.update_layout(title='Resource Usage Over Time')\\n\",\n",
      "    \"    fig_resources.show()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # ROUGE scores plot\\n\",\n",
      "    \"    fig_rouge = go.Figure()\\n\",\n",
      "    \"    for metric in ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']:\\n\",\n",
      "    \"        fig_rouge.add_trace(go.Scatter(y=df[metric], name=metric))\\n\",\n",
      "    \"    fig_rouge.update_layout(title='ROUGE Scores Over Time')\\n\",\n",
      "    \"    fig_rouge.show()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## 5. Example Usage\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Initialize the performance monitor\\n\",\n",
      "    \"monitor = PerformanceMonitor()\\n\",\n",
      "    \"\\n\",\n",
      "    \"def process_video(video_id, reference_summary=None):\\n\",\n",
      "    \"    \\\"\\\"\\\"Process a video with monitoring\\\"\\\"\\\"\\n\",\n",
      "    \"    # Get transcript\\n\",\n",
      "    \"    transcript = YouTubeTranscriptApi.get_transcript(video_id)\\n\",\n",
      "    \"    text = ' '.join([t['text'] for t in transcript])\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Generate summary with latency measurement\\n\",\n",
      "    \"    summary, latency = monitor.measure_latency(\\n\",\n",
      "    \"        lambda: summarizer(text, max_length=130, min_length=30)[0]['summary_text']\\n\",\n",
      "    \"    )\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Measure resource usage\\n\",\n",
      "    \"    resource_usage = monitor.measure_resource_usage()\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Calculate ROUGE scores if reference summary is provided\\n\",\n",
      "    \"    rouge_scores = monitor.calculate_rouge_scores(summary, reference_summary) if reference_summary else {}\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Log all metrics\\n\",\n",
      "    \"    metrics = monitor.log_performance(latency, rouge_scores, resource_usage)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return summary, metrics\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Example usage\\n\",\n",
      "    \"# video_id = \\\"YOUR_VIDEO_ID\\\"\\n\",\n",
      "    \"# summary, metrics = process_video(video_id)\\n\",\n",
      "    \"# plot_metrics_over_time(monitor.metrics_history)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.8.0\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/README.md\n",
      "================================================================================\n",
      "\n",
      "# YouTube Video Summarizer\n",
      "\n",
      "This project provides a Jupyter notebook that can summarize YouTube videos using their transcripts and Groq's AI model. The summarizer extracts the video's transcription and generates a comprehensive summary focusing on main points, key insights, and important conclusions.\n",
      "\n",
      "## Features\n",
      "\n",
      "- Extract YouTube video transcripts\n",
      "- Process transcripts using Groq's Mixtral-8x7b model\n",
      "- Generate structured summaries with main topics, key points, and conclusions\n",
      "- Support for both standard YouTube URLs and shortened (youtu.be) links\n",
      "\n",
      "## Prerequisites\n",
      "\n",
      "- Python 3.8+\n",
      "- Groq API key\n",
      "- Internet connection for accessing YouTube and Groq API\n",
      "\n",
      "## Installation\n",
      "\n",
      "1. Clone this repository\n",
      "2. Install the required packages:\n",
      "   ```bash\n",
      "   pip install -r requirements.txt\n",
      "   ```\n",
      "3. Create a `.env` file in the project directory and add your Groq API key:\n",
      "   ```\n",
      "   GROQ_API_KEY=your_api_key_here\n",
      "   ```\n",
      "\n",
      "## Usage\n",
      "\n",
      "1. Start Jupyter Notebook:\n",
      "   ```bash\n",
      "   jupyter notebook\n",
      "   ```\n",
      "2. Open `youtube_summarizer.ipynb`\n",
      "3. Run all cells in the notebook\n",
      "4. Replace the example YouTube URL with your desired video URL\n",
      "5. Run the cell to get your summary\n",
      "\n",
      "## Example\n",
      "\n",
      "```python\n",
      "youtube_url = \"https://www.youtube.com/watch?v=your_video_id\"\n",
      "summary = summarize_youtube_video(youtube_url)\n",
      "print(summary)\n",
      "```\n",
      "\n",
      "## Note\n",
      "\n",
      "- The video must have available transcripts (either auto-generated or manually created)\n",
      "- The quality of the summary depends on the quality of the transcript and the video content\n",
      "- Make sure you have sufficient API credits in your Groq account\n",
      "\n",
      "## License\n",
      "\n",
      "This project is open-source and available under the MIT License.\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/01_PoC.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Video Summarizer using Groq\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to create a YouTube video summarizer that:\\n\",\n",
      "    \"1. Takes a YouTube URL as input\\n\",\n",
      "    \"2. Extracts the video's transcription\\n\",\n",
      "    \"3. Uses Groq to generate a concise summary\\n\",\n",
      "    \"\\n\",\n",
      "    \"## Setup and Requirements\\n\",\n",
      "    \"First, we'll install the required packages:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"!pip install youtube-transcript-api groq python-dotenv -q\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Import Required Libraries\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 12,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"import groq\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from urllib.parse import urlparse, parse_qs\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load environment variables\\n\",\n",
      "    \"load_dotenv()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize Groq client\\n\",\n",
      "    \"client = groq.Groq(\\n\",\n",
      "    \"    api_key=os.getenv('GROQ_API_KEY')\\n\",\n",
      "    \")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Helper Functions\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 13,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def extract_video_id(url):\\n\",\n",
      "    \"    \\\"\\\"\\\"Extract YouTube video ID from URL\\\"\\\"\\\"\\n\",\n",
      "    \"    parsed_url = urlparse(url)\\n\",\n",
      "    \"    if parsed_url.hostname == 'youtu.be':\\n\",\n",
      "    \"        return parsed_url.path[1:]\\n\",\n",
      "    \"    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\\n\",\n",
      "    \"        if parsed_url.path == '/watch':\\n\",\n",
      "    \"            return parse_qs(parsed_url.query)['v'][0]\\n\",\n",
      "    \"    return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"def get_transcript(video_id):\\n\",\n",
      "    \"    \\\"\\\"\\\"Get transcript for a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\\n\",\n",
      "    \"        return ' '.join([t['text'] for t in transcript_list])\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error getting transcript: {e}\\\")\\n\",\n",
      "    \"        return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"def summarize_text(text, language=\\\"spanish\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"Summarize text using Groq\\\"\\\"\\\"\\n\",\n",
      "    \"    prompt = f\\\"\\\"\\\"Please provide a comprehensive summary of the following video transcript in {language}. \\n\",\n",
      "    \"    Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"    {text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"    Please structure the summary with:\\n\",\n",
      "    \"    1. Main Topic/Theme\\n\",\n",
      "    \"    2. Key Points\\n\",\n",
      "    \"    3. Important Details\\n\",\n",
      "    \"    4. Conclusions\\\"\\\"\\\"\\n\",\n",
      "    \"\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        completion = client.chat.completions.create(\\n\",\n",
      "    \"            model=\\\"llama-3.2-90b-vision-preview\\\",\\n\",\n",
      "    \"            messages=[\\n\",\n",
      "    \"                {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
      "    \"            ],\\n\",\n",
      "    \"            temperature=0.3,\\n\",\n",
      "    \"            max_tokens=2048\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"        return completion.choices[0].message.content\\n\",\n",
      "    \"    except Exception as e:\\n\",\n",
      "    \"        print(f\\\"Error in summarization: {e}\\\")\\n\",\n",
      "    \"        return None\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Main Function to Summarize YouTube Video\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 16,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def summarize_youtube_video(url, language=\\\"spanish\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"Main function to summarize a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"    # Extract video ID\\n\",\n",
      "    \"    video_id = extract_video_id(url)\\n\",\n",
      "    \"    if not video_id:\\n\",\n",
      "    \"        return \\\"Invalid YouTube URL\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Get transcript\\n\",\n",
      "    \"    transcript = get_transcript(video_id)\\n\",\n",
      "    \"    if not transcript:\\n\",\n",
      "    \"        return \\\"Could not retrieve transcript\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # Generate summary\\n\",\n",
      "    \"    summary = summarize_text(transcript, language)\\n\",\n",
      "    \"    if not summary:\\n\",\n",
      "    \"        return \\\"Could not generate summary\\\"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return summary\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Example Usage\\n\",\n",
      "    \"\\n\",\n",
      "    \"To use this summarizer, you'll need to:\\n\",\n",
      "    \"1. Create a `.env` file in the same directory as this notebook\\n\",\n",
      "    \"2. Add your Groq API key to the `.env` file: `GROQ_API_KEY=your_api_key_here`\\n\",\n",
      "    \"\\n\",\n",
      "    \"Then you can use the summarizer as shown below:\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 17,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"**Resumen del video transcript**\\n\",\n",
      "      \"\\n\",\n",
      "      \"**1. Tema principal/Tema**: La venta de acciones de EPM en UNE, una empresa de telecomunicaciones, y su impacto en la industria y la economía local.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**2. Puntos clave**:\\n\",\n",
      "      \"\\n\",\n",
      "      \"* EPM busca vender sus acciones en UNE debido a la intensidad de capital y la rápida evolución tecnológica en la industria de las telecomunicaciones.\\n\",\n",
      "      \"* La venta de acciones se realizará a través de un proceso de enajenación, que requiere la aprobación del Consejo de Medellín.\\n\",\n",
      "      \"* El valor de las acciones se estima en 1,6 billones de pesos, según el valor en libros y la capitalización de UNE.\\n\",\n",
      "      \"* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**3. Detalles importantes**:\\n\",\n",
      "      \"\\n\",\n",
      "      \"* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\\n\",\n",
      "      \"* EPM tiene otros negocios estratégicos, como la generación y distribución de energía, agua y gas, que requieren inversiones importantes.\\n\",\n",
      "      \"* La venta de acciones se realizará a través de un proceso de enajenación, que incluye la oferta a sectores solidarios y especiales, y luego al mercado.\\n\",\n",
      "      \"* El gobierno también está considerando la venta de sus acciones en UNE, lo que podría cambiar el panorama de la industria de las telecomunicaciones en Colombia.\\n\",\n",
      "      \"* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\\n\",\n",
      "      \"\\n\",\n",
      "      \"**4. Conclusión**:\\n\",\n",
      "      \"\\n\",\n",
      "      \"* La venta de acciones de EPM en UNE es un proceso complejo que requiere la aprobación del Consejo de Medellín y la valoración de las acciones en el mercado.\\n\",\n",
      "      \"* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, que beneficiarán a la comunidad y la economía local.\\n\",\n",
      "      \"* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\\n\",\n",
      "      \"* La venta de acciones de EPM en UNE puede tener un impacto significativo en el panorama de la industria de las telecomunicaciones en Colombia.\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Example usage\\n\",\n",
      "    \"youtube_url = \\\"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\\\"\\n\",\n",
      "    \"language = \\\"spanish\\\"\\n\",\n",
      "    \"summary = summarize_youtube_video(youtube_url, language)\\n\",\n",
      "    \"print(summary)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/02_MLFlow_implementation.ipynb\n",
      "================================================================================\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# YouTube Video Summarizer with MLflow Integration\\n\",\n",
      "    \"\\n\",\n",
      "    \"This notebook demonstrates how to:\\n\",\n",
      "    \"1. Create a YouTube video summarization chain\\n\",\n",
      "    \"2. Track the chain and prompts using MLflow\\n\",\n",
      "    \"3. Load and use the tracked model\\n\",\n",
      "    \"\\n\",\n",
      "    \"## Setup and Requirements\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 1,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\\n\",\n",
      "      \"Requirement already satisfied: youtube-transcript-api in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.6.3)\\n\",\n",
      "      \"Requirement already satisfied: groq in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.12.0)\\n\",\n",
      "      \"Requirement already satisfied: python-dotenv in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (1.0.1)\\n\",\n",
      "      \"Requirement already satisfied: mlflow in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (2.18.0)\\n\",\n",
      "      \"Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\\n\",\n",
      "      \"Requirement already satisfied: requests in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\\n\",\n",
      "      \"Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.6.2.post1)\\n\",\n",
      "      \"Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.9.0)\\n\",\n",
      "      \"Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (0.27.2)\\n\",\n",
      "      \"Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (2.9.2)\\n\",\n",
      "      \"Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.3.1)\\n\",\n",
      "      \"Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.12.2)\\n\",\n",
      "      \"Requirement already satisfied: mlflow-skinny==2.18.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.18.0)\\n\",\n",
      "      \"Requirement already satisfied: Flask<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.0)\\n\",\n",
      "      \"Requirement already satisfied: alembic!=1.10.0,<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.0)\\n\",\n",
      "      \"Requirement already satisfied: docker<8,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (7.1.0)\\n\",\n",
      "      \"Requirement already satisfied: graphene<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.4.3)\\n\",\n",
      "      \"Requirement already satisfied: markdown<4,>=3.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.7)\\n\",\n",
      "      \"Requirement already satisfied: matplotlib<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.9.2)\\n\",\n",
      "      \"Requirement already satisfied: numpy<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.1.3)\\n\",\n",
      "      \"Requirement already satisfied: pandas<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.2.3)\\n\",\n",
      "      \"Requirement already satisfied: pyarrow<19,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (18.0.0)\\n\",\n",
      "      \"Requirement already satisfied: scikit-learn<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.5.2)\\n\",\n",
      "      \"Requirement already satisfied: scipy<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.1)\\n\",\n",
      "      \"Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.0.36)\\n\",\n",
      "      \"Requirement already satisfied: Jinja2<4,>=2.11 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.4)\\n\",\n",
      "      \"Requirement already satisfied: gunicorn<24 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (23.0.0)\\n\",\n",
      "      \"Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\\n\",\n",
      "      \"Requirement already satisfied: click<9,>=7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\\n\",\n",
      "      \"Requirement already satisfied: cloudpickle<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\\n\",\n",
      "      \"Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.38.0)\\n\",\n",
      "      \"Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\\n\",\n",
      "      \"Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\\n\",\n",
      "      \"Requirement already satisfied: packaging<25 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\\n\",\n",
      "      \"Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.28.3)\\n\",\n",
      "      \"Requirement already satisfied: pyyaml<7,>=5.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\\n\",\n",
      "      \"Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\\n\",\n",
      "      \"Requirement already satisfied: Mako in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\\n\",\n",
      "      \"Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\\n\",\n",
      "      \"Requirement already satisfied: urllib3>=1.26.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\\n\",\n",
      "      \"Requirement already satisfied: Werkzeug>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\\n\",\n",
      "      \"Requirement already satisfied: itsdangerous>=2.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\\n\",\n",
      "      \"Requirement already satisfied: blinker>=1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\\n\",\n",
      "      \"Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.5)\\n\",\n",
      "      \"Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\\n\",\n",
      "      \"Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\\n\",\n",
      "      \"Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\\n\",\n",
      "      \"Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\\n\",\n",
      "      \"Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\\n\",\n",
      "      \"Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\\n\",\n",
      "      \"Requirement already satisfied: contourpy>=1.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.1)\\n\",\n",
      "      \"Requirement already satisfied: cycler>=0.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\\n\",\n",
      "      \"Requirement already satisfied: fonttools>=4.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.55.0)\\n\",\n",
      "      \"Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.7)\\n\",\n",
      "      \"Requirement already satisfied: pillow>=8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.0.0)\\n\",\n",
      "      \"Requirement already satisfied: pyparsing>=2.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.0)\\n\",\n",
      "      \"Requirement already satisfied: pytz>=2020.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\\n\",\n",
      "      \"Requirement already satisfied: tzdata>=2022.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\\n\",\n",
      "      \"Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\\n\",\n",
      "      \"Requirement already satisfied: pydantic-core==2.23.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\\n\",\n",
      "      \"Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.0)\\n\",\n",
      "      \"Requirement already satisfied: joblib>=1.2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.4.2)\\n\",\n",
      "      \"Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.5.0)\\n\",\n",
      "      \"Requirement already satisfied: google-auth~=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.36.0)\\n\",\n",
      "      \"Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\\n\",\n",
      "      \"Requirement already satisfied: zipp>=3.20 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\\n\",\n",
      "      \"Requirement already satisfied: deprecated>=1.2.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\\n\",\n",
      "      \"Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\\n\",\n",
      "      \"Requirement already satisfied: six>=1.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\\n\",\n",
      "      \"Requirement already satisfied: wrapt<2,>=1.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\\n\",\n",
      "      \"Requirement already satisfied: smmap<6,>=3.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\\n\",\n",
      "      \"Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\\n\",\n",
      "      \"Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\\n\",\n",
      "      \"Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"!pip install youtube-transcript-api groq python-dotenv mlflow -q\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"import mlflow\\n\",\n",
      "    \"from youtube_transcript_api import YouTubeTranscriptApi\\n\",\n",
      "    \"import groq\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"from dotenv import load_dotenv\\n\",\n",
      "    \"from urllib.parse import urlparse, parse_qs\\n\",\n",
      "    \"import json\\n\",\n",
      "    \"from typing import Dict, Any\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load environment variables\\n\",\n",
      "    \"load_dotenv()\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Initialize Groq client\\n\",\n",
      "    \"client = groq.Groq(\\n\",\n",
      "    \"    api_key=os.getenv('GROQ_API_KEY')\\n\",\n",
      "    \")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Define Chain Components\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 8,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"class YouTubeSummaryChain:\\n\",\n",
      "    \"    def __init__(self, model_name: str = \\\"mixtral-8x7b-32768\\\", temperature: float = 0.3):\\n\",\n",
      "    \"        self.model_name = model_name\\n\",\n",
      "    \"        self.temperature = temperature\\n\",\n",
      "    \"        self.prompt_template = \\\"\\\"\\\"\\n\",\n",
      "    \"        Please provide a comprehensive summary of the following video transcript. \\n\",\n",
      "    \"        Focus on the main points, key insights, and important conclusions:\\n\",\n",
      "    \"\\n\",\n",
      "    \"        {text}\\n\",\n",
      "    \"\\n\",\n",
      "    \"        Please structure the summary with:\\n\",\n",
      "    \"        1. Main Topic/Theme\\n\",\n",
      "    \"        2. Key Points\\n\",\n",
      "    \"        3. Important Details\\n\",\n",
      "    \"        4. Conclusions\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"    def _get_groq_client(self):\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        Initialize and return Groq client\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        :return: Initialized Groq client\\n\",\n",
      "    \"        \\\"\\\"\\\"\\n\",\n",
      "    \"        return groq.Groq(api_key=os.getenv('GROQ_API_KEY'))\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    def extract_video_id(self, url: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Extract YouTube video ID from URL\\\"\\\"\\\"\\n\",\n",
      "    \"        parsed_url = urlparse(url)\\n\",\n",
      "    \"        if parsed_url.hostname == 'youtu.be':\\n\",\n",
      "    \"            return parsed_url.path[1:]\\n\",\n",
      "    \"        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\\n\",\n",
      "    \"            if parsed_url.path == '/watch':\\n\",\n",
      "    \"                return parse_qs(parsed_url.query)['v'][0]\\n\",\n",
      "    \"        return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def get_transcript(self, video_id: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Get transcript for a YouTube video\\\"\\\"\\\"\\n\",\n",
      "    \"        try:\\n\",\n",
      "    \"            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\\n\",\n",
      "    \"            return ' '.join([t['text'] for t in transcript_list])\\n\",\n",
      "    \"        except Exception as e:\\n\",\n",
      "    \"            print(f\\\"Error getting transcript: {e}\\\")\\n\",\n",
      "    \"            return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def summarize_text(self, text: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Summarize text using Groq\\\"\\\"\\\"\\n\",\n",
      "    \"        prompt = self.prompt_template.format(text=text)\\n\",\n",
      "    \"\\n\",\n",
      "    \"        try:\\n\",\n",
      "    \"            # Initialize client only when needed\\n\",\n",
      "    \"            client = self._get_groq_client()\\n\",\n",
      "    \"            completion = client.chat.completions.create(\\n\",\n",
      "    \"                model=self.model_name,\\n\",\n",
      "    \"                messages=[\\n\",\n",
      "    \"                    {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
      "    \"                ],\\n\",\n",
      "    \"                temperature=self.temperature,\\n\",\n",
      "    \"                max_tokens=2048\\n\",\n",
      "    \"            )\\n\",\n",
      "    \"            return completion.choices[0].message.content\\n\",\n",
      "    \"        except Exception as e:\\n\",\n",
      "    \"            print(f\\\"Error in summarization: {e}\\\")\\n\",\n",
      "    \"            return None\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def __call__(self, url: str) -> str:\\n\",\n",
      "    \"        \\\"\\\"\\\"Process a YouTube URL and return summary\\\"\\\"\\\"\\n\",\n",
      "    \"        video_id = self.extract_video_id(url)\\n\",\n",
      "    \"        if not video_id:\\n\",\n",
      "    \"            return \\\"Invalid YouTube URL\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        transcript = self.get_transcript(video_id)\\n\",\n",
      "    \"        if not transcript:\\n\",\n",
      "    \"            return \\\"Could not retrieve transcript\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        summary = self.summarize_text(transcript)\\n\",\n",
      "    \"        if not summary:\\n\",\n",
      "    \"            return \\\"Could not generate summary\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return summary\\n\",\n",
      "    \"\\n\",\n",
      "    \"    def get_config(self) -> Dict[str, Any]:\\n\",\n",
      "    \"        \\\"\\\"\\\"Get chain configuration for MLflow tracking\\\"\\\"\\\"\\n\",\n",
      "    \"        return {\\n\",\n",
      "    \"            \\\"model_name\\\": self.model_name,\\n\",\n",
      "    \"            \\\"temperature\\\": self.temperature,\\n\",\n",
      "    \"            \\\"prompt_template\\\": self.prompt_template\\n\",\n",
      "    \"        }\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## MLflow Integration\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 6,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def log_chain_to_mlflow(chain: YouTubeSummaryChain, experiment_name: str = \\\"youtube-summarizer\\\"):\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    Log the chain configuration and prompt to MLflow\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    :param chain: YouTubeSummaryChain instance to log\\n\",\n",
      "    \"    :param experiment_name: Name of the MLflow experiment\\n\",\n",
      "    \"    :return: MLflow run ID\\n\",\n",
      "    \"    \\\"\\\"\\\"\\n\",\n",
      "    \"    mlflow.set_experiment(experiment_name)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    with mlflow.start_run() as run:\\n\",\n",
      "    \"        # Log parameters\\n\",\n",
      "    \"        config = chain.get_config()\\n\",\n",
      "    \"        mlflow.log_params({\\n\",\n",
      "    \"            \\\"model_name\\\": config[\\\"model_name\\\"],\\n\",\n",
      "    \"            \\\"temperature\\\": config[\\\"temperature\\\"]\\n\",\n",
      "    \"        })\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log prompt template as artifact\\n\",\n",
      "    \"        with open(\\\"prompt_template.txt\\\", \\\"w\\\") as f:\\n\",\n",
      "    \"            f.write(config[\\\"prompt_template\\\"])\\n\",\n",
      "    \"        mlflow.log_artifact(\\\"prompt_template.txt\\\")\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Create an input example\\n\",\n",
      "    \"        input_example = \\\"https://www.youtube.com/watch?v=example\\\"\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # Log the chain as a custom model\\n\",\n",
      "    \"        mlflow.pyfunc.log_model(\\n\",\n",
      "    \"            artifact_path=\\\"youtube_summarizer\\\",\\n\",\n",
      "    \"            python_model=chain,\\n\",\n",
      "    \"            artifacts={\\\"prompt_template\\\": \\\"prompt_template.txt\\\"},\\n\",\n",
      "    \"            code_path=[\\\".\\\"],\\n\",\n",
      "    \"            pip_requirements=[\\\"youtube-transcript-api\\\", \\\"groq\\\", \\\"python-dotenv\\\"],\\n\",\n",
      "    \"            input_example=input_example\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        return run.info.run_id\\n\",\n",
      "    \"\\n\",\n",
      "    \"def load_chain_from_mlflow(run_id: str) -> YouTubeSummaryChain:\\n\",\n",
      "    \"    \\\"\\\"\\\"Load a chain from MLflow\\\"\\\"\\\"\\n\",\n",
      "    \"    model_uri = f\\\"runs:/{run_id}/youtube_summarizer\\\"\\n\",\n",
      "    \"    chain = mlflow.pyfunc.load_model(model_uri)\\n\",\n",
      "    \"    return chain\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Example Usage\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 7,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"/Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:2852: UserWarning: The `code_path` argument is replaced by `code_paths` and is deprecated as of MLflow version 2.12.0. This argument will be removed in a future release of MLflow.\\n\",\n",
      "      \"  warnings.warn(\\n\",\n",
      "      \"2024/11/19 03:15:45 INFO mlflow.types.utils: Unsupported type hint: <class 'str'>, skipping schema inference\\n\",\n",
      "      \"2024/11/19 03:15:46 INFO mlflow.types.utils: Unsupported type hint: <class 'str'>, skipping schema inference\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Error getting transcript: \\n\",\n",
      "      \"Could not retrieve a transcript for the video https://www.youtube.com/watch?v=example! This is most likely caused by:\\n\",\n",
      "      \"\\n\",\n",
      "      \"Subtitles are disabled for this video\\n\",\n",
      "      \"\\n\",\n",
      "      \"If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"ename\": \"MlflowException\",\n",
      "     \"evalue\": \"Failed to serialize Python model. Please audit your class variables (e.g. in `__init__()`) for any unpicklable objects. If you're trying to save an external model in your custom pyfunc, Please use the `artifacts` parameter in `mlflow.pyfunc.save_model()`, and load your external model in the `load_context()` method instead. For example:\\n\\nclass MyModel(mlflow.pyfunc.PythonModel):\\n    def load_context(self, context):\\n        model_path = context.artifacts['my_model_path']\\n        // custom load logic here\\n        self.model = load_model(model_path)\\n\\nFor more information, see our full tutorial at: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\\n\\nFull serialization error: cannot pickle '_thread.RLock' object\",\n",
      "     \"output_type\": \"error\",\n",
      "     \"traceback\": [\n",
      "      \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
      "      \"\\u001b[0;31mMlflowException\\u001b[0m                           Traceback (most recent call last)\",\n",
      "      \"Cell \\u001b[0;32mIn[7], line 3\\u001b[0m\\n\\u001b[1;32m      1\\u001b[0m \\u001b[38;5;66;03m# Create and log the chain\\u001b[39;00m\\n\\u001b[1;32m      2\\u001b[0m chain \\u001b[38;5;241m=\\u001b[39m YouTubeSummaryChain()\\n\\u001b[0;32m----> 3\\u001b[0m run_id \\u001b[38;5;241m=\\u001b[39m \\u001b[43mlog_chain_to_mlflow\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mchain\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m      4\\u001b[0m \\u001b[38;5;28mprint\\u001b[39m(\\u001b[38;5;124mf\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mChain logged with run_id: \\u001b[39m\\u001b[38;5;132;01m{\\u001b[39;00mrun_id\\u001b[38;5;132;01m}\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m)\\n\\u001b[1;32m      6\\u001b[0m \\u001b[38;5;66;03m# Load the chain\\u001b[39;00m\\n\",\n",
      "      \"Cell \\u001b[0;32mIn[6], line 28\\u001b[0m, in \\u001b[0;36mlog_chain_to_mlflow\\u001b[0;34m(chain, experiment_name)\\u001b[0m\\n\\u001b[1;32m     25\\u001b[0m input_example \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mhttps://www.youtube.com/watch?v=example\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m     27\\u001b[0m \\u001b[38;5;66;03m# Log the chain as a custom model\\u001b[39;00m\\n\\u001b[0;32m---> 28\\u001b[0m \\u001b[43mmlflow\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpyfunc\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mlog_model\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m     29\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43martifact_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43myoutube_summarizer\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     30\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43mpython_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mchain\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     31\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43martifacts\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43m{\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mprompt_template\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m:\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mprompt_template.txt\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m}\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     32\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43mcode_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43m[\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43m.\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m]\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     33\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43m[\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43myoutube-transcript-api\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mgroq\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mpython-dotenv\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m]\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m     34\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43minput_example\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43minput_example\\u001b[49m\\n\\u001b[1;32m     35\\u001b[0m \\u001b[43m\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m     37\\u001b[0m \\u001b[38;5;28;01mreturn\\u001b[39;00m run\\u001b[38;5;241m.\\u001b[39minfo\\u001b[38;5;241m.\\u001b[39mrun_id\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/tracing/provider.py:268\\u001b[0m, in \\u001b[0;36mtrace_disabled.<locals>.wrapper\\u001b[0;34m(*args, **kwargs)\\u001b[0m\\n\\u001b[1;32m    266\\u001b[0m disable()\\n\\u001b[1;32m    267\\u001b[0m \\u001b[38;5;28;01mtry\\u001b[39;00m:\\n\\u001b[0;32m--> 268\\u001b[0m     is_func_called, result \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mTrue\\u001b[39;00m, \\u001b[43mf\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43margs\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43mkwargs\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    269\\u001b[0m \\u001b[38;5;28;01mfinally\\u001b[39;00m:\\n\\u001b[1;32m    270\\u001b[0m     enable()\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3246\\u001b[0m, in \\u001b[0;36mlog_model\\u001b[0;34m(artifact_path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources)\\u001b[0m\\n\\u001b[1;32m   3024\\u001b[0m \\u001b[38;5;129m@format_docstring\\u001b[39m(LOG_MODEL_PARAM_DOCS\\u001b[38;5;241m.\\u001b[39mformat(package_name\\u001b[38;5;241m=\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mscikit-learn\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m))\\n\\u001b[1;32m   3025\\u001b[0m \\u001b[38;5;129m@trace_disabled\\u001b[39m  \\u001b[38;5;66;03m# Suppress traces for internal predict calls while logging model\\u001b[39;00m\\n\\u001b[1;32m   3026\\u001b[0m \\u001b[38;5;28;01mdef\\u001b[39;00m \\u001b[38;5;21mlog_model\\u001b[39m(\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m   3046\\u001b[0m     resources: Optional[Union[\\u001b[38;5;28mstr\\u001b[39m, \\u001b[38;5;28mlist\\u001b[39m[Resource]]] \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mNone\\u001b[39;00m,\\n\\u001b[1;32m   3047\\u001b[0m ):\\n\\u001b[1;32m   3048\\u001b[0m \\u001b[38;5;250m    \\u001b[39m\\u001b[38;5;124;03m\\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[1;32m   3049\\u001b[0m \\u001b[38;5;124;03m    Log a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\\u001b[39;00m\\n\\u001b[1;32m   3050\\u001b[0m \\u001b[38;5;124;03m    artifact for the current run.\\u001b[39;00m\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m   3244\\u001b[0m \\u001b[38;5;124;03m        metadata of the logged model.\\u001b[39;00m\\n\\u001b[1;32m   3245\\u001b[0m \\u001b[38;5;124;03m    \\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[0;32m-> 3246\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[43mModel\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mlog\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m   3247\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43martifact_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43martifact_path\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3248\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mflavor\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmlflow\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpyfunc\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3249\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mloader_module\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mloader_module\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3250\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mdata_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mdata_path\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3251\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mcode_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mcode_path\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m  \\u001b[49m\\u001b[38;5;66;43;03m# deprecated\\u001b[39;49;00m\\n\\u001b[1;32m   3252\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mcode_paths\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mcode_paths\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3253\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpython_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpython_model\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3254\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43martifacts\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43martifacts\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3255\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mconda_env\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconda_env\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3256\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mregistered_model_name\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mregistered_model_name\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3257\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43msignature\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43msignature\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3258\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43minput_example\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43minput_example\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3259\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mawait_registration_for\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mawait_registration_for\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3260\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3261\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mextra_pip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mextra_pip_requirements\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3262\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmetadata\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmetadata\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3263\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmodel_config\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmodel_config\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3264\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mexample_no_conversion\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mexample_no_conversion\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3265\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mstreamable\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mstreamable\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3266\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mresources\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mresources\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3267\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43minfer_code_paths\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43minfer_code_paths\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3268\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43m)\\u001b[49m\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/models/model.py:776\\u001b[0m, in \\u001b[0;36mModel.log\\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\\u001b[0m\\n\\u001b[1;32m    772\\u001b[0m     run_id \\u001b[38;5;241m=\\u001b[39m mlflow\\u001b[38;5;241m.\\u001b[39mtracking\\u001b[38;5;241m.\\u001b[39mfluent\\u001b[38;5;241m.\\u001b[39m_get_or_start_run()\\u001b[38;5;241m.\\u001b[39minfo\\u001b[38;5;241m.\\u001b[39mrun_id\\n\\u001b[1;32m    773\\u001b[0m mlflow_model \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mcls\\u001b[39m(\\n\\u001b[1;32m    774\\u001b[0m     artifact_path\\u001b[38;5;241m=\\u001b[39martifact_path, run_id\\u001b[38;5;241m=\\u001b[39mrun_id, metadata\\u001b[38;5;241m=\\u001b[39mmetadata, resources\\u001b[38;5;241m=\\u001b[39mresources\\n\\u001b[1;32m    775\\u001b[0m )\\n\\u001b[0;32m--> 776\\u001b[0m \\u001b[43mflavor\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43msave_model\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mpath\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mlocal_path\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mmlflow_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmlflow_model\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43mkwargs\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    777\\u001b[0m \\u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\\u001b[39;00m\\n\\u001b[1;32m    778\\u001b[0m \\u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\\u001b[39;00m\\n\\u001b[1;32m    779\\u001b[0m \\u001b[38;5;28;01mfor\\u001b[39;00m pycache \\u001b[38;5;129;01min\\u001b[39;00m Path(local_path)\\u001b[38;5;241m.\\u001b[39mrglob(\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m__pycache__\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m):\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/tracing/provider.py:272\\u001b[0m, in \\u001b[0;36mtrace_disabled.<locals>.wrapper\\u001b[0;34m(*args, **kwargs)\\u001b[0m\\n\\u001b[1;32m    270\\u001b[0m             enable()\\n\\u001b[1;32m    271\\u001b[0m     \\u001b[38;5;28;01melse\\u001b[39;00m:\\n\\u001b[0;32m--> 272\\u001b[0m         is_func_called, result \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mTrue\\u001b[39;00m, \\u001b[43mf\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43margs\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43mkwargs\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    273\\u001b[0m \\u001b[38;5;66;03m# We should only catch the exception from disable() and enable()\\u001b[39;00m\\n\\u001b[1;32m    274\\u001b[0m \\u001b[38;5;66;03m# and let other exceptions propagate.\\u001b[39;00m\\n\\u001b[1;32m    275\\u001b[0m \\u001b[38;5;28;01mexcept\\u001b[39;00m MlflowTracingException \\u001b[38;5;28;01mas\\u001b[39;00m e:\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3006\\u001b[0m, in \\u001b[0;36msave_model\\u001b[0;34m(path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources, **kwargs)\\u001b[0m\\n\\u001b[1;32m   2992\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m _save_model_with_loader_module_and_data_path(\\n\\u001b[1;32m   2993\\u001b[0m         path\\u001b[38;5;241m=\\u001b[39mpath,\\n\\u001b[1;32m   2994\\u001b[0m         loader_module\\u001b[38;5;241m=\\u001b[39mloader_module,\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m   3003\\u001b[0m         infer_code_paths\\u001b[38;5;241m=\\u001b[39minfer_code_paths,\\n\\u001b[1;32m   3004\\u001b[0m     )\\n\\u001b[1;32m   3005\\u001b[0m \\u001b[38;5;28;01melif\\u001b[39;00m second_argument_set_specified:\\n\\u001b[0;32m-> 3006\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[43mmlflow\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpyfunc\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mmodel\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43m_save_model_with_class_artifacts_params\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m   3007\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpath\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpath\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3008\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43msignature\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43msignature\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3009\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mhints\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mhints\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3010\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpython_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpython_model\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3011\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43martifacts\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43martifacts\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3012\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mconda_env\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconda_env\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3013\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mcode_paths\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mcode_paths\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3014\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmlflow_model\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmlflow_model\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3015\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mpip_requirements\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3016\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mextra_pip_requirements\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mextra_pip_requirements\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3017\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmodel_config\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmodel_config\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3018\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mstreamable\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mstreamable\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3019\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmodel_code_path\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmodel_code_path\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3020\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43minfer_code_paths\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43minfer_code_paths\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m   3021\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43m)\\u001b[49m\\n\",\n",
      "      \"File \\u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/model.py:382\\u001b[0m, in \\u001b[0;36m_save_model_with_class_artifacts_params\\u001b[0;34m(path, python_model, signature, hints, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config, streamable, model_code_path, infer_code_paths)\\u001b[0m\\n\\u001b[1;32m    378\\u001b[0m \\u001b[38;5;28;01mexcept\\u001b[39;00m \\u001b[38;5;167;01mException\\u001b[39;00m \\u001b[38;5;28;01mas\\u001b[39;00m e:\\n\\u001b[1;32m    379\\u001b[0m     \\u001b[38;5;66;03m# cloudpickle sometimes raises TypeError instead of PicklingError.\\u001b[39;00m\\n\\u001b[1;32m    380\\u001b[0m     \\u001b[38;5;66;03m# catching generic Exception and checking message to handle both cases.\\u001b[39;00m\\n\\u001b[1;32m    381\\u001b[0m     \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mcannot pickle\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m \\u001b[38;5;129;01min\\u001b[39;00m \\u001b[38;5;28mstr\\u001b[39m(e)\\u001b[38;5;241m.\\u001b[39mlower():\\n\\u001b[0;32m--> 382\\u001b[0m         \\u001b[38;5;28;01mraise\\u001b[39;00m MlflowException(\\n\\u001b[1;32m    383\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mFailed to serialize Python model. Please audit your \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    384\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mclass variables (e.g. in `__init__()`) for any \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    385\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124munpicklable objects. If you\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mre trying to save an external model \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    386\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124min your custom pyfunc, Please use the `artifacts` parameter \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    387\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124min `mlflow.pyfunc.save_model()`, and load your external model \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    388\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124min the `load_context()` method instead. For example:\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    389\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mclass MyModel(mlflow.pyfunc.PythonModel):\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    390\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m    def load_context(self, context):\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    391\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m        model_path = context.artifacts[\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124mmy_model_path\\u001b[39m\\u001b[38;5;124m'\\u001b[39m\\u001b[38;5;124m]\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    392\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m        // custom load logic here\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    393\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m        self.model = load_model(model_path)\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    394\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mFor more information, see our full tutorial at: \\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    395\\u001b[0m             \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mhttps://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    396\\u001b[0m             \\u001b[38;5;124mf\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;130;01m\\\\n\\u001b[39;00m\\u001b[38;5;124mFull serialization error: \\u001b[39m\\u001b[38;5;132;01m{\\u001b[39;00me\\u001b[38;5;132;01m}\\u001b[39;00m\\u001b[38;5;124m\\\"\\u001b[39m\\n\\u001b[1;32m    397\\u001b[0m         ) \\u001b[38;5;28;01mfrom\\u001b[39;00m \\u001b[38;5;28;01mNone\\u001b[39;00m\\n\\u001b[1;32m    398\\u001b[0m     \\u001b[38;5;28;01melse\\u001b[39;00m:\\n\\u001b[1;32m    399\\u001b[0m         \\u001b[38;5;28;01mraise\\u001b[39;00m e\\n\",\n",
      "      \"\\u001b[0;31mMlflowException\\u001b[0m: Failed to serialize Python model. Please audit your class variables (e.g. in `__init__()`) for any unpicklable objects. If you're trying to save an external model in your custom pyfunc, Please use the `artifacts` parameter in `mlflow.pyfunc.save_model()`, and load your external model in the `load_context()` method instead. For example:\\n\\nclass MyModel(mlflow.pyfunc.PythonModel):\\n    def load_context(self, context):\\n        model_path = context.artifacts['my_model_path']\\n        // custom load logic here\\n        self.model = load_model(model_path)\\n\\nFor more information, see our full tutorial at: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\\n\\nFull serialization error: cannot pickle '_thread.RLock' object\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# Create and log the chain\\n\",\n",
      "    \"chain = YouTubeSummaryChain()\\n\",\n",
      "    \"run_id = log_chain_to_mlflow(chain)\\n\",\n",
      "    \"print(f\\\"Chain logged with run_id: {run_id}\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Load the chain\\n\",\n",
      "    \"loaded_chain = load_chain_from_mlflow(run_id)\\n\",\n",
      "    \"\\n\",\n",
      "    \"# Use the loaded chain\\n\",\n",
      "    \"youtube_url = \\\"https://www.youtube.com/watch?v=your_video_id\\\"\\n\",\n",
      "    \"summary = loaded_chain(youtube_url)\\n\",\n",
      "    \"print(summary)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## View MLflow Experiment Results\\n\",\n",
      "    \"\\n\",\n",
      "    \"You can view the tracked experiments by running:\\n\",\n",
      "    \"```bash\\n\",\n",
      "    \"mlflow ui\\n\",\n",
      "    \"```\\n\",\n",
      "    \"\\n\",\n",
      "    \"This will start the MLflow UI server where you can see:\\n\",\n",
      "    \"1. All experiment runs\\n\",\n",
      "    \"2. Chain configurations\\n\",\n",
      "    \"3. Prompt templates\\n\",\n",
      "    \"4. Performance metrics (if added)\"\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.11.10\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461\n",
      "creation_time: 1732004080697\n",
      "experiment_id: '336741345537322461'\n",
      "last_update_time: 1732004080697\n",
      "lifecycle_stage: active\n",
      "name: youtube-summarizer\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts\n",
      "end_time: null\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 907f1ecd64ca4ec2919e1657da05494b\n",
      "run_name: abrasive-cod-859\n",
      "run_uuid: 907f1ecd64ca4ec2919e1657da05494b\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004249085\n",
      "status: 1\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/artifacts\n",
      "end_time: 1732004146098\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 0e7459a9e3524678a1970c2b02be4ee9\n",
      "run_name: indecisive-mole-683\n",
      "run_uuid: 0e7459a9e3524678a1970c2b02be4ee9\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004145291\n",
      "status: 4\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/artifacts\n",
      "end_time: 1732004080824\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 0df34b8b49744c4d91061ee809b80f5b\n",
      "run_name: intrigued-koi-579\n",
      "run_uuid: 0df34b8b49744c4d91061ee809b80f5b\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004080797\n",
      "status: 4\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/0/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/0\n",
      "creation_time: 1732004080692\n",
      "experiment_id: '0'\n",
      "last_update_time: 1732004080692\n",
      "lifecycle_stage: active\n",
      "name: Default\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/artifacts\n",
      "end_time: 1732004146098\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 0e7459a9e3524678a1970c2b02be4ee9\n",
      "run_name: indecisive-mole-683\n",
      "run_uuid: 0e7459a9e3524678a1970c2b02be4ee9\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004145291\n",
      "status: 4\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/artifacts\n",
      "end_time: 1732004080824\n",
      "entry_point_name: ''\n",
      "experiment_id: '336741345537322461'\n",
      "lifecycle_stage: active\n",
      "run_id: 0df34b8b49744c4d91061ee809b80f5b\n",
      "run_name: intrigued-koi-579\n",
      "run_uuid: 0df34b8b49744c4d91061ee809b80f5b\n",
      "source_name: ''\n",
      "source_type: 4\n",
      "source_version: ''\n",
      "start_time: 1732004080797\n",
      "status: 4\n",
      "tags: []\n",
      "user_id: ganga\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/0/meta.yaml\n",
      "================================================================================\n",
      "\n",
      "artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/0\n",
      "creation_time: 1732004080692\n",
      "experiment_id: '0'\n",
      "last_update_time: 1732004080692\n",
      "lifecycle_stage: active\n",
      "name: Default\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/daa7f8f98e84424bb04699f779d3d707/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/daa7f8f98e84424bb04699f779d3d707/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/1ee6c5706f2e4df0bb34b383b6590c96/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/1ee6c5706f2e4df0bb34b383b6590c96/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/80640e35abf84940b9e0043f6881abb2/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/80640e35abf84940b9e0043f6881abb2/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/a88ca06d3af4489fad1921c1c028f9b7/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/a88ca06d3af4489fad1921c1c028f9b7/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/413a66439ac54cb78a385e6e93146572/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/413a66439ac54cb78a385e6e93146572/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/2feba136305a4e22bd08bbcfb5decb48/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/2feba136305a4e22bd08bbcfb5decb48/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/1d4a73d3db0e49e58886211224cfc70e/artifacts/youtube_summarizer/python_env.yaml\n",
      "================================================================================\n",
      "\n",
      "python: 3.11.10\n",
      "build_dependencies:\n",
      "- pip==24.3.1\n",
      "- setuptools==75.5.0\n",
      "- wheel==0.45.0\n",
      "dependencies:\n",
      "- -r requirements.txt\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# mlruns/1/1d4a73d3db0e49e58886211224cfc70e/artifacts/youtube_summarizer/conda.yaml\n",
      "================================================================================\n",
      "\n",
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.11.10\n",
      "- pip<=24.3.1\n",
      "- pip:\n",
      "  - mlflow==2.18.0\n",
      "  - youtube-transcript-api\n",
      "  - groq\n",
      "  - python-dotenv\n",
      "  - pandas\n",
      "name: mlflow-env\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def read_files(folder_path):\n",
    "    \"\"\"\n",
    "    Read files from the specified folder path with specific extensions.\n",
    "    \n",
    "    :param folder_path: Path to the folder containing the files to read\n",
    "    :return: List of tuples containing file paths and their contents\n",
    "    \"\"\"\n",
    "    files_and_code = []\n",
    "    file_extensions = ['.py', 'Dockerfile', '.yaml', '.env-example', '.md', \"ipynb\"]\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if any(file_name.endswith(ext) for ext in file_extensions):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    code = file.read()\n",
    "                    files_and_code.append((file_path, code))\n",
    "    \n",
    "    return files_and_code\n",
    "\n",
    "def create_txt_from_files(folder_path, output_txt_path):\n",
    "    \"\"\"\n",
    "    Create a text file containing the contents of all files in the specified folder.\n",
    "    \n",
    "    :param folder_path: Path to the folder containing the files to process\n",
    "    :param output_txt_path: Path where the output text file will be saved\n",
    "    \"\"\"\n",
    "    files_and_code = read_files(folder_path)\n",
    "    text = \"\"\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as output_file:\n",
    "        for file_path, code in files_and_code:\n",
    "            # Get relative path from the root folder\n",
    "            relative_path = os.path.relpath(file_path, folder_path)\n",
    "            text += f\"\\n{'='*80}\\n\"\n",
    "            output_file.write(f\"\\n{'='*80}\\n\")\n",
    "            text += f\"# {relative_path}\\n\"\n",
    "            output_file.write(f\"# {relative_path}\\n\")\n",
    "            text += f\"{'='*80}\\n\\n\"\n",
    "            output_file.write(f\"{'='*80}\\n\\n\")\n",
    "            text += f\"{code}\\n\\n\"\n",
    "            output_file.write(code)\n",
    "            output_file.write('\\n\\n')\n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "folder_path = '/Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille@gmail.com/My Drive/REPO/llmops-youtube-summarizer'  # replace with your folder path\n",
    "output_txt_path = 'output.txt'  # replace with your output text file path\n",
    "text = create_txt_from_files(folder_path, output_txt_path)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}



================================================================================
# 01_PoC.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer using Groq\n",
    "\n",
    "This notebook demonstrates how to create a YouTube video summarizer that:\n",
    "1. Takes a YouTube URL as input\n",
    "2. Extracts the video's transcription\n",
    "3. Uses Groq to generate a concise summary\n",
    "\n",
    "## Setup and Requirements\n",
    "First, we'll install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api groq python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(\n",
    "    api_key=os.getenv('GROQ_API_KEY')  # Put your API key here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(url):\n",
    "    \"\"\"Helper function to extract YouTube video ID from URL\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.hostname == 'youtu.be':\n",
    "        return parsed_url.path[1:]\n",
    "    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "        if parsed_url.path == '/watch':\n",
    "            return parse_qs(parsed_url.query)['v'][0]\n",
    "    return None\n",
    "\n",
    "def get_transcript(video_id):\n",
    "    \"\"\"Helper function to get transcript for a YouTube video\"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\n",
    "        return ' '.join([t['text'] for t in transcript_list])\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting transcript: {e}\")\n",
    "        return None\n",
    "\n",
    "def summarize_text(text, language=\"spanish\"):\n",
    "    \"\"\"Summarize text using Groq\"\"\"\n",
    "    prompt = f\"\"\"Please provide a comprehensive summary of the following video transcript in {language}. \n",
    "    Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "    {text}\n",
    "\n",
    "    Please structure the summary with:\n",
    "    1. Main Topic/Theme\n",
    "    2. Key Points\n",
    "    3. Important Details\n",
    "    4. Conclusions\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama-3.2-11b-vision-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in summarization: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function to Summarize YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_youtube_video(url, language=\"spanish\"):\n",
    "    \"\"\"Main function to summarize a YouTube video\"\"\"\n",
    "    # Extract video ID\n",
    "    video_id = extract_video_id(url)\n",
    "    if not video_id:\n",
    "        return \"Invalid YouTube URL\"\n",
    "    \n",
    "    # Get transcript\n",
    "    transcript = get_transcript(video_id)\n",
    "    transcript = transcript[:6000*4]\n",
    "    if not transcript:\n",
    "        return \"Could not retrieve transcript\"\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = summarize_text(transcript, language)\n",
    "    if not summary:\n",
    "        return \"Could not generate summary\"\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "To use this summarizer, you'll need to:\n",
    "1. Create a `.env` file in the same directory as this notebook\n",
    "2. Add your Groq API key to the `.env` file: `GROQ_API_KEY=your_api_key_here`\n",
    "\n",
    "Then you can use the summarizer as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**1. Main Topic/Theme**\n",
      "\n",
      "La emergencia invernal en Colombia, específicamente en los departamentos de Chocó, Guajira, Santander y Bogotá, ha causado daños significativos y afectado a miles de personas.\n",
      "\n",
      "**2. Key Points**\n",
      "\n",
      "* La emergencia invernal ha causado daños en varios departamentos de Colombia, incluyendo Chocó, Guajira, Santander y Bogotá.\n",
      "* Miles de personas han sido afectadas, con algunas familias sin acceso a alimentos, agua potable y atención médica.\n",
      "* La falta de infraestructura y servicios básicos en algunas regiones ha agravado la situación.\n",
      "* La ayuda humanitaria ha sido lenta en llegar a algunas áreas, lo que ha generado preocupación y angustia entre los afectados.\n",
      "* La solidaridad de la comunidad colombiana ha sido notable, con donaciones y ayudas llegando a los afectados.\n",
      "\n",
      "**3. Important Details**\n",
      "\n",
      "* En el departamento de Chocó, 188.000 personas han sido afectadas, con 40.000 familias damnificadas.\n",
      "* En la alta Guajira, 192.000 personas han sido afectadas, con una sola aeronave llegando con ayudas humanitarias.\n",
      "* En Santander, más de 350 familias han resultado damnificadas por el desbordamiento de la quebrada Las Cruces.\n",
      "* En Bogotá, una avalancha en el barrio Las Delicias del Carmen ha afectado a varias viviendas y vehículos.\n",
      "* La alcaldía de San Vicente de Chucurí había solicitado ayuda para prevenir la avalancha que se registró en diciembre de 2023.\n",
      "\n",
      "**4. Conclusions**\n",
      "\n",
      "La emergencia invernal en Colombia ha causado daños significativos y afectado a miles de personas. La falta de infraestructura y servicios básicos en algunas regiones ha agravado la situación. Sin embargo, la solidaridad de la comunidad colombiana ha sido notable, con donaciones y ayudas llegando a los afectados. Es importante que se continúe trabajando para brindar ayuda y apoyo a las personas afectadas y que se tomen medidas para prevenir y mitigar futuras emergencias.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "youtube_url = \"https://www.youtube.com/watch?v=r5mEZCiXYN4&pp=ygUMZXBtIGNvbG9tYmlh\"\n",
    "language = \"spanish\"\n",
    "summary = summarize_youtube_video(youtube_url, language)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# 02_MLFlow_implementation.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer with MLflow Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Create a YouTube video summarization chain\n",
    "2. Track the chain and prompts using MLflow\n",
    "3. Load and use the tracked model\n",
    "\n",
    "## Setup and Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in databricks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\n",
      "Requirement already satisfied: youtube-transcript-api in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.6.3)\n",
      "Requirement already satisfied: groq in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install youtube-transcript-api groq python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api groq python-dotenv mlflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import databricks.mlflow\n",
    "    IS_DATABRICKS = True\n",
    "    import dbutils\n",
    "except ImportError:\n",
    "    IS_DATABRICKS = False\n",
    "\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Chain Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeSummaryChain:\n",
    "    def __init__(self, model_name: str = \"mixtral-8x7b-32768\", temperature: float = 0.3, prompt_template: str = \"\", language: str = \"spanish\"):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.language = language\n",
    "        if prompt_template == \"\":\n",
    "            self.prompt_template = \"\"\"\n",
    "            Please provide a comprehensive summary of the following video transcript in {language}. \n",
    "            Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "            {text}\n",
    "\n",
    "            Please structure the summary with:\n",
    "            1. Main Topic/Theme\n",
    "            2. Key Points\n",
    "            3. Important Details\n",
    "            4. Conclusions\n",
    "            \"\"\"\n",
    "        else:\n",
    "            self.prompt_template = prompt_template\n",
    "    \n",
    "    def summarize_text(self, text):\n",
    "        \"\"\"Summarize text using Groq\"\"\"\n",
    "        # Initialize client only when needed\n",
    "        if IS_DATABRICKS:\n",
    "            groq_api_key = dbutils.secrets.get(scope=\"your-scope\", key=\"groq-api-key\")\n",
    "        else:\n",
    "            groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "            \n",
    "        client = groq.Groq(api_key=groq_api_key)\n",
    "        prompt = self.prompt_template.format(text=text, language=self.language)\n",
    "\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=2048\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error in summarization: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_video_id(self, url: str) -> str:\n",
    "        \"\"\"Extract YouTube video ID from URL\"\"\"\n",
    "        parsed_url = urlparse(url)\n",
    "        if parsed_url.hostname == 'youtu.be':\n",
    "            return parsed_url.path[1:]\n",
    "        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "            if parsed_url.path == '/watch':\n",
    "                return parse_qs(parsed_url.query)['v'][0]\n",
    "        return None\n",
    "\n",
    "    def get_transcript(self, video_id: str) -> str:\n",
    "        \"\"\"Get transcript for a YouTube video\"\"\"\n",
    "        try:\n",
    "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\n",
    "            return ' '.join([t['text'] for t in transcript_list])\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __call__(self, url: str) -> str:\n",
    "        \"\"\"Process a YouTube URL and return summary\"\"\"\n",
    "        video_id = self.extract_video_id(url)\n",
    "        if not video_id:\n",
    "            return \"Invalid YouTube URL\"\n",
    "        \n",
    "        transcript = self.get_transcript(video_id)\n",
    "        if not transcript:\n",
    "            return \"Could not retrieve transcript\"\n",
    "        \n",
    "        summary = self.summarize_text(transcript)\n",
    "        if not summary:\n",
    "            return \"Could not generate summary\"\n",
    "        \n",
    "        return summary, transcript\n",
    "\n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get chain configuration for MLflow tracking\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"prompt_template\": self.prompt_template\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mlflow():\n",
    "    \"\"\"\n",
    "    Set up MLflow tracking with support for both Databricks and local environments\n",
    "    \n",
    "    :return: None\n",
    "    :raises: MLflowException if tracking setup fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if IS_DATABRICKS:\n",
    "            # Databricks automatically configures tracking URI\n",
    "            print(\"Running in Databricks environment\")\n",
    "        else:\n",
    "            mlflow_dir = Path(\"mlruns\")\n",
    "            mlflow_dir.mkdir(exist_ok=True)\n",
    "            mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up MLflow tracking: {e}\")\n",
    "        raise\n",
    "\n",
    "def log_chain_to_mlflow(chain: YouTubeSummaryChain, experiment_name: str = \"youtube-summarizer\"):\n",
    "    \"\"\"\n",
    "    Log the chain configuration and prompt to MLflow with Databricks support\n",
    "    \n",
    "    :param chain: YouTubeSummaryChain instance to log\n",
    "    :param experiment_name: Name of the MLflow experiment\n",
    "    :return: MLflow run ID\n",
    "    :raises: MLflowException if logging fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if IS_DATABRICKS:\n",
    "            # Use workspace path for Databricks\n",
    "            experiment_path = f\"/Shared/{experiment_name}\"\n",
    "            try:\n",
    "                experiment = mlflow.get_experiment_by_name(experiment_path)\n",
    "                if experiment is None:\n",
    "                    mlflow.create_experiment(experiment_path)\n",
    "                mlflow.set_experiment(experiment_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting up Databricks experiment: {e}\")\n",
    "                raise\n",
    "        else:\n",
    "            # Local experiment setup\n",
    "            experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "            if experiment is None:\n",
    "                mlflow.create_experiment(experiment_name)\n",
    "            mlflow.set_experiment(experiment_name)\n",
    "        \n",
    "        with mlflow.start_run() as run:\n",
    "            # Log parameters\n",
    "            config = chain.get_config()\n",
    "            mlflow.log_params({\n",
    "                \"model_name\": config[\"model_name\"],\n",
    "                \"temperature\": config[\"temperature\"],\n",
    "                \"environment\": \"databricks\" if IS_DATABRICKS else \"local\"\n",
    "            })\n",
    "            \n",
    "            # Create temporary file for prompt template\n",
    "            prompt_path = None\n",
    "            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\n",
    "                f.write(config[\"prompt_template\"])\n",
    "                prompt_path = f.name\n",
    "            \n",
    "            try:\n",
    "                # Create wrapper\n",
    "                wrapper = YouTubeSummarizerWrapper(chain)\n",
    "                \n",
    "                # Log the model with requirements\n",
    "                requirements = [\n",
    "                    \"youtube-transcript-api\",\n",
    "                    \"groq\",\n",
    "                    \"python-dotenv\",\n",
    "                    \"pandas\"\n",
    "                ]\n",
    "                if IS_DATABRICKS:\n",
    "                    requirements.append(\"databricks-mlflow\")\n",
    "                \n",
    "                mlflow.pyfunc.log_model(\n",
    "                    artifact_path=\"youtube_summarizer\",\n",
    "                    python_model=wrapper,\n",
    "                    artifacts={\"prompt_template\": prompt_path},\n",
    "                    pip_requirements=requirements\n",
    "                )\n",
    "            finally:\n",
    "                # Clean up temp file after logging\n",
    "                if prompt_path and os.path.exists(prompt_path):\n",
    "                    os.unlink(prompt_path)\n",
    "            \n",
    "            return run.info.run_id\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error logging chain to MLflow: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_chain_from_mlflow(run_id: str) -> YouTubeSummaryChain:\n",
    "    \"\"\"\n",
    "    Load a chain from MLflow with Databricks support\n",
    "    \n",
    "    :param run_id: MLflow run ID to load\n",
    "    :return: Loaded chain\n",
    "    :raises: MLflowException if loading fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if IS_DATABRICKS:\n",
    "            model_uri = f\"runs:/{run_id}/youtube_summarizer\"\n",
    "            chain = mlflow.pyfunc.load_model(model_uri)\n",
    "            return chain\n",
    "        else:\n",
    "            model_uri = f\"runs:/{run_id}/youtube_summarizer\"\n",
    "            chain = mlflow.pyfunc.load_model(model_uri)\n",
    "            return chain\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading chain from MLflow: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "class YouTubeSummarizerWrapper(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    MLflow wrapper for YouTube summarizer\n",
    "    \n",
    "    :param chain: Instance of YouTubeSummaryChain\n",
    "    \"\"\"\n",
    "    def __init__(self, chain=None):\n",
    "        self.chain = chain or YouTubeSummaryChain()\n",
    "        \n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        :param context: MLflow model context\n",
    "        :param model_input: DataFrame or Series containing YouTube URLs\n",
    "        :return: List of summaries\n",
    "        \"\"\"\n",
    "        if isinstance(model_input, pd.Series):\n",
    "            urls = model_input.tolist()\n",
    "        else:\n",
    "            urls = model_input['url'].tolist()\n",
    "            \n",
    "        return [self.chain(url) for url in urls]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a105ce5f5a3d4b7ca154e6cb0309f56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 09:50:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain logged with run_id: 327f957a0ae94cf58849f91eb5362af9\n",
      "1. Main Topic/Theme:\n",
      "The main topic of this transcript is the announcement of the beginning of the process of selling the telecommunications branch of Empresas Públicas de Medellín (EPM) by its manager, John Maya.\n",
      "\n",
      "2. Key Points:\n",
      "   - The telecommunications industry requires high capital investments due to its rapid technological changes every 5 years.\n",
      "   - EPM, as a public service provider, needs to invest in strategic areas such as energy generation, distribution, water supply, and gas, instead of telecommunications.\n",
      "   - The sale of the telecommunications branch depends on the approval of the Medellín Council, and the funds will be specifically allocated to EPM, not the mayoralty.\n",
      "   - EPM's current financial situation is good, with positive results in the first semester of the year, but there is a budget deficit of around 500,000 million pesos for planned projects.\n",
      "   - The sale process will follow a specific route, starting with offering the shares to the solidarity sector, then to special sectors, and finally to the general market.\n",
      "   - If the sale is not successful in any of these phases, EPM will continue as a partner in the telecommunications company.\n",
      "\n",
      "3. Important Details:\n",
      "   - The value of the telecommunications branch in EPM's books is 1.6 billion pesos, considering the 2022 deterioration of 1.04 billion pesos and the 2023 capitalization of 600,000 million pesos, of which 300,000 million corresponded to EPM.\n",
      "   - The government is also considering selling its shares in the telecommunications market, which could lead to a stronger competitor against the current market leader, Claro.\n",
      "   - If the sale is approved, the resources will be allocated to education and scholarships, innovation and technology for public services, waste valorization, and improving connectivity in communities.\n",
      "\n",
      "4. Conclusions:\n",
      "   - The decision to sell the telecommunications branch of EPM aims to optimize the use of resources and focus on strategic areas for the company.\n",
      "   - The sale process will follow a specific order, and EPM will continue as a partner if the sale is not successful.\n",
      "   - The funds from the sale will be invested in various projects that benefit the public services sector, education, innovation, waste management, and connectivity.\n",
      "   - The government is also considering selling its shares in the telecommunications market, which could lead to a more competitive market.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "setup_mlflow()\n",
    "\n",
    "chain = YouTubeSummaryChain(language=\"spanish\")\n",
    "run_id = log_chain_to_mlflow(chain)\n",
    "print(f\"Chain logged with run_id: {run_id}\")\n",
    "\n",
    "# Load the chain\n",
    "loaded_chain = load_chain_from_mlflow(run_id)\n",
    "\n",
    "# Use the loaded chain - Fix the prediction call\n",
    "youtube_url = \"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\"\n",
    "# Convert single URL to pandas Series\n",
    "input_data = pd.Series([youtube_url])\n",
    "summary, transcript = loaded_chain.predict(input_data)[0]  # Get first result from the list\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(metrics_dict):\n",
    "    \"\"\"Log metrics to MLflow\"\"\"\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_metrics(metrics_dict)\n",
    "        mlflow.log_param(\"model_name\", \"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import psutil\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        self.metrics_history = []\n",
    "    \n",
    "    def measure_latency(self, func, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Measure execution time of a function\n",
    "        \n",
    "        :param func: Function to measure\n",
    "        :param args: Positional arguments for the function\n",
    "        :param kwargs: Keyword arguments for the function\n",
    "        :return: tuple of (results, execution_time)\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        results = func(*args, **kwargs)  # Just store the results directly\n",
    "        end_time = time.time()\n",
    "        return results, end_time - start_time\n",
    "    \n",
    "    def measure_resource_usage(self):\n",
    "        \"\"\"Measure CPU and memory usage\"\"\"\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_info = psutil.Process().memory_info()\n",
    "        return {\n",
    "            'cpu_percent': cpu_percent,\n",
    "            'memory_mb': memory_info.rss / 1024 / 1024\n",
    "        }\n",
    "    \n",
    "    def calculate_text_metrics(self, summary: str, transcript: str) -> dict:\n",
    "        \"\"\"\n",
    "        Calculate text-based metrics like reduction percentage and lengths\n",
    "        \n",
    "        :param summary: Generated summary text\n",
    "        :param transcript: Original transcript text\n",
    "        :return: Dictionary containing text metrics\n",
    "        \"\"\"\n",
    "        summary_length = len(summary.split())\n",
    "        transcript_length = len(transcript.split())\n",
    "        reduction_percentage = ((transcript_length - summary_length) / transcript_length) * 100\n",
    "        \n",
    "        return {\n",
    "            'summary_length': summary_length,\n",
    "            'transcript_length': transcript_length,\n",
    "            'reduction_percentage': reduction_percentage\n",
    "        }\n",
    "    \n",
    "    def log_performance(self, latency, summary: str, transcript: str, resource_usage: dict):\n",
    "        \"\"\"\n",
    "        Log all performance metrics including text metrics\n",
    "        \n",
    "        :param latency: Processing time\n",
    "        :param summary: Generated summary text\n",
    "        :param transcript: Original transcript text\n",
    "        :param resource_usage: Dictionary containing resource usage metrics\n",
    "        :return: Combined metrics dictionary\n",
    "        \"\"\"\n",
    "        text_metrics = self.calculate_text_metrics(summary, transcript)\n",
    "        metrics = {\n",
    "            'latency': latency,\n",
    "            **resource_usage,\n",
    "            **text_metrics\n",
    "        }\n",
    "        self.metrics_history.append(metrics)\n",
    "        log_metrics(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_over_time(metrics_history):\n",
    "    \"\"\"\n",
    "    Create interactive plots for metrics over time including text metrics\n",
    "    \n",
    "    :param metrics_history: List of dictionaries containing metrics data\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(metrics_history)\n",
    "    \n",
    "    # Latency plot\n",
    "    fig_latency = px.line(df, y='latency', title='Inference Latency Over Time')\n",
    "    fig_latency.show()\n",
    "    \n",
    "    # Resource usage plot\n",
    "    fig_resources = go.Figure()\n",
    "    fig_resources.add_trace(go.Scatter(y=df['cpu_percent'], name='CPU %'))\n",
    "    fig_resources.add_trace(go.Scatter(y=df['memory_mb'], name='Memory (MB)'))\n",
    "    fig_resources.update_layout(title='Resource Usage Over Time')\n",
    "    fig_resources.show()\n",
    "    \n",
    "    # Text metrics plot\n",
    "    fig_text = go.Figure()\n",
    "    text_metrics = ['summary_length', 'transcript_length', 'reduction_percentage']\n",
    "    for metric in text_metrics:\n",
    "        if metric in df.columns:\n",
    "            fig_text.add_trace(go.Scatter(y=df[metric], name=metric))\n",
    "    fig_text.update_layout(title='Text Metrics Over Time')\n",
    "    fig_text.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the performance monitor\n",
    "monitor = PerformanceMonitor()\n",
    "\n",
    "summarizer = load_chain_from_mlflow(run_id)\n",
    "\n",
    "def process_videos(video_ids):\n",
    "    \"\"\"\n",
    "    Process multiple videos with monitoring\n",
    "    \n",
    "    :param video_ids: List of YouTube video IDs or URLs\n",
    "    :return: tuple of (list of summaries, list of metrics)\n",
    "    \"\"\"\n",
    "    # if videos_ids is a string, convert it to a list\n",
    "    if isinstance(video_ids, str):\n",
    "        video_ids = [video_ids]\n",
    "    \n",
    "    # Prepare input data\n",
    "    input_data = []\n",
    "    for vid in video_ids:\n",
    "        if \"youtube.com\" in vid or \"youtu.be\" in vid:\n",
    "            input_data.append(vid)\n",
    "        else:\n",
    "            input_data.append(f\"https://youtube.com/watch?v={vid}\")\n",
    "    \n",
    "    input_series = pd.Series(input_data)\n",
    "    \n",
    "    # Process all videos\n",
    "    summaries = []\n",
    "    metrics_list = []\n",
    "    \n",
    "    # Generate summaries with latency measurement\n",
    "    results, total_latency = monitor.measure_latency(\n",
    "        lambda: summarizer.predict(input_series)\n",
    "    )\n",
    "    \n",
    "    # Calculate average latency per video\n",
    "    avg_latency = total_latency / len(video_ids)\n",
    "    \n",
    "    # Process each result\n",
    "    for result in results:\n",
    "        summary, transcript = result  # Unpack each result\n",
    "        \n",
    "        # Measure resource usage\n",
    "        resource_usage = monitor.measure_resource_usage()\n",
    "\n",
    "        # Log metrics for each video\n",
    "        metrics = monitor.log_performance(avg_latency, summary, transcript, resource_usage)\n",
    "        \n",
    "        summaries.append(summary)\n",
    "        metrics_list.append(metrics)\n",
    "    \n",
    "    return summaries, metrics_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "index=%{x}<br>latency=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2
         ],
         "xaxis": "x",
         "y": [
          45.083091020584106,
          45.083091020584106,
          45.083091020584106
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Inference Latency Over Time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "latency"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "CPU %",
         "type": "scatter",
         "y": [
          19.9,
          28.8,
          31.6
         ]
        },
        {
         "name": "Memory (MB)",
         "type": "scatter",
         "y": [
          103.125,
          139.75,
          144.109375
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Resource Usage Over Time"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "summary_length",
         "type": "scatter",
         "y": [
          28,
          40,
          305
         ]
        },
        {
         "name": "transcript_length",
         "type": "scatter",
         "y": [
          1819,
          2576,
          1936
         ]
        },
        {
         "name": "reduction_percentage",
         "type": "scatter",
         "y": [
          98.46069268829028,
          98.4472049689441,
          84.24586776859503
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Text Metrics Over Time"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "videos_ids = [\"https://www.youtube.com/watch?v=v2DGDwOjdIk&pp=ygUMZXBtIGNvbG9tYmlh\",\n",
    "              \"https://www.youtube.com/watch?v=mACcTs5YsMM&pp=ygUMZXBtIGNvbG9tYmlh\",\n",
    "              \"https://www.youtube.com/watch?v=2LU9KKnI4Do&pp=ygUMZXBtIGNvbG9tYmlh\"]\n",
    "\n",
    "summary, metrics = process_videos(videos_ids)\n",
    "plot_metrics_over_time(monitor.metrics_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ganga/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data() -> List[Dict[str, str]]:\n",
    "    \"\"\"Prepare test data with YouTube videos and reference summaries\"\"\"\n",
    "    # Replace with your actual test data\n",
    "    return [\n",
    "        {\n",
    "            \"video_url\": \"https://www.youtube.com/watch?v=v2DGDwOjdIk&pp=ygUMZXBtIGNvbG9tYmlh\",\n",
    "            \"reference_summary\": \"This source is a transcript of a video detailing the history of Empresas Públicas de Medellín (EPM), a public service company in Medellín, Colombia. It highlights the pivotal moment when Medellín was first illuminated by electric light in 1898, a time when gas lamps were the norm, and emphasizes the impact of this innovation on the city and its residents. The text also emphasizes the importance of EPM’s continued service in bringing electricity to remote areas in Colombia even in the 21st century, demonstrating the company's commitment to providing essential services to all. The transcript showcases the evolution of EPM from its origins in private companies to its current status as a public utility, highlighting its historical significance and its ongoing role in improving the lives of people in Medellín and beyond.\"\n",
    "        },\n",
    "        {\n",
    "            \"video_url\": \"https://www.youtube.com/watch?v=mACcTs5YsMM&pp=ygUMZXBtIGNvbG9tYmlh\",\n",
    "            \"reference_summary\": \"This source is a transcript of a radio interview with John Maya, the manager of Empresas Públicas de Medellín (EPM), a public utility company in Colombia. The interview focuses on the financial difficulties faced by Afinia, a subsidiary of EPM that provides electricity to the Colombian Caribbean coast. Maya explains that Afinia's problems stem from a combination of factors, including a lack of government subsidies, delayed payments for a tariff option, and a rise in energy losses due to increased consumption and unpaid bills. He asserts that the root of the problem lies not with Afinia's management, but with the high cost of electricity in the region, which is driven by a combination of factors including high electricity generation costs and energy losses. Maya proposes a solution involving the government taking over a portion of the costs, but expresses concern about the slow pace of progress and the potential for the government to intervene and permanently take control of Afinia, a scenario he considers problematic. He also criticizes the previous administration's decision to replace Afinia's experienced manager with someone less qualified, a move that negatively impacted the company's performance. Overall, the interview provides insight into the complex financial and operational challenges faced by Afinia and the broader electricity sector in the Colombian Caribbean coast, highlighting the role of government policy, energy market dynamics, and internal management in shaping the current situation.\"\n",
    "        },\n",
    "        {\n",
    "            \"video_url\": \"https://www.youtube.com/watch?v=2LU9KKnI4Do&pp=ygUMZXBtIGNvbG9tYmlh\",\n",
    "            \"reference_summary\": \"This excerpt is a transcript of a radio interview with Federico Gutiérrez, the mayor of Medellín, Colombia. The interview focuses on a looming crisis in Colombia’s natural gas supply, with Gutiérrez warning of potential rationing and price increases due to a nationwide shortage. He emphasizes the urgency of the situation, noting that existing supply contracts are expiring soon and that there are insufficient offers to meet projected demand. Gutiérrez argues that the government's energy policies have contributed to this crisis by neglecting exploration and exploitation. He also criticizes President Petro for using inflammatory language to describe a police intervention that involved removing an individual who was allegedly exposing himself to children, characterizing it as an instance of fascism. Gutiérrez contrasts this with his own focus on governance and addressing the city's pressing needs.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "test_data = prepare_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def evaluate_transcript_with_llm(transcript: str, predicted_summary: str, reference_summary: str) -> str:\n",
    "    \"\"\"Evaluate a transcript with a LLM\"\"\"\n",
    "    if IS_DATABRICKS:\n",
    "            groq_api_key = dbutils.secrets.get(scope=\"your-scope\", key=\"groq-api-key\")\n",
    "    else:\n",
    "        groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "    client = groq.Groq(api_key=groq_api_key)\n",
    "    prompt_template = \"\"\"\n",
    "    You are a professional editor, give me a score for the following summary based on the reference summary:\n",
    "    \n",
    "    transcript: {transcript}\n",
    "    reference summary: {reference_summary}\n",
    "    predicted summary: {predicted_summary}\n",
    "    \n",
    "    give me a score between 0 and 100 for the predicted summary\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = prompt_template.format(transcript=transcript, predicted_summary=predicted_summary, reference_summary=reference_summary)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama-3.2-90b-vision-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        result = completion.choices[0].message.content\n",
    "        # extract number from the result using regex\n",
    "        return int(re.search(r'\\d+', result).group())\n",
    "    except Exception as e:\n",
    "        print(f\"Error in summarization: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_metrics(transcript: str, predicted_summary: str, reference_summary: str) -> Dict[str, float]:\n",
    "    \"\"\"Calculate various evaluation metrics\"\"\"\n",
    "    # ROUGE scores\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = scorer.score(reference_summary, predicted_summary)\n",
    "    \n",
    "    # BLEU score\n",
    "    reference = [reference_summary.split()]\n",
    "    candidate = predicted_summary.split()\n",
    "    bleu = sentence_bleu(reference, candidate)\n",
    "    \n",
    "    # Summary length metrics\n",
    "    pred_length = len(predicted_summary.split())\n",
    "    ref_length = len(reference_summary.split())\n",
    "    length_ratio = pred_length / ref_length if ref_length > 0 else 0\n",
    "    \n",
    "    # Evaluation with LLM\n",
    "    score_llm = evaluate_transcript_with_llm(transcript, predicted_summary, reference_summary)\n",
    "    \n",
    "    return {\n",
    "        'rouge1_precision': rouge_scores['rouge1'].precision,\n",
    "        'rouge1_recall': rouge_scores['rouge1'].recall,\n",
    "        'rouge1_f1': rouge_scores['rouge1'].fmeasure,\n",
    "        'rouge2_f1': rouge_scores['rouge2'].fmeasure,\n",
    "        'rougeL_f1': rouge_scores['rougeL'].fmeasure,\n",
    "        'bleu_score': bleu,\n",
    "        'summary_length_ratio': length_ratio,\n",
    "        'predicted_length': pred_length,\n",
    "        'reference_length': ref_length,\n",
    "        'llm_score': score_llm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_log_visualizations(metrics_list: List[Dict[str, float]]):\n",
    "    \"\"\"Create and log visualizations to MLflow\"\"\"\n",
    "    # Convert metrics to DataFrame\n",
    "    df = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    # ROUGE scores comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    rouge_metrics = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']\n",
    "    df[rouge_metrics].mean().plot(kind='bar')\n",
    "    plt.title('Average ROUGE Scores')\n",
    "    plt.ylabel('Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('rouge_scores.png')\n",
    "    mlflow.log_artifact('rouge_scores.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Summary length analysis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['reference_length'], df['predicted_length'])\n",
    "    plt.plot([0, max(df['reference_length'])], [0, max(df['reference_length'])], '--', color='red')\n",
    "    plt.xlabel('Reference Summary Length')\n",
    "    plt.ylabel('Predicted Summary Length')\n",
    "    plt.title('Summary Length Comparison')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('length_comparison.png')\n",
    "    mlflow.log_artifact('length_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Metrics distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics_to_plot = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1', 'bleu_score']\n",
    "    df[metrics_to_plot].boxplot()\n",
    "    plt.title('Distribution of Evaluation Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_distribution.png')\n",
    "    mlflow.log_artifact('metrics_distribution.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_mlflow(model, test_data: List[Dict[str, str]]):\n",
    "    \"\"\"Evaluate model and log results to MLflow\"\"\"\n",
    "    mlflow.set_experiment(\"youtube-summarizer-evaluation\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"model_evaluation\") as run:\n",
    "        all_metrics = []\n",
    "        \n",
    "        # Log model parameters if available\n",
    "        model_params = model.get_config() if hasattr(model, 'get_config') else {}\n",
    "        mlflow.log_params(model_params)\n",
    "        \n",
    "        # Evaluate each test example\n",
    "        for i, example in enumerate(test_data):\n",
    "            try:\n",
    "                # Generate summary using predict method\n",
    "                input_data = pd.Series([example['video_url']])\n",
    "                result = model.predict(input_data)[0]  # Get first result\n",
    "                \n",
    "                # Check the type of result and handle accordingly\n",
    "                if isinstance(result, tuple):\n",
    "                    summary, transcript = result\n",
    "                elif isinstance(result, str):\n",
    "                    summary = result\n",
    "                    transcript = \"Transcript not available\"  # fallback\n",
    "                else:\n",
    "                    print(f\"Unexpected result type: {type(result)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate metrics\n",
    "                metrics = calculate_metrics(transcript, summary, example['reference_summary'])\n",
    "                all_metrics.append(metrics)\n",
    "                \n",
    "                # Log metrics for each example\n",
    "                for metric_name, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"example_{i}_{metric_name}\", value)\n",
    "                \n",
    "                # Log summaries as artifacts\n",
    "                example_dir = f\"example_{i}\"\n",
    "                os.makedirs(example_dir, exist_ok=True)\n",
    "                \n",
    "                with open(f\"{example_dir}/predicted_summary.txt\", \"w\") as f:\n",
    "                    f.write(summary)\n",
    "                with open(f\"{example_dir}/reference_summary.txt\", \"w\") as f:\n",
    "                    f.write(example['reference_summary'])\n",
    "                \n",
    "                mlflow.log_artifacts(example_dir)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing example {i}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not all_metrics:\n",
    "            print(\"No successful evaluations completed\")\n",
    "            return None, None\n",
    "            \n",
    "        # Calculate and log average metrics\n",
    "        avg_metrics = {}\n",
    "        for metric in all_metrics[0].keys():\n",
    "            avg_value = np.mean([m[metric] for m in all_metrics])\n",
    "            avg_metrics[f\"avg_{metric}\"] = avg_value\n",
    "            mlflow.log_metric(f\"avg_{metric}\", avg_value)\n",
    "        \n",
    "        # Create and log visualizations\n",
    "        create_and_log_visualizations(all_metrics)\n",
    "        \n",
    "        return run.info.run_id, avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base line Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log experiment to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21525b2c624b4237a82f3311b2c6305e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 09:57:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain logged with run_id: 7af45a39ac3049e7bada8bc93b771e0b\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "setup_mlflow()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Please provide a comprehensive summary of the following video transcript in {language}. \n",
    "Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "{text}\n",
    "\n",
    "Please structure the summary with:\n",
    "1. Main Topic/Theme\n",
    "2. Key Points\n",
    "3. Important Details\n",
    "4. Conclusions\n",
    "\"\"\"\n",
    "model_name = \"llama-3.2-90b-vision-preview\"\n",
    "\n",
    "chain = YouTubeSummaryChain(prompt_template=prompt_template, language=\"english\")\n",
    "run_id = log_chain_to_mlflow(chain)\n",
    "print(f\"Chain logged with run_id: {run_id}\")\n",
    "\n",
    "# Load the chain\n",
    "loaded_chain = load_chain_from_mlflow(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Main Topic/Theme:\n",
      "The main topic of the transcript is the proposed sale of EPM's stake in Tigo-Une by the manager of DPM (Dirección de Proyectos Estratégicos - Strategic Projects Directorate), John Maya. He discusses the reasons for selling, the financial situation of EPM, and the potential use of the sale's proceeds.\n",
      "\n",
      "2. Key Points:\n",
      "\n",
      "- The telecommunications industry requires significant capital investments due to rapid technological changes every 5 years.\n",
      "- EPM, as a public services provider, needs to invest in strategic areas like energy generation, distribution, water, gas, and telecommunications through partners.\n",
      "- EPM has identified a budget deficit of around $150 million for financing planned projects.\n",
      "- The value of Tigo-Une's shares in EPM's books is around 1.6 trillion pesos ($400 million) after accounting for a 1.04 trillion pesos ($250 million) deterioration in 2022.\n",
      "- The sale of Tigo-Une's shares requires the approval of the EPM board and a subsequent valuation by a financial institution.\n",
      "- The government is also considering selling its stake in Telecom, which may result in a stronger competitor for Claro in the Colombian telecommunications market.\n",
      "- If the sale is not approved by the sector, special groups, or the market, EPM has a clause to sell the shares with a partner, such as Millicom (Tigo's parent company).\n",
      "- The potential use of the sale's proceeds includes education, innovation, residue valorization, and improving connectivity in underserved areas.\n",
      "\n",
      "3. Important Details:\n",
      "\n",
      "- EPM's financial situation is good, with positive results in the first semester of the year.\n",
      "- EPM's budget deficit is not a loss or a sign of financial difficulties but a result of insufficient financing for planned projects.\n",
      "- The deterioration of Tigo-Une's shares in 2022 occurred during the administration of former Medellín mayor Daniel Quintero.\n",
      "- The sale of Tigo-Une's shares would not directly benefit the city of Medellín, as the funds would be reinvested in EPM for specific purposes.\n",
      "- EPM's extensive fiber-optic network can be used to improve connectivity in schools, hospitals, and communities, but EPM does not intend to enter the telecommunications commercialization business.\n",
      "\n",
      "4. Conclusions:\n",
      "\n",
      "- The sale of EPM's stake in Tigo-Une is driven by the need to invest in strategic areas and the rapid technological changes in the telecommunications industry.\n",
      "- EPM's financial situation is stable, but there is a budget deficit for planned projects.\n",
      "- The potential sale of Tigo-Une's shares would require several approvals and valuations, and the proceeds would be reinvested in EPM for various purposes.\n",
      "- The government is also considering selling its stake in Telecom, which could impact the Colombian telecommunications market.\n",
      "- EPM aims to improve education, innovation, residue valorization, and connectivity in underserved areas with the potential sale's proceeds.\n"
     ]
    }
   ],
   "source": [
    "# Use the loaded chain - Fix the prediction call\n",
    "youtube_url = \"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\"\n",
    "# Convert single URL to pandas Series\n",
    "input_data = pd.Series([youtube_url])\n",
    "summary, transcript = loaded_chain.predict(input_data)[0]  # Get first result from the list\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning:\n",
      "\n",
      "\n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "==================\n",
      "avg_rouge1_precision: 0.2747\n",
      "avg_rouge1_recall: 0.5431\n",
      "avg_rouge1_f1: 0.3603\n",
      "avg_rouge2_f1: 0.1044\n",
      "avg_rougeL_f1: 0.1901\n",
      "avg_bleu_score: 0.0325\n",
      "avg_summary_length_ratio: 2.1463\n",
      "avg_predicted_length: 334.3333\n",
      "avg_reference_length: 165.3333\n",
      "avg_llm_score: 87.3333\n",
      "\n",
      "MLflow run ID: 467d9e0959a444a181fcd6c889663c1e\n",
      "View detailed results in the MLflow UI\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data\n",
    "test_data = prepare_test_data()\n",
    "\n",
    "# Run evaluation\n",
    "run_id, avg_metrics = evaluate_model_with_mlflow(loaded_chain, test_data)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(\"==================\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nMLflow run ID: {run_id}\")\n",
    "print(\"View detailed results in the MLflow UI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff8cc9a6f8d4f19b7f417abb75dd969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 10:01:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain logged with run_id: 4a78dfca7de94b32882502181643e67c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning:\n",
      "\n",
      "\n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "==================\n",
      "avg_rouge1_precision: 0.2477\n",
      "avg_rouge1_recall: 0.5797\n",
      "avg_rouge1_f1: 0.3453\n",
      "avg_rouge2_f1: 0.1109\n",
      "avg_rougeL_f1: 0.1838\n",
      "avg_bleu_score: 0.0393\n",
      "avg_summary_length_ratio: 2.4600\n",
      "avg_predicted_length: 394.3333\n",
      "avg_reference_length: 165.3333\n",
      "avg_llm_score: 87.3333\n",
      "\n",
      "MLflow run ID: 35ebfbc3649d4024a1691655a74dbae1\n",
      "View detailed results in the MLflow UI\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "setup_mlflow()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Please provide a comprehensive summary of the following video transcript in {language}. \n",
    "Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "{text}\n",
    "\n",
    "Please structure the summary with:\n",
    "1. Main Topic/Theme\n",
    "2. Key Points\n",
    "3. Important Details\n",
    "4. Conclusions\n",
    "\"\"\"\n",
    "model_name = \"llama-3.2-11b-text-preview\"\n",
    "\n",
    "chain = YouTubeSummaryChain(prompt_template=prompt_template, language=\"english\")\n",
    "run_id = log_chain_to_mlflow(chain)\n",
    "print(f\"Chain logged with run_id: {run_id}\")\n",
    "\n",
    "# Load the chain\n",
    "loaded_chain = load_chain_from_mlflow(run_id)\n",
    "\n",
    "# Prepare test data\n",
    "test_data = prepare_test_data()\n",
    "\n",
    "# Run evaluation\n",
    "run_id, avg_metrics = evaluate_model_with_mlflow(loaded_chain, test_data)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(\"==================\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nMLflow run ID: {run_id}\")\n",
    "print(\"View detailed results in the MLflow UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View MLflow Experiment Results\n",
    "\n",
    "You can view the tracked experiments by running:\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "This will start the MLflow UI server where you can see:\n",
    "1. All experiment runs\n",
    "2. Chain configurations\n",
    "3. Prompt templates\n",
    "4. Performance metrics (if added)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# 03_CrewAi_example.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this use case we are going to use crewai to generate code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrewAi Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\n",
      "Collecting crewai\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/13/55/8caa2264c59be4c11266be1aae2b57610dcd30cd1c6f0752416589126f3b/crewai-0.80.0-py3-none-any.whl (197 kB)\n",
      "Collecting appdirs>=1.4.4 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting auth0-python>=4.7.1 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/e4/0e/38cb7b781371e79e9c697fb78f3ccd18fda8bd547d0a2e76e616561a3792/auth0_python-4.7.2-py3-none-any.whl (131 kB)\n",
      "Collecting chromadb>=0.4.24 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/5f/7a/10bf5dc92d13cc03230190fcc5016a0b138d99e5b36b8b89ee0fe1680e10/chromadb-0.5.20-py3-none-any.whl (617 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m264.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=8.1.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (8.1.7)\n",
      "Collecting crewai-tools>=0.14.0 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c8/ed/9f4e64e1507062957b0118085332d38b621c1000874baef2d1c4069bfd97/crewai_tools-0.14.0-py3-none-any.whl (462 kB)\n",
      "Collecting instructor>=1.3.3 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/9d/f1/e136ffee98aeadb6c6f3d36fe7ff6cdcc08d857827b9f234e67d1abe18e6/instructor-1.6.4-py3-none-any.whl (70 kB)\n",
      "Collecting json-repair>=0.25.2 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ed/e0/6eb79e8b0379df19d0567adbe4c4cde4a328423bf0452a4dcd77aa00f901/json_repair-0.30.2-py3-none-any.whl (18 kB)\n",
      "Collecting jsonref>=1.1.0 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/0c/ec/e1db9922bceb168197a558a2b8c03a7963f1afe93517ddd3cf99f202f996/jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Collecting langchain>=0.2.16 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/49/09/72630413a7ded27684e33392a0ff52ff1c8ea6749fee641319e75f82072b/langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m329.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting litellm>=1.44.22 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/83/19/f0725dfecfc9f3ed7eb433b5f303b6af4fb5245ed5ed6735f32872df9c65/litellm-1.52.10-py3-none-any.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m278.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting openai>=1.13.3 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/30/90/7f6621a79de8b32f120e9790441c24dd9afafb2f1ca41fd3b9f4faaf8f9f/openai-1.54.5-py3-none-any.whl (389 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (1.28.2)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.22.0 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/19/23/802b889cf8bf3e235f30fbcbaa2b3fd484fe8c76b5b4db00f00c0e9af20f/opentelemetry_exporter_otlp_proto_http-1.28.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (1.28.2)\n",
      "Requirement already satisfied: pydantic>=2.4.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (2.9.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (1.0.1)\n",
      "Collecting pyvis>=0.3.2 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ab/4b/e37e4e5d5ee1179694917b445768bdbfb084f5a59ecd38089d3413d4c70f/pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m275.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2024.9.11 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai) (2024.11.6)\n",
      "Collecting tomli-w>=1.1.0 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c4/ac/ce90573ba446a9bbe65838ded066a805234d159b4446ae9f8ec5bbd36cbd/tomli_w-1.1.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting tomli>=2.0.2 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/de/f7/4da0ffe1892122c9ea096c57f64c2753ae5dd3ce85488802d11b0992cc6d/tomli-2.1.0-py3-none-any.whl (13 kB)\n",
      "Collecting uv>=0.4.25 (from crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/24/e0/f468ea89d85fb4c7a442b999d6fc1a5ef32e6fa3c872e471f0a1ba856069/uv-0.5.2-py3-none-macosx_11_0_arm64.whl (12.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m320.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.5 (from auth0-python>=4.7.1->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/b7/d7/56f11579e6521f058b011ad22d8a8818eb68c22e7e6237de0277f0963973/aiohttp-3.11.4-cp311-cp311-macosx_11_0_arm64.whl (454 kB)\n",
      "Collecting cryptography<44.0.0,>=43.0.1 (from auth0-python>=4.7.1->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/30/d5/c8b32c047e2e81dd172138f772e81d852c51f0f2ad2ae8a24f1122e9e9a7/cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m238.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyjwt<3.0.0,>=2.8.0 (from auth0-python>=4.7.1->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/6f/1d/ef9b066e7ef60494c94173dc9f0b9adf5d9ec5f888109f5c669f53d4144b/PyJWT-2.10.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from auth0-python>=4.7.1->crewai) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=2.0.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from auth0-python>=4.7.1->crewai) (2.2.3)\n",
      "Collecting build>=1.0.3 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/84/c2/80633736cd183ee4a62107413def345f7e6e3c01563dbca1417363cf957e/build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/0d/19/aa6f2139f1ff7ad23a690ebf2a511b2594ab359915d7979f76f3213e46c4/chroma_hnswlib-0.7.6-cp311-cp311-macosx_11_0_arm64.whl (185 kB)\n",
      "Collecting fastapi>=0.95.2 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/54/c4/148d5046a96c428464557264877ae5a9338a83bbe0df045088749ec89820/fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/eb/14/78bd0e95dd2444b6caacbca2b730671d4295ccb628ef58b81bee903629df/uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (2.1.3)\n",
      "Collecting posthog>=2.4.0 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/71/23/1e7b25c4b8181da03431c57f234f6b8c883fe9b68128110e217e870d1250/posthog-3.7.2-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/43/d3/3b7e17266a4d360af0a93965021ef8192d833233658a9d59501fbaf1341a/onnxruntime-1.20.0-cp311-cp311-macosx_13_0_universal2.whl (31.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m224.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/dd/7e/6af5a7de87988cfc951db86f7fd0ecaabc20bc112fd9cfe06b8a01f11400/opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d3/a9/ef2678c16caf5dc2f84628bfafdbc90139e3c78d9017afd07fbd51b1eeef/opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (0.20.3)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c7/2c/94ed7b91db81d61d7096ac8f2d325ec562fc75e35f3baea8749c85b28784/PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (4.67.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7b/59/34dae935bbb42f3e8929c90e9dfff49090cef412cf767cf4f14cd01ded18/grpcio-1.68.0-cp311-cp311-macosx_10_9_universal2.whl (11.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m338.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting bcrypt>=4.0.1 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/96/86/8c6a84daed4dd878fbab094400c9174c43d9b838ace077a2f8ee8bc3ae12/bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl (472 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/22/69/e90a0b4d0c16e095901679216c8ecdc728110c7c54e7b5f43a623bc4c789/typer-0.13.1-py3-none-any.whl (44 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/fb/a8/17f5e28cecdbd6d48127c22abdb794740803491f422a11905c4569d8e139/kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m302.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/13/f0/2d3daca276a4673f82af859e4b0b18befd4e6e54f1017ba48ea9735b2f1b/mmh3-5.0.1-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1e/25/c869a1fbd481dcb02c70032fd6a7243de7582bc48c7cae03d6f0985a11c0/orjson-3.10.11-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (266 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from chromadb>=0.4.24->crewai) (0.27.2)\n",
      "Collecting rich>=10.11.0 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.12.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai-tools>=0.14.0->crewai) (4.12.3)\n",
      "Requirement already satisfied: docker>=7.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from crewai-tools>=0.14.0->crewai) (7.1.0)\n",
      "Collecting docx2txt>=0.8 (from crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7d/7d/60ee3f2b16d9bfdfa72e8599470a2c1a5b759cb113c6fe1006be28359327/docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting embedchain>=0.1.114 (from crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/52/82/3d0355c22bc68cfbb8fbcf670da4c01b31bd7eb516974a08cf7533e89887/embedchain-0.1.125-py3-none-any.whl (211 kB)\n",
      "Collecting lancedb>=0.5.4 (from crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/b9/25/25f8494e164ec83212002018053271865ae06ca4cc5976e3987515fdeb2a/lancedb-0.16.0-cp38-abi3-macosx_11_0_arm64.whl (22.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.6/22.6 MB\u001b[0m \u001b[31m328.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting pyright>=1.1.350 (from crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1b/26/c288cabf8cfc5a27e1aa9e5029b7682c0f920b8074f45d22bf844314d66a/pyright-1.1.389-py3-none-any.whl (18 kB)\n",
      "Collecting pytest>=8.0.0 (from crewai-tools>=0.14.0->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/6b/77/7440a06a8ead44c7757a64362dd22df5760f9b12dc5f11b6188cd2fc27a0/pytest-8.3.3-py3-none-any.whl (342 kB)\n",
      "Collecting pytube>=15.0.0 (from crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/51/64/bcf8632ed2b7a36bbf84a0544885ffa1d0b4bcf25cc0903dba66ec5fdad9/pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "Collecting selenium>=4.18.1 (from crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/91/08/10cff8463b3510b78f9e3dcef6b37c542b06d71ed1240a8940ba0c75d3bc/selenium-4.26.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m271.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting docstring-parser<0.17,>=0.16 (from instructor>=1.3.3->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d5/7c/e9fcff7623954d86bdc17782036cbf715ecab1bec4847c008557affe1ca8/docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from instructor>=1.3.3->crewai) (3.1.4)\n",
      "Collecting jiter<0.7,>=0.6.1 (from instructor>=1.3.3->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/91/35/85ef9eaef7dec14f28dd9b8a2116c07075bb2731a405b650a55fda4c74d7/jiter-0.6.1-cp311-cp311-macosx_11_0_arm64.whl (302 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from instructor>=1.3.3->crewai) (2.23.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from langchain>=0.2.16->crewai) (2.0.36)\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain>=0.2.16->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a1/25/5bd49cda589e98908e40591214c98cac52f7eb37230bbe493dbd883b9a89/langchain_core-0.3.19-py3-none-any.whl (409 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain>=0.2.16->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ee/c6/5ba25c8bad647e92a92b3066177ab10d78efbd16c0b9919948cdcd18b027/langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain>=0.2.16->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/f8/53/0a22394aa520176b1981e9b7f02090425731b575e9ae28f86a7f5341208c/langsmith-0.1.143-py3-none-any.whl (306 kB)\n",
      "Collecting numpy>=1.22.5 (from chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1a/2e/151484f49fd03944c4a3ad9c418ed193cfd02724e138ac8a9505d056c582/numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m307.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=6.8.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from litellm>=1.44.22->crewai) (8.5.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from litellm>=1.44.22->crewai) (4.23.0)\n",
      "Collecting tiktoken>=0.7.0 (from litellm>=1.44.22->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/8c/f8/f0101d98d661b34534769c3818f5af631e59c36ac6d07268fbfc89e539ce/tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl (982 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from openai>=1.13.3->crewai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from openai>=1.13.3->crewai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-api>=1.22.0->crewai) (1.2.15)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a0/0f/c0713fb2b3d28af4b2fded3291df1c4d4f79a00d15c2374a9e010870016c/googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/2a/4d/769f3b1b1c6af5e603da50349ba31af757897540a75d666de22d39461055/opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1d/12/646f48d6d698a6df0437a22b591387440dc4888c8752d1a1300f730da710/opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-proto==1.28.2->opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai) (5.28.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-sdk>=1.22.0->crewai) (0.49b2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyvis>=0.3.2->crewai) (8.29.0)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis>=0.3.2->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a1/64/815460f86d94c9e1431800a75061719824c6fef14d88a6117eba3126cd5b/jsonpickle-4.0.0-py3-none-any.whl (46 kB)\n",
      "Collecting networkx>=1.11 (from pyvis>=0.3.2->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m118.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/f7/d8/120cd0fe3e8530df0539e71ba9683eade12cae103dd7543e50d15f737917/aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/2c/31/ab01375682f14f7613a1ade30149f684c84f9b8823a4391ed950c8285656/frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl (52 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/70/0f/6dc70ddf5d442702ed74f298d69977f904960b82368532c88e854b79f72b/multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c0/1d/c700d16d1d6903aeab28372fe9999762f074b80b96a0ccc953175b858743/propcache-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/19/71/f7241b745f0f9b3120de1b2a63c08b5bae5ec6d42890026a58545a068c4e/yarl-1.17.2-cp311-cp311-macosx_11_0_arm64.whl (91 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.13.3->crewai) (3.10)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from beautifulsoup4>=4.12.3->crewai-tools>=0.14.0->crewai) (2.6)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from build>=1.0.3->chromadb>=0.4.24->crewai) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/bd/24/12818598c362d7f300f18e74db45963dbcb85150324092410c8b49405e42/pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->crewai) (1.16.0)\n",
      "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (1.14.0)\n",
      "Collecting cohere<6.0,>=5.3 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/53/5c/909862a2eb2a0eaf3bc2024058207e342286e015d60ff03fe38f3efdde6d/cohere-5.11.4-py3-none-any.whl (249 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.26.1 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7d/c7/276023cb0f2b2e9bea17df73894113b3ce25b5742198e1a3e2175ade5b90/google_cloud_aiplatform-1.72.0-py2.py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m262.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/49/87/8dde0a3757bc207805f751b47878888b09db4a464ae48a55f386f091b488/gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
      "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/64/5e/bbfb1b33703a973e7eef6582b523ae932e7e64c9b84ac7eecaa8af71475e/langchain_cohere-0.3.1-py3-none-any.whl (43 kB)\n",
      "Collecting langchain-community<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/cc/19/f8af1cdefe326730ae02bd653f7382693153baf0bac7a69537d7811cad5f/langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m292.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/56/f3/b8767fd4f33fb811139292943083f9bef0f8cc4a43edeff2c19b501df75f/langchain_openai-0.2.9-py3-none-any.whl (50 kB)\n",
      "Collecting mem0ai<0.2.0,>=0.1.29 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/65/9b/755be84f669415b3b513cfd935e768c4c84ac5c1ab6ff6ac2dab990a261a/mem0ai-0.1.29-py3-none-any.whl (79 kB)\n",
      "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/04/fc/6f52588ac1cb4400a7804ef88d0d4e00cfe57a7ac6793ec3b00de5a8758b/pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ad/1b/81855a88c6db2b114d5b2e9f96339190d5ee4d1b981d217fa32127bb00e0/schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tiktoken>=0.7.0 (from litellm>=1.44.22->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/30/ef/e07dbfcb2f85c84abaa1b035a9279575a8da0236305491dc22ae099327f7/tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl (907 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m907.0/907.0 kB\u001b[0m \u001b[31m483.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/96/00/2b325970b3060c7cecebab6d295afe763365822b1306a12eeab198f74323/starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.4.24->crewai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.4.24->crewai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.24->crewai) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm>=1.44.22->crewai) (3.21.0)\n",
      "Requirement already satisfied: decorator in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.3.3->crewai) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (0.21.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (2.36.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/4c/a3/ac312faeceffd2d8f86bc6dcb5c401188ba5a01bc88e69bed97578a0dfcd/durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Collecting deprecation (from lancedb>=0.5.4->crewai-tools>=0.14.0->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: nest-asyncio~=1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from lancedb>=0.5.4->crewai-tools>=0.14.0->crewai) (1.6.0)\n",
      "Collecting pylance==0.19.2 (from lancedb>=0.5.4->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/8b/f5/6c2f04869747cb382f0f561362d354e132c2adb9b299aa28f28bb1847209/pylance-0.19.2-cp39-abi3-macosx_11_0_arm64.whl (26.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m303.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=12 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pylance==0.19.2->lancedb>=0.5.4->crewai-tools>=0.14.0->crewai) (18.0.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.15->langchain>=0.2.16->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain>=0.2.16->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/99/ff/c87e0622b1dadea79d2fb0b25ade9ed98954c9033722eb707053d310d4f3/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m266.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3f/82/06a56e786de3ea0ef4703ed313d9d8395fb4bc9ae740cc71415178ae8bff/opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ef/e3/ad23372525653b0221212d5e2a71bd97aae64cc35f90cbf0c70de57dfa4e/opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
      "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/19/22/9128f10d1c2868ee42df7e10937d00f154a69bee87c416ca9b20a6af6c54/opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/39/e3/893e8757be2612e6c266d9bb58ad2e3651524b5b40cf56761e985a28b13e/asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d2/1d/1b658dbd2b9fa9c4c9f32accbfc0205d532c8c6194dc0f2a4c0428e7128a/nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Collecting iniconfig (from pytest>=8.0.0->crewai-tools>=0.14.0->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ef/a6/62565a6e1cf69e10f5727360368e451d4b7f58beeac6173dc9db836a5b46/iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest>=8.0.0->crewai-tools>=0.14.0->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/88/5f/e351af9a41f866ac3f1fac4ca0613908d9a41741cfcf2228f4ad853b697d/pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->auth0-python>=4.7.1->crewai) (3.4.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb>=0.4.24->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting trio~=0.17 (from selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/3c/83/ec3196c360afffbc5b342ead48d1eb7393dd74fa70bca75d33905a86f211/trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb>=0.4.24->crewai) (0.26.2)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a6/17/3e0d3e9b901c732987a45f4f94d4e2c62b89a041d93db89eafb262afd8d5/httptools-0.6.4-cp311-cp311-macosx_11_0_arm64.whl (103 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/57/a7/4cf0334105c1160dd6819f3297f8700fda7fc30ab4f61fbf3e725acbc7cc/uvloop-0.21.0-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m395.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/bc/67/d8c9d256791fe312fea118a8a051411337c948101a24586e2df237507976/watchfiles-0.24.0-cp311-cp311-macosx_11_0_arm64.whl (367 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ff/b8/7185212adad274c2b42b6a24e1ee6b916b7809ed611cbebc33b227e5c215/websockets-14.1-cp311-cp311-macosx_11_0_arm64.whl (159 kB)\n",
      "Requirement already satisfied: Mako in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (1.3.6)\n",
      "Requirement already satisfied: pycparser in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/89/61/b8b18aebc01e5d5a77042f6d555fe091d3279242edd5639252c9fcb9a3b7/fastavro-1.9.7-cp311-cp311-macosx_10_9_universal2.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m369.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/00/2f/804f58f0b856ab3bf21617cccf5b39206e6c4c94c2cd227bde125ea6105f/parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d7/01/485b3026ff90e5190b5e24f1711522e06c79f4a56c8f4b95848ac072e20f/types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (4.9)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/17/a4/c26886d57d90032c5f74c2e80aefdc38ec58551fc46bd4ce79fb2c9389fa/google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/dd/25/0b7cc838ae3d76d46539020ec39fc92bfc9acc29367e58fe912702c2a79e/proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/fc/da/95db7bd4f0bd1644378ac1702c565c0210b004754d925a74f526a710c087/google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/f5/40/4b11a4a8839de8ce802a3ccd60b34e70ce10d13d434a560534ba98f0ea3f/google_cloud_bigquery-3.27.0-py2.py3-none-any.whl (240 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/dd/cf/68ba6b60d1363a7e3193f457badc3cb4003552b11fa37152be9db2a3d0ac/google_cloud_resource_manager-1.13.1-py2.py3-none-any.whl (358 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/37/63/e182e43081fffa0a2d970c480f2ef91647a6ab94098f61748c23c2a485f2/shapely-2.0.6-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m343.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.24->crewai) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.24->crewai) (2024.10.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain>=0.2.16->crewai) (3.0.0)\n",
      "Collecting langchain-experimental>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/56/fb/50a7181c318495c5481757d2606c22c6b30a4c50d75236898bb1a5437069/langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\n",
      "Requirement already satisfied: pandas>=1.4.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (2.2.3)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain>=0.2.16->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/1e/69/919673c5101a0c633658d58b11b454b251ca82300941fba801201434755d/SQLAlchemy-2.0.35-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m317.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/5e/f9/ff95fd7d760af42f647ea87f9b8a383d891cdb5e5dbd4613edaeb094252a/pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.24->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: pytz<2025.0,>=2024.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (2024.2)\n",
      "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/68/c0/eef4fe9dad6d41333f7dc6567fa8144ffc1837c8a0edfc2317d50715335f/qdrant_client-1.12.1-py3-none-any.whl (267 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium>=4.18.1->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/8d/59/b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9/PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/ac/a7/a78ff54e67ef92a3d12126b98eb98ab8abab3de4a8c46d240c87e514d6bb/marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Using cached https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/40/ba/dc535631a9dffa421b327ebfc961911af54c396aa5324efd122a94f72464/grpcio_status-1.68.0-py3-none-any.whl (14 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/5e/0f/2e2061e3fbcb9d535d5da3f58cc8de4947df1786fe6a1355960feb05a681/google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/82/35/b8d3baf8c46695858cb9d8835a53baa1eeb9906ddaf2f728a5f5b640fd1e/google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/a8/7d/da3875b7728bc700eeb28b513754ce237c04ac7cbf8559d76b0464ee01cb/grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/7d/14/ab47972ac79b6e7b03c8be3a7ef44b530a60e69555668dbbf08fc5692a98/google_crc32c-1.6.0-cp311-cp311-macosx_12_0_arm64.whl (30 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (2024.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (0.6.1)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/c4/a2/78a4c5c3e3ae3bd209519da5a4fc6669a5f3d06423d466028d01e7fbbbce/grpcio_tools-1.68.0-cp311-cp311-macosx_10_9_universal2.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m264.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/9b/fb/a70a4214956182e0d7a9099ab17d50bfcba1056188e9b14f35b9e2b62a0d/portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai) (75.5.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/2a/e5/db6d438da759efbb488c4f3fbdab7764492ff3c3f953132efa6b9f0e9e53/h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d7/de/85a784bcc4a3779d1753a7ec2dee5de90e18c7bcf402e71b51fcf150b129/hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools>=0.14.0->crewai)\n",
      "  Downloading https://artifacts.procoretech.com/artifactory/api/pypi/python/packages/packages/d5/34/e8b383f35b77c402d28563d2b8f83159319b509bc5f760b15d60b0abf165/hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Building wheels for collected packages: docx2txt, pypika\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=26746b7841d8f93ebcc82a30ff0b0c915d7f5bbd371225b4b55240f87cddb01c\n",
      "  Stored in directory: /Users/ganga/Library/Caches/pip/wheels/c4/03/59/df04cbcd5d012f3ecfb3670eb6ad72a5d29a8e651dabbd38ee\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=cfeed010bf0ccccbdce8bf0f9cf921c15ab53e362d510992888e0b5c36393eea\n",
      "  Stored in directory: /Users/ganga/Library/Caches/pip/wheels/25/f2/c2/d448de95a3b62d6a57978ebc61d80c7b4ae79ca0a2bcfdcb5b\n",
      "Successfully built docx2txt pypika\n",
      "Installing collected packages: sortedcontainers, schema, pypika, mpmath, monotonic, flatbuffers, durationpy, docx2txt, appdirs, wsproto, websockets, uvloop, uvicorn, uv, types-requests, tomli-w, tomli, tabulate, sympy, SQLAlchemy, shellingham, pytube, pysocks, pysbd, pyproject_hooks, pypdf, pyjwt, proto-plus, propcache, portalocker, pluggy, parameterized, outcome, orjson, opentelemetry-util-http, opentelemetry-proto, oauthlib, numpy, nodeenv, networkx, mypy-extensions, multidict, mmh3, mdurl, marshmallow, jsonref, jsonpickle, jsonpatch, json-repair, jiter, iniconfig, importlib-resources, hyperframe, humanfriendly, httpx-sse, httptools, hpack, grpcio, googleapis-common-protos, google-crc32c, frozenlist, fastavro, docstring-parser, deprecation, bcrypt, backoff, asgiref, aiohappyeyeballs, yarl, watchfiles, typing-inspect, trio, tiktoken, starlette, shapely, requests-toolbelt, requests-oauthlib, pytest, pyright, pylance, posthog, opentelemetry-exporter-otlp-proto-common, markdown-it-py, h2, grpcio-tools, grpcio-status, gptcache, google-resumable-media, cryptography, coloredlogs, chroma-hnswlib, build, aiosignal, trio-websocket, rich, pydantic-settings, openai, onnxruntime, langsmith, lancedb, kubernetes, grpc-google-iam-v1, google-api-core, fastapi, dataclasses-json, aiohttp, typer, selenium, qdrant-client, pyvis, opentelemetry-instrumentation, litellm, langchain-core, google-cloud-core, cohere, auth0-python, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mem0ai, langchain-text-splitters, langchain-openai, instructor, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, opentelemetry-instrumentation-fastapi, langchain, google-cloud-aiplatform, langchain-community, chromadb, langchain-experimental, langchain-cohere, embedchain, crewai-tools, crewai\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.36\n",
      "    Uninstalling SQLAlchemy-2.0.36:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.36\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.3 aiohttp-3.11.4 aiosignal-1.3.1 appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.7.2 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.20 cohere-5.11.4 coloredlogs-15.0.1 crewai-0.80.0 crewai-tools-0.14.0 cryptography-43.0.3 dataclasses-json-0.6.7 deprecation-2.1.0 docstring-parser-0.16 docx2txt-0.8 durationpy-0.9 embedchain-0.1.125 fastapi-0.115.5 fastavro-1.9.7 flatbuffers-24.3.25 frozenlist-1.5.0 google-api-core-2.23.0 google-cloud-aiplatform-1.72.0 google-cloud-bigquery-3.27.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.13.1 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.66.0 gptcache-0.1.44 grpc-google-iam-v1-0.13.1 grpcio-1.68.0 grpcio-status-1.68.0 grpcio-tools-1.68.0 h2-4.1.0 hpack-4.0.0 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 hyperframe-6.0.1 importlib-resources-6.4.5 iniconfig-2.0.0 instructor-1.6.4 jiter-0.6.1 json-repair-0.30.2 jsonpatch-1.33 jsonpickle-4.0.0 jsonref-1.1.0 kubernetes-31.0.0 lancedb-0.16.0 langchain-0.3.7 langchain-cohere-0.3.1 langchain-community-0.3.7 langchain-core-0.3.19 langchain-experimental-0.3.3 langchain-openai-0.2.9 langchain-text-splitters-0.3.2 langsmith-0.1.143 litellm-1.52.10 markdown-it-py-3.0.0 marshmallow-3.23.1 mdurl-0.1.2 mem0ai-0.1.29 mmh3-5.0.1 monotonic-1.6 mpmath-1.3.0 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 nodeenv-1.9.1 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.20.0 openai-1.54.5 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-exporter-otlp-proto-http-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-util-http-0.49b2 orjson-3.10.11 outcome-1.3.0.post0 parameterized-0.9.0 pluggy-1.5.0 portalocker-2.10.1 posthog-3.7.2 propcache-0.2.0 proto-plus-1.25.0 pydantic-settings-2.6.1 pyjwt-2.10.0 pylance-0.19.2 pypdf-5.1.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.389 pysbd-0.3.4 pysocks-1.7.1 pytest-8.3.3 pytube-15.0.0 pyvis-0.3.2 qdrant-client-1.12.1 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-13.9.4 schema-0.7.7 selenium-4.26.1 shapely-2.0.6 shellingham-1.5.4 sortedcontainers-2.4.0 starlette-0.41.3 sympy-1.13.3 tabulate-0.9.0 tiktoken-0.7.0 tomli-2.1.0 tomli-w-1.1.0 trio-0.27.0 trio-websocket-0.11.1 typer-0.13.1 types-requests-2.32.0.20241016 typing-inspect-0.9.0 uv-0.5.2 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0 websockets-14.1 wsproto-1.2.0 yarl-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "source code not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproject\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrewBase, agent, crew, task\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrewai_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SerperDevTool\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;129;43m@CrewBase\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mLatestAiDevelopmentCrew\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"LatestAiDevelopment crew\"\"\"\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43m@agent\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mresearcher\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAgent\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/crewai/project/crew_base.py:14\u001b[0m, in \u001b[0;36mCrewBase\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCrewBase\u001b[39m(\u001b[38;5;28mcls\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m---> 14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mWrappedClass\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_crew_class\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Get the directory of the class being decorated\u001b[39;49;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/crewai/project/crew_base.py:18\u001b[0m, in \u001b[0;36mCrewBase.<locals>.WrappedClass\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m is_crew_class: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Get the directory of the class being decorated\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m base_directory \u001b[38;5;241m=\u001b[39m Path(\u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m     20\u001b[0m original_agents_config_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magents_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig/agents.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m original_tasks_config_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasks_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig/tasks.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/inspect.py:904\u001b[0m, in \u001b[0;36mgetfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 904\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource code not available\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is a built-in class\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mobject\u001b[39m))\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismethod(\u001b[38;5;28mobject\u001b[39m):\n",
      "\u001b[0;31mOSError\u001b[0m: source code not available"
     ]
    }
   ],
   "source": [
    "# src/latest_ai_development/crew.py\n",
    "from crewai import Agent, Crew, Process, Task\n",
    "from crewai.project import CrewBase, agent, crew, task\n",
    "from crewai_tools import SerperDevTool\n",
    "\n",
    "@CrewBase\n",
    "class LatestAiDevelopmentCrew():\n",
    "    \"\"\"LatestAiDevelopment crew\"\"\"\n",
    "\n",
    "    @agent\n",
    "    def researcher(self) -> Agent:\n",
    "        return Agent(\n",
    "        config=self.agents_config['researcher'],\n",
    "        verbose=True,\n",
    "        tools=[SerperDevTool()]\n",
    "        )\n",
    "\n",
    "    @agent\n",
    "    def reporting_analyst(self) -> Agent:\n",
    "        return Agent(\n",
    "        config=self.agents_config['reporting_analyst'],\n",
    "        verbose=True\n",
    "        )\n",
    "\n",
    "    @task\n",
    "    def research_task(self) -> Task:\n",
    "        return Task(\n",
    "        config=self.tasks_config['research_task'],\n",
    "        )\n",
    "\n",
    "    @task\n",
    "    def reporting_task(self) -> Task:\n",
    "        return Task(\n",
    "        config=self.tasks_config['reporting_task'],\n",
    "        output_file='output/report.md' # This is the file that will be contain the final report.\n",
    "        )\n",
    "\n",
    "    @crew\n",
    "    def crew(self) -> Crew:\n",
    "        \"\"\"Creates the LatestAiDevelopment crew\"\"\"\n",
    "        return Crew(\n",
    "        agents=self.agents, # Automatically created by the @agent decorator\n",
    "        tasks=self.tasks, # Automatically created by the @task decorator\n",
    "        process=Process.sequential,\n",
    "        verbose=True,\n",
    "        ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# src/latest_ai_development/main.py\n",
    "import sys\n",
    "from latest_ai_development.crew import LatestAiDevelopmentCrew\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Run the crew.\n",
    "    \"\"\"\n",
    "    inputs = {\n",
    "      'topic': 'AI Agents'\n",
    "    }\n",
    "    LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}



================================================================================
# tasks.yaml
================================================================================

# src/latest_ai_development/config/tasks.yaml
research_task:
  description: >
    Conduct a thorough research about {topic}
    Make sure you find any interesting and relevant information given
    the current year is 2024.
  expected_output: >
    A list with 10 bullet points of the most relevant information about {topic}
  agent: researcher

reporting_task:
  description: >
    Review the context you got and expand each topic into a full section for a report.
    Make sure the report is detailed and contains any and all relevant information.
  expected_output: >
    A fully fledge reports with the mains topics, each with a full section of information.
    Formatted as markdown without '```'
  agent: reporting_analyst
  output_file: report.md



================================================================================
# mlruns/336741345537322461/meta.yaml
================================================================================

artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461
creation_time: 1732004080697
experiment_id: '336741345537322461'
last_update_time: 1732004080697
lifecycle_stage: active
name: youtube-summarizer



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts
end_time: 1732004251458
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 907f1ecd64ca4ec2919e1657da05494b
run_name: abrasive-cod-859
run_uuid: 907f1ecd64ca4ec2919e1657da05494b
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004249085
status: 3
tags: []
user_id: ganga



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
name: mlflow-env



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/03_MLFlow_monitoring.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for YouTube Summarizer with MLflow\n",
    "\n",
    "This notebook evaluates the YouTube summarizer model using MLflow to track metrics and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_model_from_mlflow(run_id: str):\n",
    "    \"\"\"Load the YouTube summarizer model from MLflow\"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/youtube_summarizer\"\n",
    "    return mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Replace with your run_id from the training notebook\n",
    "RUN_ID = \"your_run_id_here\"\n",
    "model = load_model_from_mlflow(RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def prepare_test_data() -> List[Dict[str, str]]:\n",
    "    \"\"\"Prepare test data with YouTube videos and reference summaries\"\"\"\n",
    "    # Replace with your actual test data\n",
    "    return [\n",
    "        {\n",
    "            \"video_url\": \"https://www.youtube.com/watch?v=example1\",\n",
    "            \"reference_summary\": \"Reference summary for video 1\"\n",
    "        },\n",
    "        {\n",
    "            \"video_url\": \"https://www.youtube.com/watch?v=example2\",\n",
    "            \"reference_summary\": \"Reference summary for video 2\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_metrics(predicted_summary: str, reference_summary: str) -> Dict[str, float]:\n",
    "    \"\"\"Calculate various evaluation metrics\"\"\"\n",
    "    # ROUGE scores\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = scorer.score(reference_summary, predicted_summary)\n",
    "    \n",
    "    # BLEU score\n",
    "    reference = [reference_summary.split()]\n",
    "    candidate = predicted_summary.split()\n",
    "    bleu = sentence_bleu(reference, candidate)\n",
    "    \n",
    "    # Summary length metrics\n",
    "    pred_length = len(predicted_summary.split())\n",
    "    ref_length = len(reference_summary.split())\n",
    "    length_ratio = pred_length / ref_length if ref_length > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'rouge1_precision': rouge_scores['rouge1'].precision,\n",
    "        'rouge1_recall': rouge_scores['rouge1'].recall,\n",
    "        'rouge1_f1': rouge_scores['rouge1'].fmeasure,\n",
    "        'rouge2_f1': rouge_scores['rouge2'].fmeasure,\n",
    "        'rougeL_f1': rouge_scores['rougeL'].fmeasure,\n",
    "        'bleu_score': bleu,\n",
    "        'summary_length_ratio': length_ratio,\n",
    "        'predicted_length': pred_length,\n",
    "        'reference_length': ref_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_model_with_mlflow(model, test_data: List[Dict[str, str]]):\n",
    "    \"\"\"Evaluate model and log results to MLflow\"\"\"\n",
    "    mlflow.set_experiment(\"youtube-summarizer-evaluation\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"model_evaluation\") as run:\n",
    "        all_metrics = []\n",
    "        \n",
    "        # Log model parameters\n",
    "        model_params = model.get_config() if hasattr(model, 'get_config') else {}\n",
    "        mlflow.log_params(model_params)\n",
    "        \n",
    "        # Evaluate each test example\n",
    "        for i, example in enumerate(test_data):\n",
    "            # Generate summary\n",
    "            predicted_summary = model(example['video_url'])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = calculate_metrics(predicted_summary, example['reference_summary'])\n",
    "            all_metrics.append(metrics)\n",
    "            \n",
    "            # Log metrics for each example\n",
    "            for metric_name, value in metrics.items():\n",
    "                mlflow.log_metric(f\"example_{i}_{metric_name}\", value)\n",
    "            \n",
    "            # Log summaries as artifacts\n",
    "            example_dir = f\"example_{i}\"\n",
    "            os.makedirs(example_dir, exist_ok=True)\n",
    "            \n",
    "            with open(f\"{example_dir}/predicted_summary.txt\", \"w\") as f:\n",
    "                f.write(predicted_summary)\n",
    "            with open(f\"{example_dir}/reference_summary.txt\", \"w\") as f:\n",
    "                f.write(example['reference_summary'])\n",
    "            \n",
    "            mlflow.log_artifacts(example_dir)\n",
    "        \n",
    "        # Calculate and log average metrics\n",
    "        avg_metrics = {}\n",
    "        for metric in all_metrics[0].keys():\n",
    "            avg_value = np.mean([m[metric] for m in all_metrics])\n",
    "            avg_metrics[f\"avg_{metric}\"] = avg_value\n",
    "            mlflow.log_metric(f\"avg_{metric}\", avg_value)\n",
    "        \n",
    "        # Create and log visualizations\n",
    "        create_and_log_visualizations(all_metrics)\n",
    "        \n",
    "        return run.info.run_id, avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_and_log_visualizations(metrics_list: List[Dict[str, float]]):\n",
    "    \"\"\"Create and log visualizations to MLflow\"\"\"\n",
    "    # Convert metrics to DataFrame\n",
    "    df = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    # ROUGE scores comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    rouge_metrics = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']\n",
    "    df[rouge_metrics].mean().plot(kind='bar')\n",
    "    plt.title('Average ROUGE Scores')\n",
    "    plt.ylabel('Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('rouge_scores.png')\n",
    "    mlflow.log_artifact('rouge_scores.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Summary length analysis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['reference_length'], df['predicted_length'])\n",
    "    plt.plot([0, max(df['reference_length'])], [0, max(df['reference_length'])], '--', color='red')\n",
    "    plt.xlabel('Reference Summary Length')\n",
    "    plt.ylabel('Predicted Summary Length')\n",
    "    plt.title('Summary Length Comparison')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('length_comparison.png')\n",
    "    mlflow.log_artifact('length_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Metrics distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics_to_plot = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1', 'bleu_score']\n",
    "    df[metrics_to_plot].boxplot()\n",
    "    plt.title('Distribution of Evaluation Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_distribution.png')\n",
    "    mlflow.log_artifact('metrics_distribution.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare test data\n",
    "test_data = prepare_test_data()\n",
    "\n",
    "# Run evaluation\n",
    "run_id, avg_metrics = evaluate_model_with_mlflow(model, test_data)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(\"==================\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nMLflow run ID: {run_id}\")\n",
    "print(\"View detailed results in the MLflow UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results in MLflow UI\n",
    "\n",
    "To view the detailed results and visualizations:\n",
    "1. Start the MLflow UI by running `mlflow ui` in your terminal\n",
    "2. Open http://localhost:5000 in your browser\n",
    "3. Navigate to the experiment \"youtube-summarizer-evaluation\"\n",
    "4. Click on the run ID printed above to see detailed metrics and artifacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/__init__.py
================================================================================




================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/04_MLFlow_evaluation.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Summarizer: Model Setup and Monitoring\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Set up the YouTube summarizer model\n",
    "2. Implement monitoring using MLflow\n",
    "3. Track model performance metrics\n",
    "4. Monitor system resources and latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import time\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "import psutil\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Setup\n",
    "\n",
    "First, we'll set up our summarization model using the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def initialize_model():\n",
    "    \"\"\"Initialize the summarization model\"\"\"\n",
    "    model_name = \"facebook/bart-large-cnn\"  # You can change this to other models\n",
    "    summarizer = pipeline(\"summarization\", model=model_name)\n",
    "    return summarizer\n",
    "\n",
    "# Initialize the model\n",
    "summarizer = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLflow Setup\n",
    "\n",
    "Set up MLflow to track experiments and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"youtube_summarizer_monitoring\")\n",
    "\n",
    "def log_metrics(metrics_dict):\n",
    "    \"\"\"Log metrics to MLflow\"\"\"\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_metrics(metrics_dict)\n",
    "        mlflow.log_param(\"model_name\", \"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Monitoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        self.metrics_history = []\n",
    "    \n",
    "    def measure_latency(self, func, *args, **kwargs):\n",
    "        \"\"\"Measure execution time of a function\"\"\"\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        return result, end_time - start_time\n",
    "    \n",
    "    def measure_resource_usage(self):\n",
    "        \"\"\"Measure CPU and memory usage\"\"\"\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_info = psutil.Process().memory_info()\n",
    "        return {\n",
    "            'cpu_percent': cpu_percent,\n",
    "            'memory_mb': memory_info.rss / 1024 / 1024\n",
    "        }\n",
    "    \n",
    "    def calculate_rouge_scores(self, prediction, reference):\n",
    "        \"\"\"Calculate ROUGE scores\"\"\"\n",
    "        scores = self.scorer.score(prediction, reference)\n",
    "        return {\n",
    "            'rouge1_f1': scores['rouge1'].fmeasure,\n",
    "            'rouge2_f1': scores['rouge2'].fmeasure,\n",
    "            'rougeL_f1': scores['rougeL'].fmeasure\n",
    "        }\n",
    "    \n",
    "    def log_performance(self, latency, rouge_scores, resource_usage):\n",
    "        \"\"\"Log all performance metrics\"\"\"\n",
    "        metrics = {\n",
    "            'latency': latency,\n",
    "            **rouge_scores,\n",
    "            **resource_usage\n",
    "        }\n",
    "        self.metrics_history.append(metrics)\n",
    "        log_metrics(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_metrics_over_time(metrics_history):\n",
    "    \"\"\"Create interactive plots for metrics over time\"\"\"\n",
    "    df = pd.DataFrame(metrics_history)\n",
    "    \n",
    "    # Latency plot\n",
    "    fig_latency = px.line(df, y='latency', title='Inference Latency Over Time')\n",
    "    fig_latency.show()\n",
    "    \n",
    "    # Resource usage plot\n",
    "    fig_resources = go.Figure()\n",
    "    fig_resources.add_trace(go.Scatter(y=df['cpu_percent'], name='CPU %'))\n",
    "    fig_resources.add_trace(go.Scatter(y=df['memory_mb'], name='Memory (MB)'))\n",
    "    fig_resources.update_layout(title='Resource Usage Over Time')\n",
    "    fig_resources.show()\n",
    "    \n",
    "    # ROUGE scores plot\n",
    "    fig_rouge = go.Figure()\n",
    "    for metric in ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']:\n",
    "        fig_rouge.add_trace(go.Scatter(y=df[metric], name=metric))\n",
    "    fig_rouge.update_layout(title='ROUGE Scores Over Time')\n",
    "    fig_rouge.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the performance monitor\n",
    "monitor = PerformanceMonitor()\n",
    "\n",
    "def process_video(video_id, reference_summary=None):\n",
    "    \"\"\"Process a video with monitoring\"\"\"\n",
    "    # Get transcript\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    text = ' '.join([t['text'] for t in transcript])\n",
    "    \n",
    "    # Generate summary with latency measurement\n",
    "    summary, latency = monitor.measure_latency(\n",
    "        lambda: summarizer(text, max_length=130, min_length=30)[0]['summary_text']\n",
    "    )\n",
    "    \n",
    "    # Measure resource usage\n",
    "    resource_usage = monitor.measure_resource_usage()\n",
    "    \n",
    "    # Calculate ROUGE scores if reference summary is provided\n",
    "    rouge_scores = monitor.calculate_rouge_scores(summary, reference_summary) if reference_summary else {}\n",
    "    \n",
    "    # Log all metrics\n",
    "    metrics = monitor.log_performance(latency, rouge_scores, resource_usage)\n",
    "    \n",
    "    return summary, metrics\n",
    "\n",
    "# Example usage\n",
    "# video_id = \"YOUR_VIDEO_ID\"\n",
    "# summary, metrics = process_video(video_id)\n",
    "# plot_metrics_over_time(monitor.metrics_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/README.md
================================================================================

# YouTube Video Summarizer

This project provides a Jupyter notebook that can summarize YouTube videos using their transcripts and Groq's AI model. The summarizer extracts the video's transcription and generates a comprehensive summary focusing on main points, key insights, and important conclusions.

## Features

- Extract YouTube video transcripts
- Process transcripts using Groq's Mixtral-8x7b model
- Generate structured summaries with main topics, key points, and conclusions
- Support for both standard YouTube URLs and shortened (youtu.be) links

## Prerequisites

- Python 3.8+
- Groq API key
- Internet connection for accessing YouTube and Groq API

## Installation

1. Clone this repository
2. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```
3. Create a `.env` file in the project directory and add your Groq API key:
   ```
   GROQ_API_KEY=your_api_key_here
   ```

## Usage

1. Start Jupyter Notebook:
   ```bash
   jupyter notebook
   ```
2. Open `youtube_summarizer.ipynb`
3. Run all cells in the notebook
4. Replace the example YouTube URL with your desired video URL
5. Run the cell to get your summary

## Example

```python
youtube_url = "https://www.youtube.com/watch?v=your_video_id"
summary = summarize_youtube_video(youtube_url)
print(summary)
```

## Note

- The video must have available transcripts (either auto-generated or manually created)
- The quality of the summary depends on the quality of the transcript and the video content
- Make sure you have sufficient API credits in your Groq account

## License

This project is open-source and available under the MIT License.



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/01_PoC.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer using Groq\n",
    "\n",
    "This notebook demonstrates how to create a YouTube video summarizer that:\n",
    "1. Takes a YouTube URL as input\n",
    "2. Extracts the video's transcription\n",
    "3. Uses Groq to generate a concise summary\n",
    "\n",
    "## Setup and Requirements\n",
    "First, we'll install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api groq python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(url):\n",
    "    \"\"\"Extract YouTube video ID from URL\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.hostname == 'youtu.be':\n",
    "        return parsed_url.path[1:]\n",
    "    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "        if parsed_url.path == '/watch':\n",
    "            return parse_qs(parsed_url.query)['v'][0]\n",
    "    return None\n",
    "\n",
    "def get_transcript(video_id):\n",
    "    \"\"\"Get transcript for a YouTube video\"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\n",
    "        return ' '.join([t['text'] for t in transcript_list])\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting transcript: {e}\")\n",
    "        return None\n",
    "\n",
    "def summarize_text(text, language=\"spanish\"):\n",
    "    \"\"\"Summarize text using Groq\"\"\"\n",
    "    prompt = f\"\"\"Please provide a comprehensive summary of the following video transcript in {language}. \n",
    "    Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "    {text}\n",
    "\n",
    "    Please structure the summary with:\n",
    "    1. Main Topic/Theme\n",
    "    2. Key Points\n",
    "    3. Important Details\n",
    "    4. Conclusions\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama-3.2-90b-vision-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in summarization: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function to Summarize YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_youtube_video(url, language=\"spanish\"):\n",
    "    \"\"\"Main function to summarize a YouTube video\"\"\"\n",
    "    # Extract video ID\n",
    "    video_id = extract_video_id(url)\n",
    "    if not video_id:\n",
    "        return \"Invalid YouTube URL\"\n",
    "    \n",
    "    # Get transcript\n",
    "    transcript = get_transcript(video_id)\n",
    "    if not transcript:\n",
    "        return \"Could not retrieve transcript\"\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = summarize_text(transcript, language)\n",
    "    if not summary:\n",
    "        return \"Could not generate summary\"\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "To use this summarizer, you'll need to:\n",
    "1. Create a `.env` file in the same directory as this notebook\n",
    "2. Add your Groq API key to the `.env` file: `GROQ_API_KEY=your_api_key_here`\n",
    "\n",
    "Then you can use the summarizer as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Resumen del video transcript**\n",
      "\n",
      "**1. Tema principal/Tema**: La venta de acciones de EPM en UNE, una empresa de telecomunicaciones, y su impacto en la industria y la economía local.\n",
      "\n",
      "**2. Puntos clave**:\n",
      "\n",
      "* EPM busca vender sus acciones en UNE debido a la intensidad de capital y la rápida evolución tecnológica en la industria de las telecomunicaciones.\n",
      "* La venta de acciones se realizará a través de un proceso de enajenación, que requiere la aprobación del Consejo de Medellín.\n",
      "* El valor de las acciones se estima en 1,6 billones de pesos, según el valor en libros y la capitalización de UNE.\n",
      "* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\n",
      "\n",
      "**3. Detalles importantes**:\n",
      "\n",
      "* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\n",
      "* EPM tiene otros negocios estratégicos, como la generación y distribución de energía, agua y gas, que requieren inversiones importantes.\n",
      "* La venta de acciones se realizará a través de un proceso de enajenación, que incluye la oferta a sectores solidarios y especiales, y luego al mercado.\n",
      "* El gobierno también está considerando la venta de sus acciones en UNE, lo que podría cambiar el panorama de la industria de las telecomunicaciones en Colombia.\n",
      "* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\n",
      "\n",
      "**4. Conclusión**:\n",
      "\n",
      "* La venta de acciones de EPM en UNE es un proceso complejo que requiere la aprobación del Consejo de Medellín y la valoración de las acciones en el mercado.\n",
      "* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, que beneficiarán a la comunidad y la economía local.\n",
      "* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\n",
      "* La venta de acciones de EPM en UNE puede tener un impacto significativo en el panorama de la industria de las telecomunicaciones en Colombia.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "youtube_url = \"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\"\n",
    "language = \"spanish\"\n",
    "summary = summarize_youtube_video(youtube_url, language)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/02_MLFlow_implementation.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer with MLflow Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Create a YouTube video summarization chain\n",
    "2. Track the chain and prompts using MLflow\n",
    "3. Load and use the tracked model\n",
    "\n",
    "## Setup and Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\n",
      "Requirement already satisfied: youtube-transcript-api in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.6.3)\n",
      "Requirement already satisfied: groq in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: mlflow in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.18.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.18.0)\n",
      "Requirement already satisfied: Flask<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.1.3)\n",
      "Requirement already satisfied: pandas<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (18.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.38.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: packaging<25 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.28.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n",
      "Requirement already satisfied: Mako in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.36.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api groq python-dotenv mlflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Chain Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeSummaryChain:\n",
    "    def __init__(self, model_name: str = \"mixtral-8x7b-32768\", temperature: float = 0.3):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.prompt_template = \"\"\"\n",
    "        Please provide a comprehensive summary of the following video transcript. \n",
    "        Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "        {text}\n",
    "\n",
    "        Please structure the summary with:\n",
    "        1. Main Topic/Theme\n",
    "        2. Key Points\n",
    "        3. Important Details\n",
    "        4. Conclusions\n",
    "        \"\"\"\n",
    "        \n",
    "    def _get_groq_client(self):\n",
    "        \"\"\"\n",
    "        Initialize and return Groq client\n",
    "        \n",
    "        :return: Initialized Groq client\n",
    "        \"\"\"\n",
    "        return groq.Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "    \n",
    "    def extract_video_id(self, url: str) -> str:\n",
    "        \"\"\"Extract YouTube video ID from URL\"\"\"\n",
    "        parsed_url = urlparse(url)\n",
    "        if parsed_url.hostname == 'youtu.be':\n",
    "            return parsed_url.path[1:]\n",
    "        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "            if parsed_url.path == '/watch':\n",
    "                return parse_qs(parsed_url.query)['v'][0]\n",
    "        return None\n",
    "\n",
    "    def get_transcript(self, video_id: str) -> str:\n",
    "        \"\"\"Get transcript for a YouTube video\"\"\"\n",
    "        try:\n",
    "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            return ' '.join([t['text'] for t in transcript_list])\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "    def summarize_text(self, text: str) -> str:\n",
    "        \"\"\"Summarize text using Groq\"\"\"\n",
    "        prompt = self.prompt_template.format(text=text)\n",
    "\n",
    "        try:\n",
    "            # Initialize client only when needed\n",
    "            client = self._get_groq_client()\n",
    "            completion = client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=2048\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error in summarization: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __call__(self, url: str) -> str:\n",
    "        \"\"\"Process a YouTube URL and return summary\"\"\"\n",
    "        video_id = self.extract_video_id(url)\n",
    "        if not video_id:\n",
    "            return \"Invalid YouTube URL\"\n",
    "        \n",
    "        transcript = self.get_transcript(video_id)\n",
    "        if not transcript:\n",
    "            return \"Could not retrieve transcript\"\n",
    "        \n",
    "        summary = self.summarize_text(transcript)\n",
    "        if not summary:\n",
    "            return \"Could not generate summary\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get chain configuration for MLflow tracking\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"prompt_template\": self.prompt_template\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_chain_to_mlflow(chain: YouTubeSummaryChain, experiment_name: str = \"youtube-summarizer\"):\n",
    "    \"\"\"\n",
    "    Log the chain configuration and prompt to MLflow\n",
    "    \n",
    "    :param chain: YouTubeSummaryChain instance to log\n",
    "    :param experiment_name: Name of the MLflow experiment\n",
    "    :return: MLflow run ID\n",
    "    \"\"\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        # Log parameters\n",
    "        config = chain.get_config()\n",
    "        mlflow.log_params({\n",
    "            \"model_name\": config[\"model_name\"],\n",
    "            \"temperature\": config[\"temperature\"]\n",
    "        })\n",
    "        \n",
    "        # Log prompt template as artifact\n",
    "        with open(\"prompt_template.txt\", \"w\") as f:\n",
    "            f.write(config[\"prompt_template\"])\n",
    "        mlflow.log_artifact(\"prompt_template.txt\")\n",
    "        \n",
    "        # Create an input example\n",
    "        input_example = \"https://www.youtube.com/watch?v=example\"\n",
    "        \n",
    "        # Log the chain as a custom model\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"youtube_summarizer\",\n",
    "            python_model=chain,\n",
    "            artifacts={\"prompt_template\": \"prompt_template.txt\"},\n",
    "            code_path=[\".\"],\n",
    "            pip_requirements=[\"youtube-transcript-api\", \"groq\", \"python-dotenv\"],\n",
    "            input_example=input_example\n",
    "        )\n",
    "        \n",
    "        return run.info.run_id\n",
    "\n",
    "def load_chain_from_mlflow(run_id: str) -> YouTubeSummaryChain:\n",
    "    \"\"\"Load a chain from MLflow\"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/youtube_summarizer\"\n",
    "    chain = mlflow.pyfunc.load_model(model_uri)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:2852: UserWarning: The `code_path` argument is replaced by `code_paths` and is deprecated as of MLflow version 2.12.0. This argument will be removed in a future release of MLflow.\n",
      "  warnings.warn(\n",
      "2024/11/19 03:15:45 INFO mlflow.types.utils: Unsupported type hint: <class 'str'>, skipping schema inference\n",
      "2024/11/19 03:15:46 INFO mlflow.types.utils: Unsupported type hint: <class 'str'>, skipping schema inference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting transcript: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=example! This is most likely caused by:\n",
      "\n",
      "Subtitles are disabled for this video\n",
      "\n",
      "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Failed to serialize Python model. Please audit your class variables (e.g. in `__init__()`) for any unpicklable objects. If you're trying to save an external model in your custom pyfunc, Please use the `artifacts` parameter in `mlflow.pyfunc.save_model()`, and load your external model in the `load_context()` method instead. For example:\n\nclass MyModel(mlflow.pyfunc.PythonModel):\n    def load_context(self, context):\n        model_path = context.artifacts['my_model_path']\n        // custom load logic here\n        self.model = load_model(model_path)\n\nFor more information, see our full tutorial at: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\n\nFull serialization error: cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create and log the chain\u001b[39;00m\n\u001b[1;32m      2\u001b[0m chain \u001b[38;5;241m=\u001b[39m YouTubeSummaryChain()\n\u001b[0;32m----> 3\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[43mlog_chain_to_mlflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain logged with run_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the chain\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36mlog_chain_to_mlflow\u001b[0;34m(chain, experiment_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m input_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=example\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Log the chain as a custom model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myoutube_summarizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_template\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_template.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myoutube-transcript-api\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython-dotenv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/tracing/provider.py:268\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m disable()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     enable()\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3246\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(artifact_path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;129m@trace_disabled\u001b[39m  \u001b[38;5;66;03m# Suppress traces for internal predict calls while logging model\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3046\u001b[0m     resources: Optional[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Resource]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3047\u001b[0m ):\n\u001b[1;32m   3048\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;124;03m    Log a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001b[39;00m\n\u001b[1;32m   3050\u001b[0m \u001b[38;5;124;03m    artifact for the current run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3244\u001b[0m \u001b[38;5;124;03m        metadata of the logged model.\u001b[39;00m\n\u001b[1;32m   3245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3247\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# deprecated\u001b[39;49;00m\n\u001b[1;32m   3252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3254\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3257\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3258\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_no_conversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_no_conversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3267\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/models/model.py:776\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39m_get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m    773\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    774\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id, metadata\u001b[38;5;241m=\u001b[39mmetadata, resources\u001b[38;5;241m=\u001b[39mresources\n\u001b[1;32m    775\u001b[0m )\n\u001b[0;32m--> 776\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/tracing/provider.py:272\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             enable()\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m         is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# We should only catch the exception from disable() and enable()\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# and let other exceptions propagate.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowTracingException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3006\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources, **kwargs)\u001b[0m\n\u001b[1;32m   2992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _save_model_with_loader_module_and_data_path(\n\u001b[1;32m   2993\u001b[0m         path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   2994\u001b[0m         loader_module\u001b[38;5;241m=\u001b[39mloader_module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3003\u001b[0m         infer_code_paths\u001b[38;5;241m=\u001b[39minfer_code_paths,\n\u001b[1;32m   3004\u001b[0m     )\n\u001b[1;32m   3005\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m second_argument_set_specified:\n\u001b[0;32m-> 3006\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model_with_class_artifacts_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3008\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3011\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_code_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_code_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/model.py:382\u001b[0m, in \u001b[0;36m_save_model_with_class_artifacts_params\u001b[0;34m(path, python_model, signature, hints, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config, streamable, model_code_path, infer_code_paths)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# cloudpickle sometimes raises TypeError instead of PicklingError.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# catching generic Exception and checking message to handle both cases.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to serialize Python model. Please audit your \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass variables (e.g. in `__init__()`) for any \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munpicklable objects. If you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre trying to save an external model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min your custom pyfunc, Please use the `artifacts` parameter \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min `mlflow.pyfunc.save_model()`, and load your external model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the `load_context()` method instead. For example:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyModel(mlflow.pyfunc.PythonModel):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def load_context(self, context):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        model_path = context.artifacts[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_model_path\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        // custom load logic here\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.model = load_model(model_path)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    394\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor more information, see our full tutorial at: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFull serialization error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    397\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mMlflowException\u001b[0m: Failed to serialize Python model. Please audit your class variables (e.g. in `__init__()`) for any unpicklable objects. If you're trying to save an external model in your custom pyfunc, Please use the `artifacts` parameter in `mlflow.pyfunc.save_model()`, and load your external model in the `load_context()` method instead. For example:\n\nclass MyModel(mlflow.pyfunc.PythonModel):\n    def load_context(self, context):\n        model_path = context.artifacts['my_model_path']\n        // custom load logic here\n        self.model = load_model(model_path)\n\nFor more information, see our full tutorial at: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\n\nFull serialization error: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "# Create and log the chain\n",
    "chain = YouTubeSummaryChain()\n",
    "run_id = log_chain_to_mlflow(chain)\n",
    "print(f\"Chain logged with run_id: {run_id}\")\n",
    "\n",
    "# Load the chain\n",
    "loaded_chain = load_chain_from_mlflow(run_id)\n",
    "\n",
    "# Use the loaded chain\n",
    "youtube_url = \"https://www.youtube.com/watch?v=your_video_id\"\n",
    "summary = loaded_chain(youtube_url)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View MLflow Experiment Results\n",
    "\n",
    "You can view the tracked experiments by running:\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "This will start the MLflow UI server where you can see:\n",
    "1. All experiment runs\n",
    "2. Chain configurations\n",
    "3. Prompt templates\n",
    "4. Performance metrics (if added)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/meta.yaml
================================================================================

artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461
creation_time: 1732004080697
experiment_id: '336741345537322461'
last_update_time: 1732004080697
lifecycle_stage: active
name: youtube-summarizer



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts
end_time: null
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 907f1ecd64ca4ec2919e1657da05494b
run_name: abrasive-cod-859
run_uuid: 907f1ecd64ca4ec2919e1657da05494b
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004249085
status: 1
tags: []
user_id: ganga



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/artifacts
end_time: 1732004146098
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 0e7459a9e3524678a1970c2b02be4ee9
run_name: indecisive-mole-683
run_uuid: 0e7459a9e3524678a1970c2b02be4ee9
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004145291
status: 4
tags: []
user_id: ganga



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/artifacts
end_time: 1732004080824
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 0df34b8b49744c4d91061ee809b80f5b
run_name: intrigued-koi-579
run_uuid: 0df34b8b49744c4d91061ee809b80f5b
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004080797
status: 4
tags: []
user_id: ganga



================================================================================
# mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/0/meta.yaml
================================================================================

artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/0
creation_time: 1732004080692
experiment_id: '0'
last_update_time: 1732004080692
lifecycle_stage: active
name: Default



================================================================================
# mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/artifacts
end_time: 1732004146098
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 0e7459a9e3524678a1970c2b02be4ee9
run_name: indecisive-mole-683
run_uuid: 0e7459a9e3524678a1970c2b02be4ee9
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004145291
status: 4
tags: []
user_id: ganga



================================================================================
# mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/artifacts
end_time: 1732004080824
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 0df34b8b49744c4d91061ee809b80f5b
run_name: intrigued-koi-579
run_uuid: 0df34b8b49744c4d91061ee809b80f5b
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004080797
status: 4
tags: []
user_id: ganga



================================================================================
# mlruns/0/meta.yaml
================================================================================

artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/0
creation_time: 1732004080692
experiment_id: '0'
last_update_time: 1732004080692
lifecycle_stage: active
name: Default



================================================================================
# mlruns/1/a3e0cf31be6941898f90784e623e20ae/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/a3e0cf31be6941898f90784e623e20ae/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/3353294078c140ef8b9ebaee52ff842c/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/3353294078c140ef8b9ebaee52ff842c/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/b4423718012a4c4f8ce1ec028a380915/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/b4423718012a4c4f8ce1ec028a380915/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/3d42bc27e4d9459cb9af992afbb16765/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/3d42bc27e4d9459cb9af992afbb16765/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/5d00f8009c5c49349dbc80b888baeb0f/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/5d00f8009c5c49349dbc80b888baeb0f/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
name: mlflow-env



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/03_MLFlow_monitoring.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for YouTube Summarizer with MLflow\n",
    "\n",
    "This notebook evaluates the YouTube summarizer model using MLflow to track metrics and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_model_from_mlflow(run_id: str):\n",
    "    \"\"\"Load the YouTube summarizer model from MLflow\"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/youtube_summarizer\"\n",
    "    return mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Replace with your run_id from the training notebook\n",
    "RUN_ID = \"your_run_id_here\"\n",
    "model = load_model_from_mlflow(RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def prepare_test_data() -> List[Dict[str, str]]:\n",
    "    \"\"\"Prepare test data with YouTube videos and reference summaries\"\"\"\n",
    "    # Replace with your actual test data\n",
    "    return [\n",
    "        {\n",
    "            \"video_url\": \"https://www.youtube.com/watch?v=example1\",\n",
    "            \"reference_summary\": \"Reference summary for video 1\"\n",
    "        },\n",
    "        {\n",
    "            \"video_url\": \"https://www.youtube.com/watch?v=example2\",\n",
    "            \"reference_summary\": \"Reference summary for video 2\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_metrics(predicted_summary: str, reference_summary: str) -> Dict[str, float]:\n",
    "    \"\"\"Calculate various evaluation metrics\"\"\"\n",
    "    # ROUGE scores\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = scorer.score(reference_summary, predicted_summary)\n",
    "    \n",
    "    # BLEU score\n",
    "    reference = [reference_summary.split()]\n",
    "    candidate = predicted_summary.split()\n",
    "    bleu = sentence_bleu(reference, candidate)\n",
    "    \n",
    "    # Summary length metrics\n",
    "    pred_length = len(predicted_summary.split())\n",
    "    ref_length = len(reference_summary.split())\n",
    "    length_ratio = pred_length / ref_length if ref_length > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'rouge1_precision': rouge_scores['rouge1'].precision,\n",
    "        'rouge1_recall': rouge_scores['rouge1'].recall,\n",
    "        'rouge1_f1': rouge_scores['rouge1'].fmeasure,\n",
    "        'rouge2_f1': rouge_scores['rouge2'].fmeasure,\n",
    "        'rougeL_f1': rouge_scores['rougeL'].fmeasure,\n",
    "        'bleu_score': bleu,\n",
    "        'summary_length_ratio': length_ratio,\n",
    "        'predicted_length': pred_length,\n",
    "        'reference_length': ref_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_model_with_mlflow(model, test_data: List[Dict[str, str]]):\n",
    "    \"\"\"Evaluate model and log results to MLflow\"\"\"\n",
    "    mlflow.set_experiment(\"youtube-summarizer-evaluation\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"model_evaluation\") as run:\n",
    "        all_metrics = []\n",
    "        \n",
    "        # Log model parameters\n",
    "        model_params = model.get_config() if hasattr(model, 'get_config') else {}\n",
    "        mlflow.log_params(model_params)\n",
    "        \n",
    "        # Evaluate each test example\n",
    "        for i, example in enumerate(test_data):\n",
    "            # Generate summary\n",
    "            predicted_summary = model(example['video_url'])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = calculate_metrics(predicted_summary, example['reference_summary'])\n",
    "            all_metrics.append(metrics)\n",
    "            \n",
    "            # Log metrics for each example\n",
    "            for metric_name, value in metrics.items():\n",
    "                mlflow.log_metric(f\"example_{i}_{metric_name}\", value)\n",
    "            \n",
    "            # Log summaries as artifacts\n",
    "            example_dir = f\"example_{i}\"\n",
    "            os.makedirs(example_dir, exist_ok=True)\n",
    "            \n",
    "            with open(f\"{example_dir}/predicted_summary.txt\", \"w\") as f:\n",
    "                f.write(predicted_summary)\n",
    "            with open(f\"{example_dir}/reference_summary.txt\", \"w\") as f:\n",
    "                f.write(example['reference_summary'])\n",
    "            \n",
    "            mlflow.log_artifacts(example_dir)\n",
    "        \n",
    "        # Calculate and log average metrics\n",
    "        avg_metrics = {}\n",
    "        for metric in all_metrics[0].keys():\n",
    "            avg_value = np.mean([m[metric] for m in all_metrics])\n",
    "            avg_metrics[f\"avg_{metric}\"] = avg_value\n",
    "            mlflow.log_metric(f\"avg_{metric}\", avg_value)\n",
    "        \n",
    "        # Create and log visualizations\n",
    "        create_and_log_visualizations(all_metrics)\n",
    "        \n",
    "        return run.info.run_id, avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_and_log_visualizations(metrics_list: List[Dict[str, float]]):\n",
    "    \"\"\"Create and log visualizations to MLflow\"\"\"\n",
    "    # Convert metrics to DataFrame\n",
    "    df = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    # ROUGE scores comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    rouge_metrics = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']\n",
    "    df[rouge_metrics].mean().plot(kind='bar')\n",
    "    plt.title('Average ROUGE Scores')\n",
    "    plt.ylabel('Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('rouge_scores.png')\n",
    "    mlflow.log_artifact('rouge_scores.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Summary length analysis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['reference_length'], df['predicted_length'])\n",
    "    plt.plot([0, max(df['reference_length'])], [0, max(df['reference_length'])], '--', color='red')\n",
    "    plt.xlabel('Reference Summary Length')\n",
    "    plt.ylabel('Predicted Summary Length')\n",
    "    plt.title('Summary Length Comparison')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('length_comparison.png')\n",
    "    mlflow.log_artifact('length_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Metrics distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics_to_plot = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1', 'bleu_score']\n",
    "    df[metrics_to_plot].boxplot()\n",
    "    plt.title('Distribution of Evaluation Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_distribution.png')\n",
    "    mlflow.log_artifact('metrics_distribution.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare test data\n",
    "test_data = prepare_test_data()\n",
    "\n",
    "# Run evaluation\n",
    "run_id, avg_metrics = evaluate_model_with_mlflow(model, test_data)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(\"==================\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nMLflow run ID: {run_id}\")\n",
    "print(\"View detailed results in the MLflow UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results in MLflow UI\n",
    "\n",
    "To view the detailed results and visualizations:\n",
    "1. Start the MLflow UI by running `mlflow ui` in your terminal\n",
    "2. Open http://localhost:5000 in your browser\n",
    "3. Navigate to the experiment \"youtube-summarizer-evaluation\"\n",
    "4. Click on the run ID printed above to see detailed metrics and artifacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/__init__.py
================================================================================




================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/04_MLFlow_evaluation.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Summarizer: Model Setup and Monitoring\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Set up the YouTube summarizer model\n",
    "2. Implement monitoring using MLflow\n",
    "3. Track model performance metrics\n",
    "4. Monitor system resources and latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import time\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "import psutil\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Setup\n",
    "\n",
    "First, we'll set up our summarization model using the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def initialize_model():\n",
    "    \"\"\"Initialize the summarization model\"\"\"\n",
    "    model_name = \"facebook/bart-large-cnn\"  # You can change this to other models\n",
    "    summarizer = pipeline(\"summarization\", model=model_name)\n",
    "    return summarizer\n",
    "\n",
    "# Initialize the model\n",
    "summarizer = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLflow Setup\n",
    "\n",
    "Set up MLflow to track experiments and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"youtube_summarizer_monitoring\")\n",
    "\n",
    "def log_metrics(metrics_dict):\n",
    "    \"\"\"Log metrics to MLflow\"\"\"\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_metrics(metrics_dict)\n",
    "        mlflow.log_param(\"model_name\", \"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Monitoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        self.metrics_history = []\n",
    "    \n",
    "    def measure_latency(self, func, *args, **kwargs):\n",
    "        \"\"\"Measure execution time of a function\"\"\"\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        return result, end_time - start_time\n",
    "    \n",
    "    def measure_resource_usage(self):\n",
    "        \"\"\"Measure CPU and memory usage\"\"\"\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_info = psutil.Process().memory_info()\n",
    "        return {\n",
    "            'cpu_percent': cpu_percent,\n",
    "            'memory_mb': memory_info.rss / 1024 / 1024\n",
    "        }\n",
    "    \n",
    "    def calculate_rouge_scores(self, prediction, reference):\n",
    "        \"\"\"Calculate ROUGE scores\"\"\"\n",
    "        scores = self.scorer.score(prediction, reference)\n",
    "        return {\n",
    "            'rouge1_f1': scores['rouge1'].fmeasure,\n",
    "            'rouge2_f1': scores['rouge2'].fmeasure,\n",
    "            'rougeL_f1': scores['rougeL'].fmeasure\n",
    "        }\n",
    "    \n",
    "    def log_performance(self, latency, rouge_scores, resource_usage):\n",
    "        \"\"\"Log all performance metrics\"\"\"\n",
    "        metrics = {\n",
    "            'latency': latency,\n",
    "            **rouge_scores,\n",
    "            **resource_usage\n",
    "        }\n",
    "        self.metrics_history.append(metrics)\n",
    "        log_metrics(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_metrics_over_time(metrics_history):\n",
    "    \"\"\"Create interactive plots for metrics over time\"\"\"\n",
    "    df = pd.DataFrame(metrics_history)\n",
    "    \n",
    "    # Latency plot\n",
    "    fig_latency = px.line(df, y='latency', title='Inference Latency Over Time')\n",
    "    fig_latency.show()\n",
    "    \n",
    "    # Resource usage plot\n",
    "    fig_resources = go.Figure()\n",
    "    fig_resources.add_trace(go.Scatter(y=df['cpu_percent'], name='CPU %'))\n",
    "    fig_resources.add_trace(go.Scatter(y=df['memory_mb'], name='Memory (MB)'))\n",
    "    fig_resources.update_layout(title='Resource Usage Over Time')\n",
    "    fig_resources.show()\n",
    "    \n",
    "    # ROUGE scores plot\n",
    "    fig_rouge = go.Figure()\n",
    "    for metric in ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']:\n",
    "        fig_rouge.add_trace(go.Scatter(y=df[metric], name=metric))\n",
    "    fig_rouge.update_layout(title='ROUGE Scores Over Time')\n",
    "    fig_rouge.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the performance monitor\n",
    "monitor = PerformanceMonitor()\n",
    "\n",
    "def process_video(video_id, reference_summary=None):\n",
    "    \"\"\"Process a video with monitoring\"\"\"\n",
    "    # Get transcript\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    text = ' '.join([t['text'] for t in transcript])\n",
    "    \n",
    "    # Generate summary with latency measurement\n",
    "    summary, latency = monitor.measure_latency(\n",
    "        lambda: summarizer(text, max_length=130, min_length=30)[0]['summary_text']\n",
    "    )\n",
    "    \n",
    "    # Measure resource usage\n",
    "    resource_usage = monitor.measure_resource_usage()\n",
    "    \n",
    "    # Calculate ROUGE scores if reference summary is provided\n",
    "    rouge_scores = monitor.calculate_rouge_scores(summary, reference_summary) if reference_summary else {}\n",
    "    \n",
    "    # Log all metrics\n",
    "    metrics = monitor.log_performance(latency, rouge_scores, resource_usage)\n",
    "    \n",
    "    return summary, metrics\n",
    "\n",
    "# Example usage\n",
    "# video_id = \"YOUR_VIDEO_ID\"\n",
    "# summary, metrics = process_video(video_id)\n",
    "# plot_metrics_over_time(monitor.metrics_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/README.md
================================================================================

# YouTube Video Summarizer

This project provides a Jupyter notebook that can summarize YouTube videos using their transcripts and Groq's AI model. The summarizer extracts the video's transcription and generates a comprehensive summary focusing on main points, key insights, and important conclusions.

## Features

- Extract YouTube video transcripts
- Process transcripts using Groq's Mixtral-8x7b model
- Generate structured summaries with main topics, key points, and conclusions
- Support for both standard YouTube URLs and shortened (youtu.be) links

## Prerequisites

- Python 3.8+
- Groq API key
- Internet connection for accessing YouTube and Groq API

## Installation

1. Clone this repository
2. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```
3. Create a `.env` file in the project directory and add your Groq API key:
   ```
   GROQ_API_KEY=your_api_key_here
   ```

## Usage

1. Start Jupyter Notebook:
   ```bash
   jupyter notebook
   ```
2. Open `youtube_summarizer.ipynb`
3. Run all cells in the notebook
4. Replace the example YouTube URL with your desired video URL
5. Run the cell to get your summary

## Example

```python
youtube_url = "https://www.youtube.com/watch?v=your_video_id"
summary = summarize_youtube_video(youtube_url)
print(summary)
```

## Note

- The video must have available transcripts (either auto-generated or manually created)
- The quality of the summary depends on the quality of the transcript and the video content
- Make sure you have sufficient API credits in your Groq account

## License

This project is open-source and available under the MIT License.



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/01_PoC.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer using Groq\n",
    "\n",
    "This notebook demonstrates how to create a YouTube video summarizer that:\n",
    "1. Takes a YouTube URL as input\n",
    "2. Extracts the video's transcription\n",
    "3. Uses Groq to generate a concise summary\n",
    "\n",
    "## Setup and Requirements\n",
    "First, we'll install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api groq python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(url):\n",
    "    \"\"\"Extract YouTube video ID from URL\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.hostname == 'youtu.be':\n",
    "        return parsed_url.path[1:]\n",
    "    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "        if parsed_url.path == '/watch':\n",
    "            return parse_qs(parsed_url.query)['v'][0]\n",
    "    return None\n",
    "\n",
    "def get_transcript(video_id):\n",
    "    \"\"\"Get transcript for a YouTube video\"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\n",
    "        return ' '.join([t['text'] for t in transcript_list])\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting transcript: {e}\")\n",
    "        return None\n",
    "\n",
    "def summarize_text(text, language=\"spanish\"):\n",
    "    \"\"\"Summarize text using Groq\"\"\"\n",
    "    prompt = f\"\"\"Please provide a comprehensive summary of the following video transcript in {language}. \n",
    "    Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "    {text}\n",
    "\n",
    "    Please structure the summary with:\n",
    "    1. Main Topic/Theme\n",
    "    2. Key Points\n",
    "    3. Important Details\n",
    "    4. Conclusions\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama-3.2-90b-vision-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in summarization: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function to Summarize YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_youtube_video(url, language=\"spanish\"):\n",
    "    \"\"\"Main function to summarize a YouTube video\"\"\"\n",
    "    # Extract video ID\n",
    "    video_id = extract_video_id(url)\n",
    "    if not video_id:\n",
    "        return \"Invalid YouTube URL\"\n",
    "    \n",
    "    # Get transcript\n",
    "    transcript = get_transcript(video_id)\n",
    "    if not transcript:\n",
    "        return \"Could not retrieve transcript\"\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = summarize_text(transcript, language)\n",
    "    if not summary:\n",
    "        return \"Could not generate summary\"\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "To use this summarizer, you'll need to:\n",
    "1. Create a `.env` file in the same directory as this notebook\n",
    "2. Add your Groq API key to the `.env` file: `GROQ_API_KEY=your_api_key_here`\n",
    "\n",
    "Then you can use the summarizer as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Resumen del video transcript**\n",
      "\n",
      "**1. Tema principal/Tema**: La venta de acciones de EPM en UNE, una empresa de telecomunicaciones, y su impacto en la industria y la economía local.\n",
      "\n",
      "**2. Puntos clave**:\n",
      "\n",
      "* EPM busca vender sus acciones en UNE debido a la intensidad de capital y la rápida evolución tecnológica en la industria de las telecomunicaciones.\n",
      "* La venta de acciones se realizará a través de un proceso de enajenación, que requiere la aprobación del Consejo de Medellín.\n",
      "* El valor de las acciones se estima en 1,6 billones de pesos, según el valor en libros y la capitalización de UNE.\n",
      "* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\n",
      "\n",
      "**3. Detalles importantes**:\n",
      "\n",
      "* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\n",
      "* EPM tiene otros negocios estratégicos, como la generación y distribución de energía, agua y gas, que requieren inversiones importantes.\n",
      "* La venta de acciones se realizará a través de un proceso de enajenación, que incluye la oferta a sectores solidarios y especiales, y luego al mercado.\n",
      "* El gobierno también está considerando la venta de sus acciones en UNE, lo que podría cambiar el panorama de la industria de las telecomunicaciones en Colombia.\n",
      "* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\n",
      "\n",
      "**4. Conclusión**:\n",
      "\n",
      "* La venta de acciones de EPM en UNE es un proceso complejo que requiere la aprobación del Consejo de Medellín y la valoración de las acciones en el mercado.\n",
      "* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, que beneficiarán a la comunidad y la economía local.\n",
      "* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\n",
      "* La venta de acciones de EPM en UNE puede tener un impacto significativo en el panorama de la industria de las telecomunicaciones en Colombia.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "youtube_url = \"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\"\n",
    "language = \"spanish\"\n",
    "summary = summarize_youtube_video(youtube_url, language)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/02_MLFlow_implementation.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer with MLflow Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Create a YouTube video summarization chain\n",
    "2. Track the chain and prompts using MLflow\n",
    "3. Load and use the tracked model\n",
    "\n",
    "## Setup and Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\n",
      "Requirement already satisfied: youtube-transcript-api in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.6.3)\n",
      "Requirement already satisfied: groq in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: mlflow in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.18.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.18.0)\n",
      "Requirement already satisfied: Flask<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.1.3)\n",
      "Requirement already satisfied: pandas<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (18.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.38.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: packaging<25 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.28.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n",
      "Requirement already satisfied: Mako in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.36.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api groq python-dotenv mlflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Chain Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeSummaryChain:\n",
    "    def __init__(self, model_name: str = \"mixtral-8x7b-32768\", temperature: float = 0.3):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.prompt_template = \"\"\"\n",
    "        Please provide a comprehensive summary of the following video transcript. \n",
    "        Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "        {text}\n",
    "\n",
    "        Please structure the summary with:\n",
    "        1. Main Topic/Theme\n",
    "        2. Key Points\n",
    "        3. Important Details\n",
    "        4. Conclusions\n",
    "        \"\"\"\n",
    "        \n",
    "    def _get_groq_client(self):\n",
    "        \"\"\"\n",
    "        Initialize and return Groq client\n",
    "        \n",
    "        :return: Initialized Groq client\n",
    "        \"\"\"\n",
    "        return groq.Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "    \n",
    "    def extract_video_id(self, url: str) -> str:\n",
    "        \"\"\"Extract YouTube video ID from URL\"\"\"\n",
    "        parsed_url = urlparse(url)\n",
    "        if parsed_url.hostname == 'youtu.be':\n",
    "            return parsed_url.path[1:]\n",
    "        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "            if parsed_url.path == '/watch':\n",
    "                return parse_qs(parsed_url.query)['v'][0]\n",
    "        return None\n",
    "\n",
    "    def get_transcript(self, video_id: str) -> str:\n",
    "        \"\"\"Get transcript for a YouTube video\"\"\"\n",
    "        try:\n",
    "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            return ' '.join([t['text'] for t in transcript_list])\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "    def summarize_text(self, text: str) -> str:\n",
    "        \"\"\"Summarize text using Groq\"\"\"\n",
    "        prompt = self.prompt_template.format(text=text)\n",
    "\n",
    "        try:\n",
    "            # Initialize client only when needed\n",
    "            client = self._get_groq_client()\n",
    "            completion = client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=2048\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error in summarization: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __call__(self, url: str) -> str:\n",
    "        \"\"\"Process a YouTube URL and return summary\"\"\"\n",
    "        video_id = self.extract_video_id(url)\n",
    "        if not video_id:\n",
    "            return \"Invalid YouTube URL\"\n",
    "        \n",
    "        transcript = self.get_transcript(video_id)\n",
    "        if not transcript:\n",
    "            return \"Could not retrieve transcript\"\n",
    "        \n",
    "        summary = self.summarize_text(transcript)\n",
    "        if not summary:\n",
    "            return \"Could not generate summary\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get chain configuration for MLflow tracking\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"prompt_template\": self.prompt_template\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this after the imports\n",
    "# Set up MLflow tracking\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")  # Local SQLite database\n",
    "# Or use a local directory\n",
    "# mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "def log_chain_to_mlflow(chain: YouTubeSummaryChain, experiment_name: str = \"youtube-summarizer\"):\n",
    "    \"\"\"\n",
    "    Log the chain configuration and prompt to MLflow\n",
    "    \n",
    "    :param chain: YouTubeSummaryChain instance to log\n",
    "    :param experiment_name: Name of the MLflow experiment\n",
    "    :return: MLflow run ID\n",
    "    \"\"\"\n",
    "    # Create experiment if it doesn't exist\n",
    "    try:\n",
    "        mlflow.create_experiment(experiment_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        # Log parameters\n",
    "        config = chain.get_config()\n",
    "        mlflow.log_params({\n",
    "            \"model_name\": config[\"model_name\"],\n",
    "            \"temperature\": config[\"temperature\"]\n",
    "        })\n",
    "        \n",
    "        # Log prompt template as artifact\n",
    "        with open(\"prompt_template.txt\", \"w\") as f:\n",
    "            f.write(config[\"prompt_template\"])\n",
    "        mlflow.log_artifact(\"prompt_template.txt\")\n",
    "        \n",
    "        # Log additional metadata\n",
    "        mlflow.set_tags({\n",
    "            \"model_type\": \"youtube_summarizer\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"framework\": \"groq\"\n",
    "        })\n",
    "        \n",
    "        # Create an input example\n",
    "        input_example = \"https://www.youtube.com/watch?v=example\"\n",
    "        \n",
    "        # Log the chain as a custom model\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"youtube_summarizer\",\n",
    "            python_model=chain,\n",
    "            artifacts={\"prompt_template\": \"prompt_template.txt\"},\n",
    "            code_path=[\".\"],\n",
    "            pip_requirements=[\"youtube-transcript-api\", \"groq\", \"python-dotenv\"],\n",
    "            input_example=input_example\n",
    "        )\n",
    "        \n",
    "        return run.info.run_id\n",
    "\n",
    "def load_chain_from_mlflow(run_id: str) -> YouTubeSummaryChain:\n",
    "    \"\"\"Load a chain from MLflow\"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/youtube_summarizer\"\n",
    "    chain = mlflow.pyfunc.load_model(model_uri)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and log the chain\n",
    "chain = YouTubeSummaryChain()\n",
    "run_id = log_chain_to_mlflow(chain)\n",
    "print(f\"Chain logged with run_id: {run_id}\")\n",
    "\n",
    "# Load the chain\n",
    "loaded_chain = load_chain_from_mlflow(run_id)\n",
    "\n",
    "# Use the loaded chain\n",
    "youtube_url = \"https://www.youtube.com/watch?v=your_video_id\"\n",
    "summary = loaded_chain(youtube_url)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View MLflow Experiment Results\n",
    "\n",
    "You can view the tracked experiments by running:\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "This will start the MLflow UI server where you can see:\n",
    "1. All experiment runs\n",
    "2. Chain configurations\n",
    "3. Prompt templates\n",
    "4. Performance metrics (if added)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/meta.yaml
================================================================================

artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461
creation_time: 1732004080697
experiment_id: '336741345537322461'
last_update_time: 1732004080697
lifecycle_stage: active
name: youtube-summarizer



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts
end_time: 1732004251458
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 907f1ecd64ca4ec2919e1657da05494b
run_name: abrasive-cod-859
run_uuid: 907f1ecd64ca4ec2919e1657da05494b
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004249085
status: 3
tags: []
user_id: ganga



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
name: mlflow-env



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/03_MLFlow_monitoring.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for YouTube Summarizer with MLflow\n",
    "\n",
    "This notebook evaluates the YouTube summarizer model using MLflow to track metrics and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_model_from_mlflow(run_id: str):\n",
    "    \"\"\"Load the YouTube summarizer model from MLflow\"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/youtube_summarizer\"\n",
    "    return mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Replace with your run_id from the training notebook\n",
    "RUN_ID = \"your_run_id_here\"\n",
    "model = load_model_from_mlflow(RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def prepare_test_data() -> List[Dict[str, str]]:\n",
    "    \"\"\"Prepare test data with YouTube videos and reference summaries\"\"\"\n",
    "    # Replace with your actual test data\n",
    "    return [\n",
    "        {\n",
    "            \"video_url\": \"https://www.youtube.com/watch?v=example1\",\n",
    "            \"reference_summary\": \"Reference summary for video 1\"\n",
    "        },\n",
    "        {\n",
    "            \"video_url\": \"https://www.youtube.com/watch?v=example2\",\n",
    "            \"reference_summary\": \"Reference summary for video 2\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_metrics(predicted_summary: str, reference_summary: str) -> Dict[str, float]:\n",
    "    \"\"\"Calculate various evaluation metrics\"\"\"\n",
    "    # ROUGE scores\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = scorer.score(reference_summary, predicted_summary)\n",
    "    \n",
    "    # BLEU score\n",
    "    reference = [reference_summary.split()]\n",
    "    candidate = predicted_summary.split()\n",
    "    bleu = sentence_bleu(reference, candidate)\n",
    "    \n",
    "    # Summary length metrics\n",
    "    pred_length = len(predicted_summary.split())\n",
    "    ref_length = len(reference_summary.split())\n",
    "    length_ratio = pred_length / ref_length if ref_length > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'rouge1_precision': rouge_scores['rouge1'].precision,\n",
    "        'rouge1_recall': rouge_scores['rouge1'].recall,\n",
    "        'rouge1_f1': rouge_scores['rouge1'].fmeasure,\n",
    "        'rouge2_f1': rouge_scores['rouge2'].fmeasure,\n",
    "        'rougeL_f1': rouge_scores['rougeL'].fmeasure,\n",
    "        'bleu_score': bleu,\n",
    "        'summary_length_ratio': length_ratio,\n",
    "        'predicted_length': pred_length,\n",
    "        'reference_length': ref_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_model_with_mlflow(model, test_data: List[Dict[str, str]]):\n",
    "    \"\"\"Evaluate model and log results to MLflow\"\"\"\n",
    "    mlflow.set_experiment(\"youtube-summarizer-evaluation\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"model_evaluation\") as run:\n",
    "        all_metrics = []\n",
    "        \n",
    "        # Log model parameters\n",
    "        model_params = model.get_config() if hasattr(model, 'get_config') else {}\n",
    "        mlflow.log_params(model_params)\n",
    "        \n",
    "        # Evaluate each test example\n",
    "        for i, example in enumerate(test_data):\n",
    "            # Generate summary\n",
    "            predicted_summary = model(example['video_url'])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = calculate_metrics(predicted_summary, example['reference_summary'])\n",
    "            all_metrics.append(metrics)\n",
    "            \n",
    "            # Log metrics for each example\n",
    "            for metric_name, value in metrics.items():\n",
    "                mlflow.log_metric(f\"example_{i}_{metric_name}\", value)\n",
    "            \n",
    "            # Log summaries as artifacts\n",
    "            example_dir = f\"example_{i}\"\n",
    "            os.makedirs(example_dir, exist_ok=True)\n",
    "            \n",
    "            with open(f\"{example_dir}/predicted_summary.txt\", \"w\") as f:\n",
    "                f.write(predicted_summary)\n",
    "            with open(f\"{example_dir}/reference_summary.txt\", \"w\") as f:\n",
    "                f.write(example['reference_summary'])\n",
    "            \n",
    "            mlflow.log_artifacts(example_dir)\n",
    "        \n",
    "        # Calculate and log average metrics\n",
    "        avg_metrics = {}\n",
    "        for metric in all_metrics[0].keys():\n",
    "            avg_value = np.mean([m[metric] for m in all_metrics])\n",
    "            avg_metrics[f\"avg_{metric}\"] = avg_value\n",
    "            mlflow.log_metric(f\"avg_{metric}\", avg_value)\n",
    "        \n",
    "        # Create and log visualizations\n",
    "        create_and_log_visualizations(all_metrics)\n",
    "        \n",
    "        return run.info.run_id, avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_and_log_visualizations(metrics_list: List[Dict[str, float]]):\n",
    "    \"\"\"Create and log visualizations to MLflow\"\"\"\n",
    "    # Convert metrics to DataFrame\n",
    "    df = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    # ROUGE scores comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    rouge_metrics = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']\n",
    "    df[rouge_metrics].mean().plot(kind='bar')\n",
    "    plt.title('Average ROUGE Scores')\n",
    "    plt.ylabel('Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('rouge_scores.png')\n",
    "    mlflow.log_artifact('rouge_scores.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Summary length analysis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['reference_length'], df['predicted_length'])\n",
    "    plt.plot([0, max(df['reference_length'])], [0, max(df['reference_length'])], '--', color='red')\n",
    "    plt.xlabel('Reference Summary Length')\n",
    "    plt.ylabel('Predicted Summary Length')\n",
    "    plt.title('Summary Length Comparison')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('length_comparison.png')\n",
    "    mlflow.log_artifact('length_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Metrics distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics_to_plot = ['rouge1_f1', 'rouge2_f1', 'rougeL_f1', 'bleu_score']\n",
    "    df[metrics_to_plot].boxplot()\n",
    "    plt.title('Distribution of Evaluation Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_distribution.png')\n",
    "    mlflow.log_artifact('metrics_distribution.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare test data\n",
    "test_data = prepare_test_data()\n",
    "\n",
    "# Run evaluation\n",
    "run_id, avg_metrics = evaluate_model_with_mlflow(model, test_data)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(\"==================\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nMLflow run ID: {run_id}\")\n",
    "print(\"View detailed results in the MLflow UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results in MLflow UI\n",
    "\n",
    "To view the detailed results and visualizations:\n",
    "1. Start the MLflow UI by running `mlflow ui` in your terminal\n",
    "2. Open http://localhost:5000 in your browser\n",
    "3. Navigate to the experiment \"youtube-summarizer-evaluation\"\n",
    "4. Click on the run ID printed above to see detailed metrics and artifacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/__init__.py
================================================================================




================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/04_MLFlow_evaluation.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Summarizer: Model Setup and Monitoring\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Set up the YouTube summarizer model\n",
    "2. Implement monitoring using MLflow\n",
    "3. Track model performance metrics\n",
    "4. Monitor system resources and latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import time\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "import psutil\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Setup\n",
    "\n",
    "First, we'll set up our summarization model using the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def initialize_model():\n",
    "    \"\"\"Initialize the summarization model\"\"\"\n",
    "    model_name = \"facebook/bart-large-cnn\"  # You can change this to other models\n",
    "    summarizer = pipeline(\"summarization\", model=model_name)\n",
    "    return summarizer\n",
    "\n",
    "# Initialize the model\n",
    "summarizer = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLflow Setup\n",
    "\n",
    "Set up MLflow to track experiments and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"youtube_summarizer_monitoring\")\n",
    "\n",
    "def log_metrics(metrics_dict):\n",
    "    \"\"\"Log metrics to MLflow\"\"\"\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_metrics(metrics_dict)\n",
    "        mlflow.log_param(\"model_name\", \"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Monitoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        self.metrics_history = []\n",
    "    \n",
    "    def measure_latency(self, func, *args, **kwargs):\n",
    "        \"\"\"Measure execution time of a function\"\"\"\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        return result, end_time - start_time\n",
    "    \n",
    "    def measure_resource_usage(self):\n",
    "        \"\"\"Measure CPU and memory usage\"\"\"\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_info = psutil.Process().memory_info()\n",
    "        return {\n",
    "            'cpu_percent': cpu_percent,\n",
    "            'memory_mb': memory_info.rss / 1024 / 1024\n",
    "        }\n",
    "    \n",
    "    def calculate_rouge_scores(self, prediction, reference):\n",
    "        \"\"\"Calculate ROUGE scores\"\"\"\n",
    "        scores = self.scorer.score(prediction, reference)\n",
    "        return {\n",
    "            'rouge1_f1': scores['rouge1'].fmeasure,\n",
    "            'rouge2_f1': scores['rouge2'].fmeasure,\n",
    "            'rougeL_f1': scores['rougeL'].fmeasure\n",
    "        }\n",
    "    \n",
    "    def log_performance(self, latency, rouge_scores, resource_usage):\n",
    "        \"\"\"Log all performance metrics\"\"\"\n",
    "        metrics = {\n",
    "            'latency': latency,\n",
    "            **rouge_scores,\n",
    "            **resource_usage\n",
    "        }\n",
    "        self.metrics_history.append(metrics)\n",
    "        log_metrics(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_metrics_over_time(metrics_history):\n",
    "    \"\"\"Create interactive plots for metrics over time\"\"\"\n",
    "    df = pd.DataFrame(metrics_history)\n",
    "    \n",
    "    # Latency plot\n",
    "    fig_latency = px.line(df, y='latency', title='Inference Latency Over Time')\n",
    "    fig_latency.show()\n",
    "    \n",
    "    # Resource usage plot\n",
    "    fig_resources = go.Figure()\n",
    "    fig_resources.add_trace(go.Scatter(y=df['cpu_percent'], name='CPU %'))\n",
    "    fig_resources.add_trace(go.Scatter(y=df['memory_mb'], name='Memory (MB)'))\n",
    "    fig_resources.update_layout(title='Resource Usage Over Time')\n",
    "    fig_resources.show()\n",
    "    \n",
    "    # ROUGE scores plot\n",
    "    fig_rouge = go.Figure()\n",
    "    for metric in ['rouge1_f1', 'rouge2_f1', 'rougeL_f1']:\n",
    "        fig_rouge.add_trace(go.Scatter(y=df[metric], name=metric))\n",
    "    fig_rouge.update_layout(title='ROUGE Scores Over Time')\n",
    "    fig_rouge.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the performance monitor\n",
    "monitor = PerformanceMonitor()\n",
    "\n",
    "def process_video(video_id, reference_summary=None):\n",
    "    \"\"\"Process a video with monitoring\"\"\"\n",
    "    # Get transcript\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    text = ' '.join([t['text'] for t in transcript])\n",
    "    \n",
    "    # Generate summary with latency measurement\n",
    "    summary, latency = monitor.measure_latency(\n",
    "        lambda: summarizer(text, max_length=130, min_length=30)[0]['summary_text']\n",
    "    )\n",
    "    \n",
    "    # Measure resource usage\n",
    "    resource_usage = monitor.measure_resource_usage()\n",
    "    \n",
    "    # Calculate ROUGE scores if reference summary is provided\n",
    "    rouge_scores = monitor.calculate_rouge_scores(summary, reference_summary) if reference_summary else {}\n",
    "    \n",
    "    # Log all metrics\n",
    "    metrics = monitor.log_performance(latency, rouge_scores, resource_usage)\n",
    "    \n",
    "    return summary, metrics\n",
    "\n",
    "# Example usage\n",
    "# video_id = \"YOUR_VIDEO_ID\"\n",
    "# summary, metrics = process_video(video_id)\n",
    "# plot_metrics_over_time(monitor.metrics_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/README.md
================================================================================

# YouTube Video Summarizer

This project provides a Jupyter notebook that can summarize YouTube videos using their transcripts and Groq's AI model. The summarizer extracts the video's transcription and generates a comprehensive summary focusing on main points, key insights, and important conclusions.

## Features

- Extract YouTube video transcripts
- Process transcripts using Groq's Mixtral-8x7b model
- Generate structured summaries with main topics, key points, and conclusions
- Support for both standard YouTube URLs and shortened (youtu.be) links

## Prerequisites

- Python 3.8+
- Groq API key
- Internet connection for accessing YouTube and Groq API

## Installation

1. Clone this repository
2. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```
3. Create a `.env` file in the project directory and add your Groq API key:
   ```
   GROQ_API_KEY=your_api_key_here
   ```

## Usage

1. Start Jupyter Notebook:
   ```bash
   jupyter notebook
   ```
2. Open `youtube_summarizer.ipynb`
3. Run all cells in the notebook
4. Replace the example YouTube URL with your desired video URL
5. Run the cell to get your summary

## Example

```python
youtube_url = "https://www.youtube.com/watch?v=your_video_id"
summary = summarize_youtube_video(youtube_url)
print(summary)
```

## Note

- The video must have available transcripts (either auto-generated or manually created)
- The quality of the summary depends on the quality of the transcript and the video content
- Make sure you have sufficient API credits in your Groq account

## License

This project is open-source and available under the MIT License.



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/01_PoC.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer using Groq\n",
    "\n",
    "This notebook demonstrates how to create a YouTube video summarizer that:\n",
    "1. Takes a YouTube URL as input\n",
    "2. Extracts the video's transcription\n",
    "3. Uses Groq to generate a concise summary\n",
    "\n",
    "## Setup and Requirements\n",
    "First, we'll install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api groq python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(url):\n",
    "    \"\"\"Extract YouTube video ID from URL\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.hostname == 'youtu.be':\n",
    "        return parsed_url.path[1:]\n",
    "    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "        if parsed_url.path == '/watch':\n",
    "            return parse_qs(parsed_url.query)['v'][0]\n",
    "    return None\n",
    "\n",
    "def get_transcript(video_id):\n",
    "    \"\"\"Get transcript for a YouTube video\"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'es'])\n",
    "        return ' '.join([t['text'] for t in transcript_list])\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting transcript: {e}\")\n",
    "        return None\n",
    "\n",
    "def summarize_text(text, language=\"spanish\"):\n",
    "    \"\"\"Summarize text using Groq\"\"\"\n",
    "    prompt = f\"\"\"Please provide a comprehensive summary of the following video transcript in {language}. \n",
    "    Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "    {text}\n",
    "\n",
    "    Please structure the summary with:\n",
    "    1. Main Topic/Theme\n",
    "    2. Key Points\n",
    "    3. Important Details\n",
    "    4. Conclusions\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama-3.2-90b-vision-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in summarization: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function to Summarize YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_youtube_video(url, language=\"spanish\"):\n",
    "    \"\"\"Main function to summarize a YouTube video\"\"\"\n",
    "    # Extract video ID\n",
    "    video_id = extract_video_id(url)\n",
    "    if not video_id:\n",
    "        return \"Invalid YouTube URL\"\n",
    "    \n",
    "    # Get transcript\n",
    "    transcript = get_transcript(video_id)\n",
    "    if not transcript:\n",
    "        return \"Could not retrieve transcript\"\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = summarize_text(transcript, language)\n",
    "    if not summary:\n",
    "        return \"Could not generate summary\"\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "To use this summarizer, you'll need to:\n",
    "1. Create a `.env` file in the same directory as this notebook\n",
    "2. Add your Groq API key to the `.env` file: `GROQ_API_KEY=your_api_key_here`\n",
    "\n",
    "Then you can use the summarizer as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Resumen del video transcript**\n",
      "\n",
      "**1. Tema principal/Tema**: La venta de acciones de EPM en UNE, una empresa de telecomunicaciones, y su impacto en la industria y la economía local.\n",
      "\n",
      "**2. Puntos clave**:\n",
      "\n",
      "* EPM busca vender sus acciones en UNE debido a la intensidad de capital y la rápida evolución tecnológica en la industria de las telecomunicaciones.\n",
      "* La venta de acciones se realizará a través de un proceso de enajenación, que requiere la aprobación del Consejo de Medellín.\n",
      "* El valor de las acciones se estima en 1,6 billones de pesos, según el valor en libros y la capitalización de UNE.\n",
      "* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\n",
      "\n",
      "**3. Detalles importantes**:\n",
      "\n",
      "* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\n",
      "* EPM tiene otros negocios estratégicos, como la generación y distribución de energía, agua y gas, que requieren inversiones importantes.\n",
      "* La venta de acciones se realizará a través de un proceso de enajenación, que incluye la oferta a sectores solidarios y especiales, y luego al mercado.\n",
      "* El gobierno también está considerando la venta de sus acciones en UNE, lo que podría cambiar el panorama de la industria de las telecomunicaciones en Colombia.\n",
      "* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, como la educación, la innovación y la conectividad.\n",
      "\n",
      "**4. Conclusión**:\n",
      "\n",
      "* La venta de acciones de EPM en UNE es un proceso complejo que requiere la aprobación del Consejo de Medellín y la valoración de las acciones en el mercado.\n",
      "* La venta de acciones se utilizará para financiar proyectos estratégicos de EPM, que beneficiarán a la comunidad y la economía local.\n",
      "* La industria de las telecomunicaciones es muy intensiva en capital y requiere inversiones constantes para mantenerse al día con la tecnología.\n",
      "* La venta de acciones de EPM en UNE puede tener un impacto significativo en el panorama de la industria de las telecomunicaciones en Colombia.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "youtube_url = \"https://www.youtube.com/watch?v=AgvBh3YC6fs&pp=ygUMZXBtIGNvbG9tYmlh\"\n",
    "language = \"spanish\"\n",
    "summary = summarize_youtube_video(youtube_url, language)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/02_MLFlow_implementation.ipynb
================================================================================

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer with MLflow Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Create a YouTube video summarization chain\n",
    "2. Track the chain and prompts using MLflow\n",
    "3. Load and use the tracked model\n",
    "\n",
    "## Setup and Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://luisangarita.gutierrez-contractor%40procore.com:****@artifacts.procoretech.com/artifactory/api/pypi/python/simple\n",
      "Requirement already satisfied: youtube-transcript-api in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.6.3)\n",
      "Requirement already satisfied: groq in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: mlflow in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.18.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.18.0)\n",
      "Requirement already satisfied: Flask<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.1.3)\n",
      "Requirement already satisfied: pandas<3 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (18.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.38.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: packaging<25 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.28.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n",
      "Requirement already satisfied: Mako in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.36.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api groq python-dotenv mlflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Chain Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeSummaryChain:\n",
    "    def __init__(self, model_name: str = \"mixtral-8x7b-32768\", temperature: float = 0.3):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.prompt_template = \"\"\"\n",
    "        Please provide a comprehensive summary of the following video transcript. \n",
    "        Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "        {text}\n",
    "\n",
    "        Please structure the summary with:\n",
    "        1. Main Topic/Theme\n",
    "        2. Key Points\n",
    "        3. Important Details\n",
    "        4. Conclusions\n",
    "        \"\"\"\n",
    "        \n",
    "    def _get_groq_client(self):\n",
    "        \"\"\"\n",
    "        Initialize and return Groq client\n",
    "        \n",
    "        :return: Initialized Groq client\n",
    "        \"\"\"\n",
    "        return groq.Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "    \n",
    "    def extract_video_id(self, url: str) -> str:\n",
    "        \"\"\"Extract YouTube video ID from URL\"\"\"\n",
    "        parsed_url = urlparse(url)\n",
    "        if parsed_url.hostname == 'youtu.be':\n",
    "            return parsed_url.path[1:]\n",
    "        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "            if parsed_url.path == '/watch':\n",
    "                return parse_qs(parsed_url.query)['v'][0]\n",
    "        return None\n",
    "\n",
    "    def get_transcript(self, video_id: str) -> str:\n",
    "        \"\"\"Get transcript for a YouTube video\"\"\"\n",
    "        try:\n",
    "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            return ' '.join([t['text'] for t in transcript_list])\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "    def summarize_text(self, text: str) -> str:\n",
    "        \"\"\"Summarize text using Groq\"\"\"\n",
    "        prompt = self.prompt_template.format(text=text)\n",
    "\n",
    "        try:\n",
    "            # Initialize client only when needed\n",
    "            client = self._get_groq_client()\n",
    "            completion = client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=2048\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error in summarization: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __call__(self, url: str) -> str:\n",
    "        \"\"\"Process a YouTube URL and return summary\"\"\"\n",
    "        video_id = self.extract_video_id(url)\n",
    "        if not video_id:\n",
    "            return \"Invalid YouTube URL\"\n",
    "        \n",
    "        transcript = self.get_transcript(video_id)\n",
    "        if not transcript:\n",
    "            return \"Could not retrieve transcript\"\n",
    "        \n",
    "        summary = self.summarize_text(transcript)\n",
    "        if not summary:\n",
    "            return \"Could not generate summary\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get chain configuration for MLflow tracking\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"prompt_template\": self.prompt_template\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_chain_to_mlflow(chain: YouTubeSummaryChain, experiment_name: str = \"youtube-summarizer\"):\n",
    "    \"\"\"\n",
    "    Log the chain configuration and prompt to MLflow\n",
    "    \n",
    "    :param chain: YouTubeSummaryChain instance to log\n",
    "    :param experiment_name: Name of the MLflow experiment\n",
    "    :return: MLflow run ID\n",
    "    \"\"\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        # Log parameters\n",
    "        config = chain.get_config()\n",
    "        mlflow.log_params({\n",
    "            \"model_name\": config[\"model_name\"],\n",
    "            \"temperature\": config[\"temperature\"]\n",
    "        })\n",
    "        \n",
    "        # Log prompt template as artifact\n",
    "        with open(\"prompt_template.txt\", \"w\") as f:\n",
    "            f.write(config[\"prompt_template\"])\n",
    "        mlflow.log_artifact(\"prompt_template.txt\")\n",
    "        \n",
    "        # Create an input example\n",
    "        input_example = \"https://www.youtube.com/watch?v=example\"\n",
    "        \n",
    "        # Log the chain as a custom model\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"youtube_summarizer\",\n",
    "            python_model=chain,\n",
    "            artifacts={\"prompt_template\": \"prompt_template.txt\"},\n",
    "            code_path=[\".\"],\n",
    "            pip_requirements=[\"youtube-transcript-api\", \"groq\", \"python-dotenv\"],\n",
    "            input_example=input_example\n",
    "        )\n",
    "        \n",
    "        return run.info.run_id\n",
    "\n",
    "def load_chain_from_mlflow(run_id: str) -> YouTubeSummaryChain:\n",
    "    \"\"\"Load a chain from MLflow\"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/youtube_summarizer\"\n",
    "    chain = mlflow.pyfunc.load_model(model_uri)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganga/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:2852: UserWarning: The `code_path` argument is replaced by `code_paths` and is deprecated as of MLflow version 2.12.0. This argument will be removed in a future release of MLflow.\n",
      "  warnings.warn(\n",
      "2024/11/19 03:15:45 INFO mlflow.types.utils: Unsupported type hint: <class 'str'>, skipping schema inference\n",
      "2024/11/19 03:15:46 INFO mlflow.types.utils: Unsupported type hint: <class 'str'>, skipping schema inference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting transcript: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=example! This is most likely caused by:\n",
      "\n",
      "Subtitles are disabled for this video\n",
      "\n",
      "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Failed to serialize Python model. Please audit your class variables (e.g. in `__init__()`) for any unpicklable objects. If you're trying to save an external model in your custom pyfunc, Please use the `artifacts` parameter in `mlflow.pyfunc.save_model()`, and load your external model in the `load_context()` method instead. For example:\n\nclass MyModel(mlflow.pyfunc.PythonModel):\n    def load_context(self, context):\n        model_path = context.artifacts['my_model_path']\n        // custom load logic here\n        self.model = load_model(model_path)\n\nFor more information, see our full tutorial at: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\n\nFull serialization error: cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create and log the chain\u001b[39;00m\n\u001b[1;32m      2\u001b[0m chain \u001b[38;5;241m=\u001b[39m YouTubeSummaryChain()\n\u001b[0;32m----> 3\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[43mlog_chain_to_mlflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain logged with run_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the chain\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36mlog_chain_to_mlflow\u001b[0;34m(chain, experiment_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m input_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=example\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Log the chain as a custom model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myoutube_summarizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_template\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_template.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myoutube-transcript-api\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython-dotenv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/tracing/provider.py:268\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m disable()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     enable()\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3246\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(artifact_path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;129m@trace_disabled\u001b[39m  \u001b[38;5;66;03m# Suppress traces for internal predict calls while logging model\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3046\u001b[0m     resources: Optional[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Resource]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3047\u001b[0m ):\n\u001b[1;32m   3048\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;124;03m    Log a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001b[39;00m\n\u001b[1;32m   3050\u001b[0m \u001b[38;5;124;03m    artifact for the current run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3244\u001b[0m \u001b[38;5;124;03m        metadata of the logged model.\u001b[39;00m\n\u001b[1;32m   3245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3247\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# deprecated\u001b[39;49;00m\n\u001b[1;32m   3252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3254\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3257\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3258\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_no_conversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_no_conversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3267\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/models/model.py:776\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39m_get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m    773\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    774\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id, metadata\u001b[38;5;241m=\u001b[39mmetadata, resources\u001b[38;5;241m=\u001b[39mresources\n\u001b[1;32m    775\u001b[0m )\n\u001b[0;32m--> 776\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/tracing/provider.py:272\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             enable()\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m         is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# We should only catch the exception from disable() and enable()\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# and let other exceptions propagate.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowTracingException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3006\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources, **kwargs)\u001b[0m\n\u001b[1;32m   2992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _save_model_with_loader_module_and_data_path(\n\u001b[1;32m   2993\u001b[0m         path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   2994\u001b[0m         loader_module\u001b[38;5;241m=\u001b[39mloader_module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3003\u001b[0m         infer_code_paths\u001b[38;5;241m=\u001b[39minfer_code_paths,\n\u001b[1;32m   3004\u001b[0m     )\n\u001b[1;32m   3005\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m second_argument_set_specified:\n\u001b[0;32m-> 3006\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model_with_class_artifacts_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3008\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3011\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_code_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_code_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llmops/lib/python3.11/site-packages/mlflow/pyfunc/model.py:382\u001b[0m, in \u001b[0;36m_save_model_with_class_artifacts_params\u001b[0;34m(path, python_model, signature, hints, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config, streamable, model_code_path, infer_code_paths)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# cloudpickle sometimes raises TypeError instead of PicklingError.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# catching generic Exception and checking message to handle both cases.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to serialize Python model. Please audit your \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass variables (e.g. in `__init__()`) for any \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munpicklable objects. If you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre trying to save an external model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min your custom pyfunc, Please use the `artifacts` parameter \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min `mlflow.pyfunc.save_model()`, and load your external model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the `load_context()` method instead. For example:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyModel(mlflow.pyfunc.PythonModel):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def load_context(self, context):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        model_path = context.artifacts[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_model_path\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        // custom load logic here\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.model = load_model(model_path)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    394\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor more information, see our full tutorial at: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFull serialization error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    397\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mMlflowException\u001b[0m: Failed to serialize Python model. Please audit your class variables (e.g. in `__init__()`) for any unpicklable objects. If you're trying to save an external model in your custom pyfunc, Please use the `artifacts` parameter in `mlflow.pyfunc.save_model()`, and load your external model in the `load_context()` method instead. For example:\n\nclass MyModel(mlflow.pyfunc.PythonModel):\n    def load_context(self, context):\n        model_path = context.artifacts['my_model_path']\n        // custom load logic here\n        self.model = load_model(model_path)\n\nFor more information, see our full tutorial at: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\n\nFull serialization error: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "# Create and log the chain\n",
    "chain = YouTubeSummaryChain()\n",
    "run_id = log_chain_to_mlflow(chain)\n",
    "print(f\"Chain logged with run_id: {run_id}\")\n",
    "\n",
    "# Load the chain\n",
    "loaded_chain = load_chain_from_mlflow(run_id)\n",
    "\n",
    "# Use the loaded chain\n",
    "youtube_url = \"https://www.youtube.com/watch?v=your_video_id\"\n",
    "summary = loaded_chain(youtube_url)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View MLflow Experiment Results\n",
    "\n",
    "You can view the tracked experiments by running:\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "This will start the MLflow UI server where you can see:\n",
    "1. All experiment runs\n",
    "2. Chain configurations\n",
    "3. Prompt templates\n",
    "4. Performance metrics (if added)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/meta.yaml
================================================================================

artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461
creation_time: 1732004080697
experiment_id: '336741345537322461'
last_update_time: 1732004080697
lifecycle_stage: active
name: youtube-summarizer



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts
end_time: null
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 907f1ecd64ca4ec2919e1657da05494b
run_name: abrasive-cod-859
run_uuid: 907f1ecd64ca4ec2919e1657da05494b
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004249085
status: 1
tags: []
user_id: ganga



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/artifacts
end_time: 1732004146098
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 0e7459a9e3524678a1970c2b02be4ee9
run_name: indecisive-mole-683
run_uuid: 0e7459a9e3524678a1970c2b02be4ee9
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004145291
status: 4
tags: []
user_id: ganga



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/artifacts
end_time: 1732004080824
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 0df34b8b49744c4d91061ee809b80f5b
run_name: intrigued-koi-579
run_uuid: 0df34b8b49744c4d91061ee809b80f5b
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004080797
status: 4
tags: []
user_id: ganga



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/907f1ecd64ca4ec2919e1657da05494b/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/0/meta.yaml
================================================================================

artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/0
creation_time: 1732004080692
experiment_id: '0'
last_update_time: 1732004080692
lifecycle_stage: active
name: Default



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0e7459a9e3524678a1970c2b02be4ee9/artifacts
end_time: 1732004146098
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 0e7459a9e3524678a1970c2b02be4ee9
run_name: indecisive-mole-683
run_uuid: 0e7459a9e3524678a1970c2b02be4ee9
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004145291
status: 4
tags: []
user_id: ganga



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/meta.yaml
================================================================================

artifact_uri: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/336741345537322461/0df34b8b49744c4d91061ee809b80f5b/artifacts
end_time: 1732004080824
entry_point_name: ''
experiment_id: '336741345537322461'
lifecycle_stage: active
run_id: 0df34b8b49744c4d91061ee809b80f5b
run_name: intrigued-koi-579
run_uuid: 0df34b8b49744c4d91061ee809b80f5b
source_name: ''
source_type: 4
source_version: ''
start_time: 1732004080797
status: 4
tags: []
user_id: ganga



================================================================================
# mlruns/1/fc23e07270ba42ddb3f4a3b3f5c9eee3/artifacts/youtube_summarizer/code/Youtube Summarizer/mlruns/0/meta.yaml
================================================================================

artifact_location: file:///Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille%40gmail.com/My%20Drive/REPO/Youtube%20Summarizer/mlruns/0
creation_time: 1732004080692
experiment_id: '0'
last_update_time: 1732004080692
lifecycle_stage: active
name: Default



================================================================================
# mlruns/1/daa7f8f98e84424bb04699f779d3d707/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/daa7f8f98e84424bb04699f779d3d707/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/1ee6c5706f2e4df0bb34b383b6590c96/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/1ee6c5706f2e4df0bb34b383b6590c96/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/80640e35abf84940b9e0043f6881abb2/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/80640e35abf84940b9e0043f6881abb2/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/a88ca06d3af4489fad1921c1c028f9b7/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/a88ca06d3af4489fad1921c1c028f9b7/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/413a66439ac54cb78a385e6e93146572/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/413a66439ac54cb78a385e6e93146572/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/2feba136305a4e22bd08bbcfb5decb48/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/2feba136305a4e22bd08bbcfb5decb48/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env



================================================================================
# mlruns/1/1d4a73d3db0e49e58886211224cfc70e/artifacts/youtube_summarizer/python_env.yaml
================================================================================

python: 3.11.10
build_dependencies:
- pip==24.3.1
- setuptools==75.5.0
- wheel==0.45.0
dependencies:
- -r requirements.txt



================================================================================
# mlruns/1/1d4a73d3db0e49e58886211224cfc70e/artifacts/youtube_summarizer/conda.yaml
================================================================================

channels:
- conda-forge
dependencies:
- python=3.11.10
- pip<=24.3.1
- pip:
  - mlflow==2.18.0
  - youtube-transcript-api
  - groq
  - python-dotenv
  - pandas
name: mlflow-env


