{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Nomic Vision Embeddings\n",
    "\n",
    "This notebook demonstrates how to finetune nomic-embed-image-v1 model using custom image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install nomic torch datasets transformers pillow torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from nomic import atlas\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the model and image processor\n",
    "model_name = \"nomic-ai/nomic-embed-image-v1\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Custom dataset class for images\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return {\n",
    "            'pixel_values': image,\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example training data - replace with your own data\n",
    "# You should have a list of image paths and corresponding labels\n",
    "train_image_paths = [\"path/to/image1.jpg\", \"path/to/image2.jpg\"]  # Replace with actual paths\n",
    "train_labels = [0, 1]  # Example labels\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = ImageDataset(train_image_paths, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training loop\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        pixel_values = batch['pixel_values'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token embedding\n",
    "        \n",
    "        # Add a simple projection layer for the task\n",
    "        projection = nn.Linear(embeddings.shape[1], 1).to(device)\n",
    "        predictions = projection(embeddings).squeeze()\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the finetuned model\n",
    "model.save_pretrained('finetuned_nomic_vision_model')\n",
    "processor.save_pretrained('finetuned_nomic_vision_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Finetuned Model\n",
    "\n",
    "Here's how to use the finetuned model to generate embeddings for images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def get_image_embedding(image_path):\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate embedding\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=image)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "# Example usage\n",
    "test_image_path = \"path/to/test_image.jpg\"  # Replace with actual path\n",
    "if os.path.exists(test_image_path):\n",
    "    embedding = get_image_embedding(test_image_path)\n",
    "    print(f\"Embedding shape: {embedding.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
