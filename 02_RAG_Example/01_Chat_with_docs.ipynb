{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "generate a txt file for a local repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_files(folder_path):\n",
    "    \"\"\"\n",
    "    Read files from the specified folder path with specific extensions.\n",
    "    \n",
    "    :param folder_path: Path to the folder containing the files to read\n",
    "    :return: List of tuples containing file paths and their contents\n",
    "    \"\"\"\n",
    "    files_and_code = []\n",
    "    file_extensions = ['.py', 'Dockerfile', '.yaml', '.env-example', '.md', \"ipynb\"]\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if any(file_name.endswith(ext) for ext in file_extensions):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    code = file.read()\n",
    "                    files_and_code.append((file_path, code))\n",
    "    \n",
    "    return files_and_code\n",
    "\n",
    "def create_txt_from_files(folder_path, output_txt_path):\n",
    "    \"\"\"\n",
    "    Create a text file containing the contents of all files in the specified folder.\n",
    "    \n",
    "    :param folder_path: Path to the folder containing the files to process\n",
    "    :param output_txt_path: Path where the output text file will be saved\n",
    "    \"\"\"\n",
    "    files_and_code = read_files(folder_path)\n",
    "    text = \"\"\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as output_file:\n",
    "        for file_path, code in files_and_code:\n",
    "            # Get relative path from the root folder\n",
    "            relative_path = os.path.relpath(file_path, folder_path)\n",
    "            text += f\"\\n{'='*80}\\n\"\n",
    "            output_file.write(f\"\\n{'='*80}\\n\")\n",
    "            text += f\"# {relative_path}\\n\"\n",
    "            output_file.write(f\"# {relative_path}\\n\")\n",
    "            text += f\"{'='*80}\\n\\n\"\n",
    "            output_file.write(f\"{'='*80}\\n\\n\")\n",
    "            text += f\"{code}\\n\\n\"\n",
    "            output_file.write(code)\n",
    "            output_file.write('\\n\\n')\n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "folder_path = '/Users/ganga/Library/CloudStorage/GoogleDrive-goldenguille@gmail.com/My Drive/REPO/llmops-youtube-summarizer'  # replace with your folder path\n",
    "output_txt_path = 'output.txt'  # replace with your output text file path\n",
    "text = create_txt_from_files(folder_path, output_txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"COHERE_API_KEY\"):\n",
    "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\",max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents([text])[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "texts = [doc.page_content for doc in documents]\n",
    "\n",
    "vectorstore = Chroma.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"# Goal\\\\n\",\\n    \"\\\\n\",\\n    \"generate a txt file for a local repository\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"# iterate through repo\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": []\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 4,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"\\\\n\",\\n      \"================================================================================\\\\n\",\\n      \"# agents.yaml\\\\n\",\\n      \"================================================================================\\\\n\",\\n      \"\\\\n\",\\n      \"# src/latest_ai_development/config/agents.yaml\\\\n\",\\n      \"researcher:\\\\n\",\\n      \"  role: >\\\\n\",\\n      \"    {topic} Senior Data Researcher\\\\n\",\\n      \"  goal: >\\\\n\",\\n      \"    Uncover cutting-edge developments in {topic}\\\\n\",\\n      \"  backstory: >\\\\n\",\\n      \"    You\\'re a seasoned researcher with a knack for uncovering the latest\\\\n\",\\n      \"    developments in {topic}. Known for your ability to find the most relevant\\\\n\",\\n      \"    information and present it in a clear and concise manner.\\\\n\",\\n      \"      \\\\n\",\\n      \"reporting_analyst:\\\\n\",\\n      \"  role: >\\\\n\",\\n      \"    {topic} Reporting Analyst\\\\n\",\\n      \"  goal: >\\\\n\",\\n      \"    Create detailed reports based on {topic} data analysis and research findings\\\\n\",\\n      \"  backstory: >\\\\n\",\\n      \"    You\\'re a meticulous analyst with a keen eye for detail. You\\'re known for\\\\n\",\\n      \"    your ability to turn complex data into clear and concise reports, making\\\\n\",\\n      \"    it easy for others to understand and act on the information you provide.\\\\n\",\\n      \"\\\\n\",\\n      \"\\\\n\",\\n      \"\\\\n\",\\n      \"================================================================================\\\\n\",\\n      \"# README.md\\\\n\",\\n      \"================================================================================\\\\n\",\\n      \"\\\\n\",\\n      \"# YouTube Video Summarizer with MLOps\\\\n\",\\n      \"\\\\n\",\\n      \"An advanced YouTube video summarization tool that leverages Groq\\'s LLM capabilities and MLOps practices to generate high-quality summaries of YouTube videos from their transcripts.\\\\n\",\\n      \"\\\\n\",\\n      \"## 🌟 Features\\\\n\",\\n      \"\\\\n\",\\n      \"- Extract transcripts from YouTube videos automatically\\\\n\",\\n      \"- Generate concise, accurate summaries using Groq\\'s LLM\\\\n\",\\n      \"- Track and version experiments using MLflow\\\\n\",\\n      \"- Evaluate summary quality using ROUGE scores\\\\n\",\\n      \"- Visualize performance metrics and length comparisons\\\\n\",\\n      \"- Reproducible MLOps pipeline\\\\n\",\\n      \"\\\\n\",\\n      \"## 📋 Prerequisites\\\\n\",\\n      \"\\\\n\",\\n      \"- Python 3.8+\\\\n\",\\n      \"- Groq API key\\\\n\",\\n      \"- YouTube Data API access (optional)\\\\n\",\\n      \"\\\\n\",\\n      \"## 🛠️ Installation\\\\n\",\\n      \"\\\\n\",\\n      \"1. Clone the repository:\\\\n\",\\n      \"```bash\\\\n\",\\n      \"git clone [your-repo-url]\\\\n\",\\n      \"cd llmops-youtube-summarizer\\\\n\",\\n      \"```\\\\n\",\\n      \"\\\\n\",\\n      \"2. Install dependencies:\\\\n\",\\n      \"```bash\\\\n\",\\n      \"pip install -r requirements.txt\\\\n\",\\n      \"```\\\\n\",\\n      \"\\\\n\",\\n      \"3. Set up environment variables:\\\\n\",\\n      \"```bash\\\\n\",\\n      \"cp .env.example .env\\\\n\",\\n      \"```\\\\n\",\\n      \"Edit `.env` and add your Groq API key:\\\\n\",\\n      \"```\\\\n\",\\n      \"GROQ_API_KEY=your_api_key_here\\\\n\",\\n      \"```\\\\n\",\\n      \"\\\\n\",\\n      \"## 🚀 Usage\\\\n\",\\n      \"\\\\n\",\\n      \"### Quick Start\\\\n\",\\n      \"1. Open and run the `01_PoC.ipynb` notebook for a simple proof-of-concept implementation\\\\n\",\\n      \"2. For the full MLOps pipeline, use `02_MLFlow_implementation.ipynb`\\\\n\",\\n      \"\\\\n\",\\n      \"### MLflow Tracking\\\\n\",\\n      \"The project uses MLflow to track:\\\\n\",\\n      \"- Model parameters\\\\n\",\\n      \"- ROUGE scores\\\\n\",\\n      \"- Summary lengths\\\\n\",\\n      \"- Performance metrics\\\\n\",\\n      \"\\\\n\",\\n      \"Access the MLflow UI:\\\\n\",\\n      \"```bash\\\\n\",\\n      \"mlflow ui\\\\n\",\\n      \"```\\\\n\",\\n      \"\\\\n\",'),\n",
       " Document(metadata={}, page_content=\"================================================================================\\n# agents.yaml\\n================================================================================\\n\\n# src/latest_ai_development/config/agents.yaml\\nresearcher:\\n  role: >\\n    {topic} Senior Data Researcher\\n  goal: >\\n    Uncover cutting-edge developments in {topic}\\n  backstory: >\\n    You're a seasoned researcher with a knack for uncovering the latest\\n    developments in {topic}. Known for your ability to find the most relevant\\n    information and present it in a clear and concise manner.\\n      \\nreporting_analyst:\\n  role: >\\n    {topic} Reporting Analyst\\n  goal: >\\n    Create detailed reports based on {topic} data analysis and research findings\\n  backstory: >\\n    You're a meticulous analyst with a keen eye for detail. You're known for\\n    your ability to turn complex data into clear and concise reports, making\\n    it easy for others to understand and act on the information you provide.\\n\\n\\n\\n================================================================================\\n# README.md\\n================================================================================\\n\\n# YouTube Video Summarizer with MLOps\\n\\nAn advanced YouTube video summarization tool that leverages Groq's LLM capabilities and MLOps practices to generate high-quality summaries of YouTube videos from their transcripts.\\n\\n## 🌟 Features\\n\\n- Extract transcripts from YouTube videos automatically\\n- Generate concise, accurate summaries using Groq's LLM\\n- Track and version experiments using MLflow\\n- Evaluate summary quality using ROUGE scores\\n- Visualize performance metrics and length comparisons\\n- Reproducible MLOps pipeline\\n\\n## 📋 Prerequisites\\n\\n- Python 3.8+\\n- Groq API key\\n- YouTube Data API access (optional)\\n\\n## 🛠️ Installation\\n\\n1. Clone the repository:\\n```bash\\ngit clone [your-repo-url]\\ncd llmops-youtube-summarizer\\n```\\n\\n2. Install dependencies:\\n```bash\\npip install -r requirements.txt\\n```\\n\\n3. Set up environment variables:\\n```bash\\ncp .env.example .env\\n```\\nEdit `.env` and add your Groq API key:\\n```\\nGROQ_API_KEY=your_api_key_here\\n```\\n\\n## 🚀 Usage\\n\\n### Quick Start\\n1. Open and run the `01_PoC.ipynb` notebook for a simple proof-of-concept implementation\\n2. For the full MLOps pipeline, use `02_MLFlow_implementation.ipynb`\\n\\n### MLflow Tracking\\nThe project uses MLflow to track:\\n- Model parameters\\n- ROUGE scores\\n- Summary lengths\\n- Performance metrics\\n\\nAccess the MLflow UI:\\n```bash\\nmlflow ui\\n```\\n\\n## 📊 Performance Metrics\\n\\nThe project includes several visualization tools:\\n- `length_comparison.png`: Compare original vs summarized text lengths\\n- `metrics_distribution.png`: Distribution of various performance metrics\\n- `rouge_scores.png`: ROUGE score analysis\\n\\n## 🔧 Dependencies\\n\\nKey dependencies include:\\n- youtube-transcript-api >= 0.6.1\\n- groq >= 0.4.2\\n- mlflow >= 2.10.0\\n- pandas >= 2.0.0\\n- rouge-score >= 0.1.2\\n- transformers >= 4.30.0\\n\\nFor a complete list, see `requirements.txt`\\n\\n## 📁 Project Structure\\n\\n```\\n.\\n├── 01_PoC.ipynb                  # Proof of concept implementation\\n├── 02_MLFlow_implementation.ipynb # MLOps pipeline implementation\\n├── prompt_template.txt           # LLM prompt engineering template\\n├── requirements.txt              # Project dependencies\\n├── mlruns/                      # MLflow experiment tracking\\n└── example_*/                   # Example outputs and results\\n```\\n\\n## 🤝 Contributing\\n\\n1. Fork the repository\\n2. Create your feature branch\\n3. Commit your changes\\n4. Push to the branch\\n5. Open a Pull Request\\n\\n## 📝 License\\n\\n[Your chosen license]\\n\\n## 🙏 Acknowledgments\\n\\n- Groq for providing the LLM API\\n- YouTube for transcript access\\n- MLflow for experiment tracking\\n\\n\\n================================================================================\\n# 04_Chat_with_docs.ipynb\\n================================================================================\"),\n",
       " Document(metadata={}, page_content='\"- ROUGE scores\\\\n\",\\n      \"- Summary lengths\\\\n\",\\n      \"- Performance metrics\\\\n\",\\n      \"\\\\n\",\\n      \"Access the MLflow UI:\\\\n\",\\n      \"```bash\\\\n\",\\n      \"mlflow ui\\\\n\",\\n      \"```\\\\n\",\\n      \"\\\\n\",\\n      \"## 📊 Performance Metrics\\\\n\",\\n      \"\\\\n\",\\n      \"The project includes several visualization tools:\\\\n\",\\n      \"- `length_comparison.png`: Compare original vs summarized text lengths\\\\n\",\\n      \"- `metrics_distribution.png`: Distribution of various performance metrics\\\\n\",\\n      \"- `rouge_scores.png`: ROUGE score analysis\\\\n\",\\n      \"\\\\n\",\\n      \"## 🔧 Dependencies\\\\n\",\\n      \"\\\\n\",\\n      \"Key dependencies include:\\\\n\",\\n      \"- youtube-transcript-api >= 0.6.1\\\\n\",\\n      \"- groq >= 0.4.2\\\\n\",\\n      \"- mlflow >= 2.10.0\\\\n\",\\n      \"- pandas >= 2.0.0\\\\n\",\\n      \"- rouge-score >= 0.1.2\\\\n\",\\n      \"- transformers >= 4.30.0\\\\n\",\\n      \"\\\\n\",\\n      \"For a complete list, see `requirements.txt`\\\\n\",\\n      \"\\\\n\",\\n      \"## 📁 Project Structure\\\\n\",\\n      \"\\\\n\",\\n      \"```\\\\n\",\\n      \".\\\\n\",\\n      \"├── 01_PoC.ipynb                  # Proof of concept implementation\\\\n\",\\n      \"├── 02_MLFlow_implementation.ipynb # MLOps pipeline implementation\\\\n\",\\n      \"├── prompt_template.txt           # LLM prompt engineering template\\\\n\",\\n      \"├── requirements.txt              # Project dependencies\\\\n\",\\n      \"├── mlruns/                      # MLflow experiment tracking\\\\n\",\\n      \"└── example_*/                   # Example outputs and results\\\\n\",\\n      \"```\\\\n\",\\n      \"\\\\n\",\\n      \"## 🤝 Contributing\\\\n\",\\n      \"\\\\n\",\\n      \"1. Fork the repository\\\\n\",\\n      \"2. Create your feature branch\\\\n\",\\n      \"3. Commit your changes\\\\n\",\\n      \"4. Push to the branch\\\\n\",\\n      \"5. Open a Pull Request\\\\n\",\\n      \"\\\\n\",\\n      \"## 📝 License\\\\n\",\\n      \"\\\\n\",\\n      \"[Your chosen license]\\\\n\",\\n      \"\\\\n\",\\n      \"## 🙏 Acknowledgments\\\\n\",\\n      \"\\\\n\",\\n      \"- Groq for providing the LLM API\\\\n\",\\n      \"- YouTube for transcript access\\\\n\",\\n      \"- MLflow for experiment tracking\\\\n\",\\n      \"\\\\n\",\\n      \"\\\\n\",\\n      \"================================================================================\\\\n\",\\n      \"# 04_Chat_with_docs.ipynb\\\\n\",\\n      \"================================================================================\\\\n\",\\n      \"\\\\n\",\\n      \"{\\\\n\",\\n      \" \\\\\"cells\\\\\": [\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# Goal\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"generate a txt file for a local repository\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# iterate through repo\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": []\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 3,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"import os\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def read_files(folder_path):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    Read files from the specified folder path with specific extensions.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    :param folder_path: Path to the folder containing the files to read\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    :return: List of tuples containing file paths and their contents\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    files_and_code = []\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    file_extensions = [\\'.py\\', \\'Dockerfile\\', \\'.yaml\\', \\'.env-example\\', \\'.md\\', \\\\\\\\\\\\\"ipynb\\\\\\\\\\\\\"]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for root, dirs, files in os.walk(folder_path):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        for file_name in files:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"            if any(file_name.endswith(ext) for ext in file_extensions):\\\\\\\\n\\\\\",\\\\n\",')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(query=\"What is the purpose of the repository?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of the repository is to host an advanced YouTube video summarization tool that leverages Groq's LLM capabilities and MLOps practices to generate high-quality summaries of YouTube videos from their transcripts. The repository includes several key components:\n",
      "\n",
      "1. **Proof of concept implementation**: A simple implementation of the YouTube video summarization tool using the `01_PoC.ipynb` notebook.\n",
      "2. **MLOps pipeline implementation**: A more comprehensive implementation of the YouTube video summarization tool using the `02_MLFlow_implementation.ipynb` notebook.\n",
      "3. **LLM prompt engineering template**: A template for engineering LLM prompts to generate high-quality summaries.\n",
      "4. **Requirements**: A list of dependencies required to run the project, including `youtube-transcript-api`, `groq`, `mlflow`, `pandas`, `rouge-score`, and `transformers`.\n",
      "5. **Project structure**: A description of the project's directory structure, including the `01_PoC.ipynb`, `02_MLFlow_implementation.ipynb`, `prompt_template.txt`, `requirements.txt`, `mlruns/`, and `example_*/` directories.\n",
      "6. **Contributing**: Guidelines for contributing to the repository, including forking the repository, creating a feature branch, committing changes, pushing to the branch, and opening a pull request.\n",
      "7. **License**: The license under which the repository is released.\n",
      "8. **Acknowledgments**: Acknowledgments to the contributors and dependencies used in the project.\n",
      "\n",
      "The repository is designed to be a reproducible MLOps pipeline that can be easily cloned, installed, and run on a local machine. The project includes several visualization tools, such as `length_comparison.png`, `metrics_distribution.png`, and `rouge_scores.png`, to help track and evaluate the performance of the summarization tool.\n"
     ]
    }
   ],
   "source": [
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(\n",
    "    api_key=os.getenv('GROQ_API_KEY')  # Put your API key here\n",
    ")\n",
    "\n",
    "def answer_question(query):\n",
    "    prompt = \"\"\"Answer the following question: {query}\n",
    "\n",
    "    based on the following context: {context}\"\"\"\n",
    "\n",
    "    context = vectorstore.similarity_search(query=query, k=3)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.2-11b-vision-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt.format(query=\"What is the purpose of the repository?\", context=context)}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=2048\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "result = answer_question(query=\"What is the purpose of the repository?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
